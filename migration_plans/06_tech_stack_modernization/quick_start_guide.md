# Quick Start Guide - Modern JobSpy Architecture

## ğŸš€ **ç«‹å³é–‹å§‹ï¼šç¾ä»£åŒ–é‡æ§‹å¯¦æ–½**

### **æŠ€è¡“æ£§æ±ºç­–çŸ©é™£**

| éœ€æ±‚ | Flask (ç¾ç‹€) | FastAPI + React (æ¨è–¦) | è©•åˆ† |
|------|-------------|------------------------|------|
| é–‹ç™¼é€Ÿåº¦ | 6/10 | 9/10 | âœ… |
| æ€§èƒ½ | 4/10 | 9/10 | âœ… |
| AI æ•´åˆ | 3/10 | 10/10 | âœ… |
| å¯ç¶­è­·æ€§ | 5/10 | 9/10 | âœ… |
| åœ˜éšŠå­¸ç¿’æˆæœ¬ | 9/10 | 6/10 | âš ï¸ |
| ç”Ÿæ…‹ç³»çµ± | 7/10 | 10/10 | âœ… |

**çµè«–**: ç¾ä»£åŒ–æ”¶ç›Šé å¤§æ–¼å­¸ç¿’æˆæœ¬ï¼Œå¼·çƒˆå»ºè­°é‡æ§‹ã€‚

---

## ğŸ“‹ **30 å¤©é‡æ§‹è¨ˆåŠƒ**

### **Week 1: ç’°å¢ƒæº–å‚™**

#### Day 1-2: æ–°é …ç›®åˆå§‹åŒ–
```bash
# 1. å‰µå»ºæ–°çš„é …ç›®çµæ§‹
mkdir jobspy-v2
cd jobspy-v2

# 2. åˆå§‹åŒ–å‰ç«¯é …ç›®
npm create vite@latest frontend -- --template react-ts
cd frontend
npm install @tanstack/react-query zustand axios tailwindcss

# 3. åˆå§‹åŒ–å¾Œç«¯é …ç›®  
cd ../
mkdir backend
cd backend
python -m venv venv
venv\Scripts\activate  # Windows
pip install fastapi uvicorn sqlalchemy asyncpg redis
```

#### Day 3-4: Docker é–‹ç™¼ç’°å¢ƒ
```yaml
# docker-compose.dev.yml
version: '3.8'
services:
  frontend:
    build: ./frontend
    ports: ["3000:3000"]
    volumes: ["./frontend:/app"]
    
  backend:
    build: ./backend  
    ports: ["8000:8000"]
    volumes: ["./backend:/app"]
    environment:
      - DATABASE_URL=postgresql://user:pass@postgres:5432/jobspy
      - REDIS_URL=redis://redis:6379
      
  postgres:
    image: postgres:15
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: pass
      POSTGRES_DB: jobspy
    volumes: ["postgres_data:/var/lib/postgresql/data"]
    
  redis:
    image: redis:7-alpine
    
volumes:
  postgres_data:
```

#### Day 5-7: åŸºç¤ API æ¶æ§‹
```python
# backend/main.py
from fastapi import FastAPI, Depends
from fastapi.middleware.cors import CORSMiddleware
import asyncio

app = FastAPI(title="JobSpy API v2")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def root():
    return {"message": "JobSpy API v2"}

@app.post("/api/search")
async def search_jobs(query: str):
    # TODO: æ•´åˆç¾æœ‰ jobseeker é‚è¼¯
    return {"jobs": [], "total": 0}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

### **Week 2: æ ¸å¿ƒåŠŸèƒ½é·ç§»**

#### Day 8-10: ç¾æœ‰ä»£ç¢¼æ•´åˆ
```python
# backend/services/job_search.py
import sys
sys.path.append("../../")  # å¼•å…¥ç¾æœ‰ jobseeker æ¨¡çµ„

from jobseeker.smart_router import smart_router
from jobseeker.model import Site

class JobSearchService:
    async def search_jobs(self, query: str, location: str = "", results_wanted: int = 20):
        """ä½¿ç”¨ç¾æœ‰ jobseeker é‚è¼¯çš„ç•°æ­¥åŒ…è£"""
        
        # èª¿ç”¨ç¾æœ‰æ™ºèƒ½è·¯ç”±
        loop = asyncio.get_event_loop()
        result = await loop.run_in_executor(
            None, 
            smart_router, 
            query, location, results_wanted
        )
        
        return {
            "jobs": result.combined_jobs_data.to_dict('records') if result.combined_jobs_data is not None else [],
            "total_jobs": result.total_jobs,
            "successful_sites": [agent.value for agent in result.successful_agents],
            "confidence_score": result.confidence_score
        }
```

#### Day 11-14: React å‰ç«¯åŸºç¤
```typescript
// frontend/src/types/index.ts
export interface JobListing {
  title: string;
  company: string;
  location: string;
  salary?: string;
  description: string;
  job_url: string;
  site: string;
}

export interface SearchResult {
  jobs: JobListing[];
  total_jobs: number;
  successful_sites: string[];
  confidence_score: number;
}

// frontend/src/services/api.ts
import axios from 'axios';

const api = axios.create({
  baseURL: 'http://localhost:8000/api',
});

export const searchJobs = async (query: string, location: string = ""): Promise<SearchResult> => {
  const response = await api.post('/search', { query, location });
  return response.data;
};

// frontend/src/components/SearchForm.tsx
import React, { useState } from 'react';
import { useMutation } from '@tanstack/react-query';
import { searchJobs } from '../services/api';

export const SearchForm: React.FC = () => {
  const [query, setQuery] = useState('');
  const [location, setLocation] = useState('');
  
  const searchMutation = useMutation({
    mutationFn: ({ query, location }: { query: string; location: string }) =>
      searchJobs(query, location),
  });
  
  const handleSubmit = (e: React.FormEvent) => {
    e.preventDefault();
    searchMutation.mutate({ query, location });
  };
  
  return (
    <form onSubmit={handleSubmit} className="max-w-2xl mx-auto p-6">
      <div className="flex gap-4">
        <input
          type="text"
          value={query}
          onChange={(e) => setQuery(e.target.value)}
          placeholder="æœå°‹è·ä½..."
          className="flex-1 px-4 py-2 border rounded-lg"
        />
        <input
          type="text"
          value={location}
          onChange={(e) => setLocation(e.target.value)}
          placeholder="åœ°é» (å¯é¸)"
          className="w-48 px-4 py-2 border rounded-lg"
        />
        <button
          type="submit"
          disabled={searchMutation.isLoading}
          className="px-6 py-2 bg-blue-600 text-white rounded-lg disabled:opacity-50"
        >
          {searchMutation.isLoading ? 'æœå°‹ä¸­...' : 'æœå°‹'}
        </button>
      </div>
      
      {searchMutation.data && (
        <div className="mt-6">
          <p>æ‰¾åˆ° {searchMutation.data.total_jobs} å€‹è·ä½</p>
          {/* è·ä½åˆ—è¡¨çµ„ä»¶ */}
        </div>
      )}
    </form>
  );
};
```

### **Week 3: AI è¦–è¦ºæ•´åˆ**

#### Day 15-17: OpenAI Vision API æ•´åˆ
```python
# backend/services/ai_vision.py
import openai
import base64
from PIL import Image
import io

class AIVisionService:
    def __init__(self, api_key: str):
        self.client = openai.AsyncOpenAI(api_key=api_key)
    
    async def analyze_job_page(self, image_data: bytes) -> dict:
        """åˆ†ææ±‚è·é é¢æˆªåœ–"""
        
        # è½‰æ›ç‚º base64
        image_base64 = base64.b64encode(image_data).decode('utf-8')
        
        response = await self.client.chat.completions.create(
            model="gpt-4-vision-preview",
            messages=[{
                "role": "user", 
                "content": [
                    {"type": "text", "text": "åˆ†æé€™å€‹æ±‚è·ç¶²ç«™é é¢ï¼Œæå–è·ä½ä¿¡æ¯å’Œå¯é»æ“Šå…ƒç´ ä½ç½®"},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}}
                ]
            }],
            max_tokens=1000
        )
        
        return {"analysis": response.choices[0].message.content}

# backend/routers/ai.py
from fastapi import APIRouter, UploadFile, File
from services.ai_vision import AIVisionService
import os

router = APIRouter(prefix="/ai", tags=["AI"])
vision_service = AIVisionService(os.getenv("OPENAI_API_KEY"))

@router.post("/analyze-page")
async def analyze_page(file: UploadFile = File(...)):
    content = await file.read()
    result = await vision_service.analyze_job_page(content)
    return result
```

#### Day 18-21: æ™ºèƒ½çˆ¬èŸ²å¼•æ“
```python
# backend/services/smart_scraper.py
from playwright.async_api import async_playwright
import asyncio
from .ai_vision import AIVisionService

class SmartScraper:
    def __init__(self, vision_service: AIVisionService):
        self.vision_service = vision_service
    
    async def scrape_with_vision(self, url: str) -> dict:
        """ä½¿ç”¨ AI è¦–è¦ºçš„æ™ºèƒ½çˆ¬èŸ²"""
        
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            page = await browser.new_page()
            
            try:
                await page.goto(url)
                
                # æˆªåœ–
                screenshot = await page.screenshot()
                
                # AI åˆ†æ
                analysis = await self.vision_service.analyze_job_page(screenshot)
                
                # TODO: åŸºæ–¼ AI åˆ†æçµæœé€²è¡Œæ™ºèƒ½æ“ä½œ
                
                return analysis
                
            finally:
                await browser.close()
```

### **Week 4: éƒ¨ç½²èˆ‡å„ªåŒ–**

#### Day 22-24: ç”Ÿç”¢éƒ¨ç½²é…ç½®
```dockerfile
# backend/Dockerfile
FROM python:3.11-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]

# frontend/Dockerfile  
FROM node:18-alpine

WORKDIR /app
COPY package*.json ./
RUN npm ci

COPY . .
RUN npm run build

FROM nginx:alpine
COPY --from=0 /app/dist /usr/share/nginx/html
```

#### Day 25-28: æ€§èƒ½å„ªåŒ–
```python
# backend/middleware/performance.py
import time
from fastapi import Request, Response
import logging

logger = logging.getLogger(__name__)

async def performance_middleware(request: Request, call_next):
    start_time = time.time()
    
    response = await call_next(request)
    
    process_time = time.time() - start_time
    response.headers["X-Process-Time"] = str(process_time)
    
    logger.info(f"{request.method} {request.url} - {process_time:.2f}s")
    return response

# ç·©å­˜é…ç½®
from functools import lru_cache
import redis

redis_client = redis.Redis.from_url("redis://localhost:6379")

@lru_cache(maxsize=1000)
async def cached_search(query: str, location: str):
    """ç·©å­˜æœå°‹çµæœ"""
    cache_key = f"search:{query}:{location}"
    cached = redis_client.get(cache_key)
    
    if cached:
        return json.loads(cached)
        
    # åŸ·è¡Œæœå°‹é‚è¼¯...
    result = await search_jobs(query, location)
    
    # ç·©å­˜ 1 å°æ™‚
    redis_client.setex(cache_key, 3600, json.dumps(result))
    return result
```

#### Day 29-30: ç›£æ§èˆ‡æ¸¬è©¦
```python
# backend/monitoring/metrics.py
from prometheus_client import Counter, Histogram, generate_latest
import time

REQUEST_COUNT = Counter('requests_total', 'Total requests', ['method', 'endpoint'])
REQUEST_DURATION = Histogram('request_duration_seconds', 'Request duration')

def track_metrics(func):
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        
        try:
            result = await func(*args, **kwargs)
            REQUEST_COUNT.labels(method='POST', endpoint='/search').inc()
            return result
        finally:
            REQUEST_DURATION.observe(time.time() - start_time)
    
    return wrapper

# å¥åº·æª¢æŸ¥
@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "timestamp": time.time(),
        "services": {
            "database": await check_database(),
            "redis": await check_redis(),
            "ai_vision": await check_ai_service()
        }
    }
```

---

## ğŸ¯ **é·ç§»æª¢æŸ¥æ¸…å–®**

### **æŠ€è¡“æº–å‚™ âœ…**
- [ ] Docker é–‹ç™¼ç’°å¢ƒé…ç½®å®Œæˆ
- [ ] FastAPI åŸºç¤æ¶æ§‹å»ºç«‹
- [ ] React TypeScript é …ç›®åˆå§‹åŒ–
- [ ] PostgreSQL æ•¸æ“šåº«é·ç§»
- [ ] Redis ç·©å­˜æ•´åˆ

### **åŠŸèƒ½é·ç§» âœ…**  
- [ ] ç¾æœ‰ jobseeker æ¨¡çµ„æ•´åˆ
- [ ] æ™ºèƒ½è·¯ç”±ç³»çµ±é·ç§»
- [ ] ç”¨æˆ¶èªè­‰ç³»çµ±é‡æ§‹
- [ ] æœå°‹çµæœå±•ç¤ºå„ªåŒ–
- [ ] CSV/JSON å°å‡ºåŠŸèƒ½

### **AI å¢å¼· âœ…**
- [ ] OpenAI Vision API æ•´åˆ
- [ ] æœ¬åœ° AI æ¨¡å‹é…ç½®
- [ ] æ™ºèƒ½çˆ¬èŸ²å¼•æ“é–‹ç™¼
- [ ] æˆæœ¬æ§åˆ¶æ©Ÿåˆ¶
- [ ] æ€§èƒ½ç›£æ§ç³»çµ±

### **éƒ¨ç½²æº–å‚™ âœ…**
- [ ] ç”Ÿç”¢ç’°å¢ƒ Docker é…ç½®
- [ ] CI/CD æµæ°´ç·šå»ºç«‹
- [ ] ç’°å¢ƒè®Šæ•¸ç®¡ç†
- [ ] ç›£æ§å’Œæ—¥èªŒç³»çµ±
- [ ] å‚™ä»½å’Œæ¢å¾©ç­–ç•¥

---

## ğŸ’° **æˆæœ¬æ•ˆç›Šé ä¼°**

### **é–‹ç™¼æŠ•å…¥**
- **é–‹ç™¼æ™‚é–“**: 30 å¤©å…¨è·é–‹ç™¼
- **å­¸ç¿’æˆæœ¬**: 1-2 é€±ç¾ä»£æŠ€è¡“æ£§ç†Ÿæ‚‰
- **ç¸½é ç®—**: $30K-50K (å«äººåŠ›å’Œå·¥å…·æˆæœ¬)

### **é æœŸæ”¶ç›Š**  
- **æ€§èƒ½æå‡**: 5-10å€éŸ¿æ‡‰é€Ÿåº¦
- **é–‹ç™¼æ•ˆç‡**: 3å€åŠŸèƒ½é–‹ç™¼é€Ÿåº¦
- **ç¶­è­·æˆæœ¬**: 50% æ¸›å°‘
- **AI ç«¶çˆ­å„ªå‹¢**: ç¨ç‰¹å¸‚å ´å®šä½
- **æ“´å±•èƒ½åŠ›**: æ”¯æŒ 10å€ç”¨æˆ¶å¢é•·

### **ROI åˆ†æ**
- **çŸ­æœŸ (6å€‹æœˆ)**: é–‹ç™¼æ•ˆç‡æå‡æ”¶å›æˆæœ¬
- **ä¸­æœŸ (1å¹´)**: AI åŠŸèƒ½å¸¶ä¾†ç«¶çˆ­å„ªå‹¢
- **é•·æœŸ (2-3å¹´)**: æŠ€è¡“é ˜å…ˆåœ°ä½ç¢ºç«‹

**å»ºè­°**: ç«‹å³é–‹å§‹é‡æ§‹ï¼ŒæŠ€è¡“å‚µå‹™æ¸…å„Ÿåˆ»ä¸å®¹ç·©ï¼ŒAI æ•´åˆå°‡æˆç‚ºæ±ºå®šæ€§ç«¶çˆ­å„ªå‹¢ã€‚