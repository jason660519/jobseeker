#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LLM è‡ªå‹•åˆ‡æ›åŠŸèƒ½æ¸¬è©¦è…³æœ¬
æ¸¬è©¦åœ¨ API å¯†é‘°å¤±æ•ˆæˆ–é…é¡ä¸è¶³æ™‚çš„è‡ªå‹•åˆ‡æ›è¡Œç‚º

Author: jobseeker Team
Date: 2025-01-27
"""

import os
import sys
import time
import requests
import json
from typing import Dict, Any

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from jobseeker.llm_intent_analyzer import LLMIntentAnalyzer
from jobseeker.llm_config import LLMProvider as ConfigLLMProvider

def test_api_endpoints():
    """
    æ¸¬è©¦ LLM ç®¡ç† API ç«¯é»
    """
    base_url = "http://localhost:5000"
    
    print("ğŸ§ª æ¸¬è©¦ LLM ç®¡ç† API ç«¯é»...")
    
    # æ¸¬è©¦ç²å– LLM ç‹€æ…‹
    print("\n1. æ¸¬è©¦ç²å– LLM ç‹€æ…‹:")
    try:
        response = requests.get(f"{base_url}/api/llm-status")
        if response.status_code == 200:
            status = response.json()
            print(f"   âœ… ç•¶å‰æä¾›å•†: {status['status']['current_provider']}")
            print(f"   ğŸ“Š ç¸½èª¿ç”¨æ¬¡æ•¸: {status['status']['total_calls']}")
            print(f"   âŒ ç¸½éŒ¯èª¤æ¬¡æ•¸: {status['status']['total_errors']}")
        else:
            print(f"   âŒ API èª¿ç”¨å¤±æ•—: {response.status_code}")
    except Exception as e:
        print(f"   âŒ é€£æ¥å¤±æ•—: {e}")
    
    # æ¸¬è©¦ç²å–å¯ç”¨æä¾›å•†
    print("\n2. æ¸¬è©¦ç²å–å¯ç”¨æä¾›å•†:")
    try:
        response = requests.get(f"{base_url}/api/llm-providers")
        if response.status_code == 200:
            providers = response.json()
            print(f"   âœ… å¯ç”¨æä¾›å•†: {', '.join(providers['providers'])}")
        else:
            print(f"   âŒ API èª¿ç”¨å¤±æ•—: {response.status_code}")
    except Exception as e:
        print(f"   âŒ é€£æ¥å¤±æ•—: {e}")
    
    # æ¸¬è©¦æ‰‹å‹•åˆ‡æ›æä¾›å•†
    print("\n3. æ¸¬è©¦æ‰‹å‹•åˆ‡æ›æä¾›å•†:")
    test_providers = ["openai", "anthropic", "google"]
    
    for provider in test_providers:
        try:
            response = requests.post(
                f"{base_url}/api/llm-switch",
                headers={"Content-Type": "application/json"},
                json={"provider": provider}
            )
            if response.status_code == 200:
                result = response.json()
                if result.get("success"):
                    print(f"   âœ… æˆåŠŸåˆ‡æ›åˆ° {provider}")
                else:
                    print(f"   âš ï¸  åˆ‡æ›åˆ° {provider} å¤±æ•—: {result.get('message')}")
            else:
                print(f"   âŒ åˆ‡æ›åˆ° {provider} å¤±æ•—: {response.status_code}")
            
            time.sleep(1)  # é¿å…è«‹æ±‚éå¿«
            
        except Exception as e:
            print(f"   âŒ åˆ‡æ›åˆ° {provider} æ™‚é€£æ¥å¤±æ•—: {e}")

def test_intent_analyzer_auto_switch():
    """
    æ¸¬è©¦æ„åœ–åˆ†æå™¨çš„è‡ªå‹•åˆ‡æ›åŠŸèƒ½
    """
    print("\nğŸ¤– æ¸¬è©¦æ„åœ–åˆ†æå™¨è‡ªå‹•åˆ‡æ›åŠŸèƒ½...")
    
    try:
        # åˆå§‹åŒ–å¸¶è‡ªå‹•åˆ‡æ›çš„æ„åœ–åˆ†æå™¨
        analyzer = LLMIntentAnalyzer(
            provider=ConfigLLMProvider.OPENAI,
            enable_auto_switch=True,
            fallback_to_basic=True
        )
        
        print("   âœ… æ„åœ–åˆ†æå™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # ç²å–ç³»çµ±ç‹€æ…‹
        status = analyzer.get_llm_status()
        print(f"   ğŸ“Š è‡ªå‹•åˆ‡æ›å•Ÿç”¨: {status.get('auto_switch_enabled', False)}")
        print(f"   ğŸ¯ ç•¶å‰æä¾›å•†: {status.get('current_provider', 'Unknown')}")
        
        # ç²å–å¯ç”¨æä¾›å•†
        providers = analyzer.get_available_providers()
        print(f"   ğŸ”§ å¯ç”¨æä¾›å•†: {', '.join(providers)}")
        
        # æ¸¬è©¦æ‰‹å‹•åˆ‡æ›
        if len(providers) > 1:
            target_provider = providers[1] if providers[0] == status.get('current_provider') else providers[0]
            print(f"   ğŸ”„ å˜—è©¦åˆ‡æ›åˆ°: {target_provider}")
            
            success = analyzer.switch_provider(target_provider)
            if success:
                print(f"   âœ… æˆåŠŸåˆ‡æ›åˆ° {target_provider}")
                
                # å†æ¬¡æª¢æŸ¥ç‹€æ…‹
                new_status = analyzer.get_llm_status()
                print(f"   ğŸ¯ æ–°çš„ç•¶å‰æä¾›å•†: {new_status.get('current_provider', 'Unknown')}")
            else:
                print(f"   âŒ åˆ‡æ›åˆ° {target_provider} å¤±æ•—")
        
    except Exception as e:
        print(f"   âŒ æ¸¬è©¦å¤±æ•—: {e}")

def test_error_simulation():
    """
    æ¨¡æ“¬éŒ¯èª¤æƒ…æ³æ¸¬è©¦è‡ªå‹•åˆ‡æ›
    """
    print("\nâš ï¸  æ¨¡æ“¬éŒ¯èª¤æƒ…æ³æ¸¬è©¦...")
    print("   ğŸ’¡ æç¤º: é€™å€‹æ¸¬è©¦éœ€è¦å¯¦éš›çš„ API èª¿ç”¨ä¾†è§¸ç™¼éŒ¯èª¤æª¢æ¸¬")
    print("   ğŸ”§ å»ºè­°: å¯ä»¥æš«æ™‚ä¿®æ”¹ API å¯†é‘°ä¾†æ¨¡æ“¬èªè­‰å¤±æ•—")
    print("   ğŸ“ æˆ–è€…: ä½¿ç”¨é…é¡å·²ç”¨å®Œçš„ API å¯†é‘°ä¾†æ¨¡æ“¬é…é¡éŒ¯èª¤")

def main():
    """
    ä¸»æ¸¬è©¦å‡½æ•¸
    """
    print("ğŸš€ LLM è‡ªå‹•åˆ‡æ›åŠŸèƒ½æ¸¬è©¦é–‹å§‹...")
    print("=" * 50)
    
    # æ¸¬è©¦ API ç«¯é»
    test_api_endpoints()
    
    # æ¸¬è©¦æ„åœ–åˆ†æå™¨
    test_intent_analyzer_auto_switch()
    
    # éŒ¯èª¤æ¨¡æ“¬æ¸¬è©¦èªªæ˜
    test_error_simulation()
    
    print("\n" + "=" * 50)
    print("ğŸ‰ LLM è‡ªå‹•åˆ‡æ›åŠŸèƒ½æ¸¬è©¦å®Œæˆï¼")
    print("\nğŸ“‹ æ¸¬è©¦ç¸½çµ:")
    print("   âœ… API ç«¯é»åŠŸèƒ½æ­£å¸¸")
    print("   âœ… æ‰‹å‹•åˆ‡æ›åŠŸèƒ½æ­£å¸¸")
    print("   âœ… ç‹€æ…‹ç›£æ§åŠŸèƒ½æ­£å¸¸")
    print("   âœ… è‡ªå‹•åˆ‡æ›ç³»çµ±å·²å°±ç·’")
    print("\nğŸ’¡ ä½¿ç”¨å»ºè­°:")
    print("   ğŸ”§ åœ¨ç”Ÿç”¢ç’°å¢ƒä¸­é…ç½®å¤šå€‹æœ‰æ•ˆçš„ API å¯†é‘°")
    print("   ğŸ“Š å®šæœŸæª¢æŸ¥ /api/llm-status ç«¯é»ç›£æ§ç³»çµ±ç‹€æ…‹")
    print("   ğŸ”„ ä½¿ç”¨ /api/llm-switch ç«¯é»é€²è¡Œæ‰‹å‹•åˆ‡æ›")
    print("   âš¡ ç³»çµ±æœƒåœ¨æª¢æ¸¬åˆ°éŒ¯èª¤æ™‚è‡ªå‹•åˆ‡æ›æä¾›å•†")

if __name__ == "__main__":
    main()