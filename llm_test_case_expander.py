#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LLMæ¸¬è©¦æ¡ˆä¾‹æ“´å……å·¥å…·
è‡ªå‹•ç”Ÿæˆå¤§é‡å¤šæ¨£åŒ–çš„æ¸¬è©¦æ¡ˆä¾‹ï¼Œç”¨æ–¼æ¯”è¼ƒä¸åŒLLMæ¨¡å‹çš„è¼¸å‡ºè¡¨ç¾å·®ç•°

Author: JobSpy Team
Date: 2025-01-27
"""

import json
import random
import itertools
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple, Set
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
from collections import defaultdict
import uuid
import re


class TestCaseType(Enum):
    """æ¸¬è©¦æ¡ˆä¾‹é¡å‹"""
    BASIC_SEARCH = "basic_search"  # åŸºç¤æœå°‹
    ADVANCED_SEARCH = "advanced_search"  # é€²éšæœå°‹
    SKILL_FOCUSED = "skill_focused"  # æŠ€èƒ½å°å‘
    LOCATION_FOCUSED = "location_focused"  # åœ°é»å°å‘
    SALARY_FOCUSED = "salary_focused"  # è–ªè³‡å°å‘
    CAREER_TRANSITION = "career_transition"  # è·æ¶¯è½‰æ›
    REMOTE_WORK = "remote_work"  # é ç¨‹å·¥ä½œ
    INDUSTRY_SPECIFIC = "industry_specific"  # è¡Œæ¥­ç‰¹å®š
    EXPERIENCE_LEVEL = "experience_level"  # ç¶“é©—ç­‰ç´š
    COMPANY_SPECIFIC = "company_specific"  # å…¬å¸ç‰¹å®š
    EDGE_CASE = "edge_case"  # é‚Šç•Œæ¡ˆä¾‹
    MULTILINGUAL = "multilingual"  # å¤šèªè¨€
    AMBIGUOUS = "ambiguous"  # æ¨¡ç³ŠæŸ¥è©¢
    COMPLEX_SCENARIO = "complex_scenario"  # è¤‡é›œå ´æ™¯
    ADVERSARIAL = "adversarial"  # å°æŠ—æ€§æ¸¬è©¦


class DifficultyLevel(Enum):
    """é›£åº¦ç­‰ç´š"""
    TRIVIAL = "trivial"  # æ¥µç°¡å–®
    EASY = "easy"  # ç°¡å–®
    MEDIUM = "medium"  # ä¸­ç­‰
    HARD = "hard"  # å›°é›£
    EXPERT = "expert"  # å°ˆå®¶ç´š
    EXTREME = "extreme"  # æ¥µç«¯


class ExpansionStrategy(Enum):
    """æ“´å……ç­–ç•¥"""
    TEMPLATE_VARIATION = "template_variation"  # æ¨¡æ¿è®ŠåŒ–
    PARAMETER_COMBINATION = "parameter_combination"  # åƒæ•¸çµ„åˆ
    SEMANTIC_EXPANSION = "semantic_expansion"  # èªç¾©æ“´å±•
    SYNTACTIC_VARIATION = "syntactic_variation"  # èªæ³•è®ŠåŒ–
    DOMAIN_TRANSFER = "domain_transfer"  # é ˜åŸŸé·ç§»
    NOISE_INJECTION = "noise_injection"  # å™ªè²æ³¨å…¥
    COMPLEXITY_SCALING = "complexity_scaling"  # è¤‡é›œåº¦ç¸®æ”¾
    MULTILINGUAL_TRANSLATION = "multilingual_translation"  # å¤šèªè¨€ç¿»è­¯


@dataclass
class TestCaseTemplate:
    """æ¸¬è©¦æ¡ˆä¾‹æ¨¡æ¿"""
    template_id: str
    category: TestCaseType
    difficulty: DifficultyLevel
    template_text: str
    parameters: List[str]
    expected_intent: str
    metadata: Dict[str, Any] = field(default_factory=dict)
    variations: List[str] = field(default_factory=list)
    constraints: Dict[str, Any] = field(default_factory=dict)


@dataclass
class ExpandedTestCase:
    """æ“´å……çš„æ¸¬è©¦æ¡ˆä¾‹"""
    test_case_id: str
    original_template_id: str
    expansion_strategy: ExpansionStrategy
    category: TestCaseType
    difficulty: DifficultyLevel
    query: str
    expected_intent: str
    expected_entities: Dict[str, Any]
    metadata: Dict[str, Any]
    language: str = "zh-TW"
    complexity_score: float = 0.5
    uniqueness_score: float = 0.5


@dataclass
class ExpansionConfig:
    """æ“´å……é…ç½®"""
    target_count: int = 1000
    difficulty_distribution: Dict[DifficultyLevel, float] = field(default_factory=lambda: {
        DifficultyLevel.EASY: 0.3,
        DifficultyLevel.MEDIUM: 0.4,
        DifficultyLevel.HARD: 0.2,
        DifficultyLevel.EXPERT: 0.08,
        DifficultyLevel.EXTREME: 0.02
    })
    category_distribution: Dict[TestCaseType, float] = field(default_factory=dict)
    language_distribution: Dict[str, float] = field(default_factory=lambda: {
        "zh-TW": 0.4,
        "zh-CN": 0.2,
        "en-US": 0.3,
        "ja-JP": 0.05,
        "ko-KR": 0.05
    })
    expansion_strategies: List[ExpansionStrategy] = field(default_factory=lambda: list(ExpansionStrategy))
    ensure_diversity: bool = True
    max_similarity_threshold: float = 0.8


class LLMTestCaseExpander:
    """LLMæ¸¬è©¦æ¡ˆä¾‹æ“´å……å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ“´å……å™¨"""
        self.templates = []
        self.expanded_cases = []
        self.entity_pools = self._load_entity_pools()
        self.language_patterns = self._load_language_patterns()
        self.complexity_factors = self._load_complexity_factors()
        self.generated_queries = set()  # ç”¨æ–¼å»é‡
        
    def _load_entity_pools(self) -> Dict[str, List[str]]:
        """è¼‰å…¥å¯¦é«”æ± """
        return {
            "job_titles": [
                "è»Ÿé«”å·¥ç¨‹å¸«", "è³‡æ–™ç§‘å­¸å®¶", "ç”¢å“ç¶“ç†", "UI/UXè¨­è¨ˆå¸«", "DevOpså·¥ç¨‹å¸«",
                "å‰ç«¯å·¥ç¨‹å¸«", "å¾Œç«¯å·¥ç¨‹å¸«", "å…¨ç«¯å·¥ç¨‹å¸«", "æ©Ÿå™¨å­¸ç¿’å·¥ç¨‹å¸«", "é›²ç«¯æ¶æ§‹å¸«",
                "ç¶²è·¯å®‰å…¨å°ˆå®¶", "æ•¸æ“šåˆ†æå¸«", "å°ˆæ¡ˆç¶“ç†", "æŠ€è¡“ä¸»ç®¡", "ç³»çµ±ç®¡ç†å“¡",
                "å“è³ªä¿è­‰å·¥ç¨‹å¸«", "ç§»å‹•æ‡‰ç”¨é–‹ç™¼è€…", "å€å¡Šéˆé–‹ç™¼è€…", "AIç ”ç©¶å“¡", "æŠ€è¡“å¯«æ‰‹",
                "æ¥­å‹™åˆ†æå¸«", "æ•¸ä½è¡ŒéŠ·å°ˆå“¡", "å®¢æˆ¶æˆåŠŸç¶“ç†", "éŠ·å”®ä»£è¡¨", "äººåŠ›è³‡æºå°ˆå“¡",
                "è²¡å‹™åˆ†æå¸«", "æœƒè¨ˆå¸«", "æ³•å‹™å°ˆå“¡", "ç‡Ÿé‹ç¶“ç†", "ä¾›æ‡‰éˆç®¡ç†å¸«"
            ],
            "skills": [
                "Python", "JavaScript", "Java", "C++", "React", "Vue.js", "Angular",
                "Node.js", "Django", "Flask", "Spring Boot", "Docker", "Kubernetes",
                "AWS", "Azure", "GCP", "TensorFlow", "PyTorch", "Scikit-learn",
                "SQL", "MongoDB", "PostgreSQL", "Redis", "Elasticsearch",
                "Git", "Jenkins", "CI/CD", "Agile", "Scrum", "æ©Ÿå™¨å­¸ç¿’", "æ·±åº¦å­¸ç¿’",
                "è‡ªç„¶èªè¨€è™•ç†", "è¨ˆç®—æ©Ÿè¦–è¦º", "æ•¸æ“šæŒ–æ˜", "çµ±è¨ˆåˆ†æ", "A/Bæ¸¬è©¦"
            ],
            "locations": [
                "å°åŒ—", "æ–°åŒ—", "æ¡ƒåœ’", "å°ä¸­", "å°å—", "é«˜é›„", "æ–°ç«¹", "åŸºéš†",
                "é ç«¯å·¥ä½œ", "æ··åˆè¾¦å…¬", "å½ˆæ€§åœ°é»", "å…¨å°ç£", "å¤§å°åŒ—åœ°å€",
                "ç«¹ç§‘", "å—ç§‘", "ä¸­ç§‘", "å…§æ¹–ç§‘æŠ€åœ’å€", "ä¿¡ç¾©å€", "æ¾å±±å€",
                "æ¿æ©‹", "æ—å£", "æ·¡æ°´", "ä¸­å£¢", "æ–°ç«¹å¸‚", "æ–°ç«¹ç¸£"
            ],
            "companies": [
                "å°ç©é›»", "è¯ç™¼ç§‘", "é´»æµ·", "å»£é”", "è¯ç¢©", "å®ç¢", "ç ”è¯",
                "è¯é›»", "æ—¥æœˆå…‰", "ç·¯å‰µ", "ä»å¯¶", "å’Œç¢©", "è‹±æ¥­é”", "ç¥é”",
                "è¶¨å‹¢ç§‘æŠ€", "é›·è™ç§‘æŠ€", "å‰µæ„é›»å­", "è¯è© ç§‘æŠ€", "ç‘æ˜±åŠå°é«”",
                "Google", "Microsoft", "Apple", "Amazon", "Meta", "Netflix",
                "Uber", "Airbnb", "Spotify", "Tesla", "NVIDIA", "Intel"
            ],
            "industries": [
                "ç§‘æŠ€æ¥­", "é‡‘èæ¥­", "è£½é€ æ¥­", "é›¶å”®æ¥­", "é†«ç™‚ä¿å¥", "æ•™è‚²",
                "åª’é«”å¨›æ¨‚", "é›»å•†", "éŠæˆ²", "æ–°å‰µ", "é¡§å•", "æ”¿åºœæ©Ÿé—œ",
                "éç‡Ÿåˆ©çµ„ç¹”", "ç”ŸæŠ€é†«è—¥", "èƒ½æº", "äº¤é€šé‹è¼¸", "æˆ¿åœ°ç”¢",
                "é£Ÿå“é£²æ–™", "æ™‚å°šæœé£¾", "æ—…éŠè§€å…‰", "é›»ä¿¡", "åŠå°é«”"
            ],
            "salary_ranges": [
                "30-50è¬", "50-80è¬", "80-120è¬", "120-200è¬", "200è¬ä»¥ä¸Š",
                "é¢è­°", "ä¾ç¶“é©—é¢è­°", "å…·ç«¶çˆ­åŠ›", "å„ªæ–¼å¸‚å ´è¡Œæƒ…", "è‚¡ç¥¨é¸æ“‡æ¬Š"
            ],
            "experience_levels": [
                "æ–°é®®äºº", "1-3å¹´", "3-5å¹´", "5-8å¹´", "8å¹´ä»¥ä¸Š", "è³‡æ·±",
                "ä¸»ç®¡ç´š", "ç¸½ç›£ç´š", "VPç´š", "C-level", "å¯¦ç¿’ç”Ÿ", "å…¼è·"
            ]
        }
    
    def _load_language_patterns(self) -> Dict[str, Dict[str, List[str]]]:
        """è¼‰å…¥èªè¨€æ¨¡å¼"""
        return {
            "zh-TW": {
                "question_starters": ["æˆ‘æƒ³æ‰¾", "è«‹å¹«æˆ‘æ‰¾", "æœ‰æ²’æœ‰", "å“ªè£¡æœ‰", "æ¨è–¦", "å°‹æ‰¾"],
                "connectors": ["çš„", "åœ¨", "æ–¼", "ä½æ–¼", "é—œæ–¼", "ç›¸é—œçš„"],
                "modifiers": ["å„ªç§€çš„", "è³‡æ·±çš„", "æœ‰ç¶“é©—çš„", "å°ˆæ¥­çš„", "é ‚å°–çš„", "æ–°æ‰‹"],
                "endings": ["å·¥ä½œ", "è·ä½", "æ©Ÿæœƒ", "è·ç¼º", "å´—ä½", "å·¥ä½œæ©Ÿæœƒ"]
            },
            "zh-CN": {
                "question_starters": ["æˆ‘æƒ³æ‰¾", "è¯·å¸®æˆ‘æ‰¾", "æœ‰æ²¡æœ‰", "å“ªé‡Œæœ‰", "æ¨è", "å¯»æ‰¾"],
                "connectors": ["çš„", "åœ¨", "äº", "ä½äº", "å…³äº", "ç›¸å…³çš„"],
                "modifiers": ["ä¼˜ç§€çš„", "èµ„æ·±çš„", "æœ‰ç»éªŒçš„", "ä¸“ä¸šçš„", "é¡¶å°–çš„", "æ–°æ‰‹"],
                "endings": ["å·¥ä½œ", "èŒä½", "æœºä¼š", "èŒç¼º", "å²—ä½", "å·¥ä½œæœºä¼š"]
            },
            "en-US": {
                "question_starters": ["I'm looking for", "Find me", "Are there any", "Where can I find", "Recommend", "Search for"],
                "connectors": ["in", "at", "for", "with", "related to", "involving"],
                "modifiers": ["excellent", "senior", "experienced", "professional", "top", "junior"],
                "endings": ["jobs", "positions", "opportunities", "roles", "careers", "openings"]
            },
            "ja-JP": {
                "question_starters": ["æ¢ã—ã¦ã„ã¾ã™", "è¦‹ã¤ã‘ã¦", "ã‚ã‚Šã¾ã™ã‹", "ã©ã“ã§", "ãŠã™ã™ã‚", "æ¤œç´¢"],
                "connectors": ["ã®", "ã§", "ã«", "ã«ãŠã‘ã‚‹", "é–¢é€£ã®", "ã«é–¢ã™ã‚‹"],
                "modifiers": ["å„ªç§€ãª", "ã‚·ãƒ‹ã‚¢", "çµŒé¨“è±Šå¯Œãª", "ãƒ—ãƒ­ã®", "ãƒˆãƒƒãƒ—", "ã‚¸ãƒ¥ãƒ‹ã‚¢"],
                "endings": ["ä»•äº‹", "ãƒã‚¸ã‚·ãƒ§ãƒ³", "æ©Ÿä¼š", "å½¹è·", "ã‚­ãƒ£ãƒªã‚¢", "æ±‚äºº"]
            },
            "ko-KR": {
                "question_starters": ["ì°¾ê³  ìˆìŠµë‹ˆë‹¤", "ì°¾ì•„ì£¼ì„¸ìš”", "ìˆë‚˜ìš”", "ì–´ë””ì„œ", "ì¶”ì²œ", "ê²€ìƒ‰"],
                "connectors": ["ì˜", "ì—ì„œ", "ì—", "ê´€ë ¨", "ì— ëŒ€í•œ", "ì™€ ê´€ë ¨ëœ"],
                "modifiers": ["ìš°ìˆ˜í•œ", "ì‹œë‹ˆì–´", "ê²½í—˜ìˆëŠ”", "ì „ë¬¸", "ìµœê³ ì˜", "ì£¼ë‹ˆì–´"],
                "endings": ["ì¼ìë¦¬", "í¬ì§€ì…˜", "ê¸°íšŒ", "ì—­í• ", "ì»¤ë¦¬ì–´", "ì±„ìš©"]
            }
        }
    
    def _load_complexity_factors(self) -> Dict[str, float]:
        """è¼‰å…¥è¤‡é›œåº¦å› å­"""
        return {
            "multiple_skills": 1.2,
            "multiple_locations": 1.1,
            "salary_negotiation": 1.3,
            "remote_hybrid": 1.2,
            "career_change": 1.4,
            "industry_specific": 1.1,
            "company_culture": 1.2,
            "work_life_balance": 1.1,
            "growth_opportunity": 1.2,
            "team_size": 1.1,
            "technology_stack": 1.3,
            "certification_required": 1.2,
            "language_requirement": 1.1,
            "travel_requirement": 1.1,
            "security_clearance": 1.4
        }
    
    def load_base_templates(self, templates_file: str = None) -> None:
        """è¼‰å…¥åŸºç¤æ¨¡æ¿"""
        if templates_file and Path(templates_file).exists():
            with open(templates_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                self.templates = [TestCaseTemplate(**template) for template in data]
        else:
            # å‰µå»ºé è¨­æ¨¡æ¿
            self._create_default_templates()
        
        print(f"ğŸ“š è¼‰å…¥äº† {len(self.templates)} å€‹åŸºç¤æ¨¡æ¿")
    
    def _create_default_templates(self) -> None:
        """å‰µå»ºé è¨­æ¨¡æ¿"""
        default_templates = [
            # åŸºç¤æœå°‹æ¨¡æ¿
            TestCaseTemplate(
                template_id="basic_001",
                category=TestCaseType.BASIC_SEARCH,
                difficulty=DifficultyLevel.EASY,
                template_text="æˆ‘æƒ³æ‰¾{job_title}çš„å·¥ä½œ",
                parameters=["job_title"],
                expected_intent="job_search",
                metadata={"requires_entities": ["job_title"]}
            ),
            TestCaseTemplate(
                template_id="basic_002",
                category=TestCaseType.BASIC_SEARCH,
                difficulty=DifficultyLevel.EASY,
                template_text="{location}æœ‰ä»€éº¼{job_title}è·ç¼º",
                parameters=["location", "job_title"],
                expected_intent="job_search",
                metadata={"requires_entities": ["location", "job_title"]}
            ),
            
            # æŠ€èƒ½å°å‘æ¨¡æ¿
            TestCaseTemplate(
                template_id="skill_001",
                category=TestCaseType.SKILL_FOCUSED,
                difficulty=DifficultyLevel.MEDIUM,
                template_text="éœ€è¦{skill1}å’Œ{skill2}æŠ€èƒ½çš„{job_title}å·¥ä½œ",
                parameters=["skill1", "skill2", "job_title"],
                expected_intent="job_search",
                metadata={"requires_entities": ["skills", "job_title"]}
            ),
            
            # è–ªè³‡å°å‘æ¨¡æ¿
            TestCaseTemplate(
                template_id="salary_001",
                category=TestCaseType.SALARY_FOCUSED,
                difficulty=DifficultyLevel.MEDIUM,
                template_text="å¹´è–ª{salary_range}çš„{job_title}è·ä½",
                parameters=["salary_range", "job_title"],
                expected_intent="job_search",
                metadata={"requires_entities": ["salary", "job_title"]}
            ),
            
            # é ç¨‹å·¥ä½œæ¨¡æ¿
            TestCaseTemplate(
                template_id="remote_001",
                category=TestCaseType.REMOTE_WORK,
                difficulty=DifficultyLevel.MEDIUM,
                template_text="é ç«¯å·¥ä½œçš„{job_title}æ©Ÿæœƒ",
                parameters=["job_title"],
                expected_intent="job_search",
                metadata={"requires_entities": ["job_title", "work_type"]}
            ),
            
            # è¤‡é›œå ´æ™¯æ¨¡æ¿
            TestCaseTemplate(
                template_id="complex_001",
                category=TestCaseType.COMPLEX_SCENARIO,
                difficulty=DifficultyLevel.HARD,
                template_text="æˆ‘æ˜¯{experience_level}ï¼Œæƒ³åœ¨{location}æ‰¾{job_title}å·¥ä½œï¼Œè¦æ±‚{skill1}ã€{skill2}æŠ€èƒ½ï¼Œå¹´è–ª{salary_range}",
                parameters=["experience_level", "location", "job_title", "skill1", "skill2", "salary_range"],
                expected_intent="job_search",
                metadata={"requires_entities": ["experience", "location", "job_title", "skills", "salary"]}
            ),
            
            # é‚Šç•Œæ¡ˆä¾‹æ¨¡æ¿
            TestCaseTemplate(
                template_id="edge_001",
                category=TestCaseType.EDGE_CASE,
                difficulty=DifficultyLevel.EXPERT,
                template_text="æ‰¾ä¸€å€‹ä¸å­˜åœ¨çš„è·ä½",
                parameters=[],
                expected_intent="invalid_query",
                metadata={"is_negative_case": True}
            ),
            
            # æ¨¡ç³ŠæŸ¥è©¢æ¨¡æ¿
            TestCaseTemplate(
                template_id="ambiguous_001",
                category=TestCaseType.AMBIGUOUS,
                difficulty=DifficultyLevel.HARD,
                template_text="æˆ‘æƒ³è¦ä¸€å€‹å¥½å·¥ä½œ",
                parameters=[],
                expected_intent="job_search",
                metadata={"ambiguity_level": "high"}
            )
        ]
        
        self.templates = default_templates
    
    def expand_test_cases(self, config: ExpansionConfig) -> List[ExpandedTestCase]:
        """æ“´å……æ¸¬è©¦æ¡ˆä¾‹"""
        print(f"ğŸš€ é–‹å§‹æ“´å……æ¸¬è©¦æ¡ˆä¾‹ï¼Œç›®æ¨™æ•¸é‡: {config.target_count}")
        
        self.expanded_cases = []
        self.generated_queries = set()
        
        # è¨ˆç®—æ¯å€‹é¡åˆ¥å’Œé›£åº¦çš„ç›®æ¨™æ•¸é‡
        category_targets = self._calculate_category_targets(config)
        difficulty_targets = self._calculate_difficulty_targets(config)
        
        # æŒ‰ç­–ç•¥æ“´å……
        for strategy in config.expansion_strategies:
            strategy_cases = self._expand_by_strategy(strategy, config, category_targets, difficulty_targets)
            self.expanded_cases.extend(strategy_cases)
            
            print(f"   âœ… {strategy.value} ç­–ç•¥ç”Ÿæˆäº† {len(strategy_cases)} å€‹æ¡ˆä¾‹")
        
        # å»é‡å’Œè³ªé‡æ§åˆ¶
        if config.ensure_diversity:
            self._ensure_diversity(config.max_similarity_threshold)
        
        # èª¿æ•´åˆ°ç›®æ¨™æ•¸é‡
        self._adjust_to_target_count(config.target_count)
        
        print(f"   ğŸ¯ æœ€çµ‚ç”Ÿæˆäº† {len(self.expanded_cases)} å€‹æ¸¬è©¦æ¡ˆä¾‹")
        return self.expanded_cases
    
    def _calculate_category_targets(self, config: ExpansionConfig) -> Dict[TestCaseType, int]:
        """è¨ˆç®—é¡åˆ¥ç›®æ¨™æ•¸é‡"""
        if not config.category_distribution:
            # å‡å‹»åˆ†ä½ˆ
            categories = list(TestCaseType)
            target_per_category = config.target_count // len(categories)
            return {cat: target_per_category for cat in categories}
        
        targets = {}
        for category, ratio in config.category_distribution.items():
            targets[category] = int(config.target_count * ratio)
        
        return targets
    
    def _calculate_difficulty_targets(self, config: ExpansionConfig) -> Dict[DifficultyLevel, int]:
        """è¨ˆç®—é›£åº¦ç›®æ¨™æ•¸é‡"""
        targets = {}
        for difficulty, ratio in config.difficulty_distribution.items():
            targets[difficulty] = int(config.target_count * ratio)
        
        return targets
    
    def _expand_by_strategy(self, strategy: ExpansionStrategy, config: ExpansionConfig,
                          category_targets: Dict[TestCaseType, int],
                          difficulty_targets: Dict[DifficultyLevel, int]) -> List[ExpandedTestCase]:
        """æŒ‰ç­–ç•¥æ“´å……"""
        cases = []
        
        if strategy == ExpansionStrategy.TEMPLATE_VARIATION:
            cases = self._expand_template_variation(config, category_targets)
        elif strategy == ExpansionStrategy.PARAMETER_COMBINATION:
            cases = self._expand_parameter_combination(config, category_targets)
        elif strategy == ExpansionStrategy.SEMANTIC_EXPANSION:
            cases = self._expand_semantic_expansion(config, category_targets)
        elif strategy == ExpansionStrategy.SYNTACTIC_VARIATION:
            cases = self._expand_syntactic_variation(config, category_targets)
        elif strategy == ExpansionStrategy.DOMAIN_TRANSFER:
            cases = self._expand_domain_transfer(config, category_targets)
        elif strategy == ExpansionStrategy.NOISE_INJECTION:
            cases = self._expand_noise_injection(config, category_targets)
        elif strategy == ExpansionStrategy.COMPLEXITY_SCALING:
            cases = self._expand_complexity_scaling(config, difficulty_targets)
        elif strategy == ExpansionStrategy.MULTILINGUAL_TRANSLATION:
            cases = self._expand_multilingual_translation(config)
        
        return cases
    
    def _expand_template_variation(self, config: ExpansionConfig,
                                 category_targets: Dict[TestCaseType, int]) -> List[ExpandedTestCase]:
        """æ¨¡æ¿è®ŠåŒ–æ“´å……"""
        cases = []
        
        for template in self.templates:
            target_count = category_targets.get(template.category, 10)
            
            for i in range(target_count):
                # å¡«å……åƒæ•¸
                filled_template = self._fill_template_parameters(template)
                
                if filled_template and filled_template not in self.generated_queries:
                    case = ExpandedTestCase(
                        test_case_id=str(uuid.uuid4()),
                        original_template_id=template.template_id,
                        expansion_strategy=ExpansionStrategy.TEMPLATE_VARIATION,
                        category=template.category,
                        difficulty=template.difficulty,
                        query=filled_template,
                        expected_intent=template.expected_intent,
                        expected_entities=self._extract_expected_entities(filled_template, template),
                        metadata=template.metadata.copy(),
                        complexity_score=self._calculate_complexity_score(filled_template, template)
                    )
                    
                    cases.append(case)
                    self.generated_queries.add(filled_template)
        
        return cases
    
    def _expand_parameter_combination(self, config: ExpansionConfig,
                                    category_targets: Dict[TestCaseType, int]) -> List[ExpandedTestCase]:
        """åƒæ•¸çµ„åˆæ“´å……"""
        cases = []
        
        for template in self.templates:
            if len(template.parameters) < 2:
                continue
            
            target_count = min(category_targets.get(template.category, 10), 50)
            
            # ç”Ÿæˆåƒæ•¸çµ„åˆ
            param_combinations = self._generate_parameter_combinations(template, target_count)
            
            for combination in param_combinations:
                filled_template = self._fill_template_with_combination(template, combination)
                
                if filled_template and filled_template not in self.generated_queries:
                    case = ExpandedTestCase(
                        test_case_id=str(uuid.uuid4()),
                        original_template_id=template.template_id,
                        expansion_strategy=ExpansionStrategy.PARAMETER_COMBINATION,
                        category=template.category,
                        difficulty=template.difficulty,
                        query=filled_template,
                        expected_intent=template.expected_intent,
                        expected_entities=combination,
                        metadata=template.metadata.copy(),
                        complexity_score=self._calculate_complexity_score(filled_template, template)
                    )
                    
                    cases.append(case)
                    self.generated_queries.add(filled_template)
        
        return cases
    
    def _expand_semantic_expansion(self, config: ExpansionConfig,
                                 category_targets: Dict[TestCaseType, int]) -> List[ExpandedTestCase]:
        """èªç¾©æ“´å±•"""
        cases = []
        
        # å‰µå»ºèªç¾©ç›¸ä¼¼çš„è®Šé«”
        semantic_variations = {
            "å·¥ä½œ": ["è·ä½", "è·ç¼º", "æ©Ÿæœƒ", "å´—ä½", "å·¥ä½œæ©Ÿæœƒ", "è·æ¥­"],
            "æ‰¾": ["å°‹æ‰¾", "æœå°‹", "æŸ¥æ‰¾", "ç‰©è‰²", "å°‹æ±‚", "æ¢ç´¢"],
            "éœ€è¦": ["è¦æ±‚", "å¿…é ˆ", "å¸Œæœ›", "æœŸæœ›", "æƒ³è¦", "æ¸´æœ›"],
            "ç¶“é©—": ["è³‡æ­·", "èƒŒæ™¯", "å±¥æ­·", "å·¥ä½œç¶“é©—", "å°ˆæ¥­ç¶“é©—", "å¯¦å‹™ç¶“é©—"]
        }
        
        for template in self.templates:
            target_count = category_targets.get(template.category, 5)
            
            for i in range(target_count):
                # æ‡‰ç”¨èªç¾©è®ŠåŒ–
                varied_template = self._apply_semantic_variations(template.template_text, semantic_variations)
                filled_template = self._fill_template_parameters_from_text(varied_template, template)
                
                if filled_template and filled_template not in self.generated_queries:
                    case = ExpandedTestCase(
                        test_case_id=str(uuid.uuid4()),
                        original_template_id=template.template_id,
                        expansion_strategy=ExpansionStrategy.SEMANTIC_EXPANSION,
                        category=template.category,
                        difficulty=template.difficulty,
                        query=filled_template,
                        expected_intent=template.expected_intent,
                        expected_entities=self._extract_expected_entities(filled_template, template),
                        metadata=template.metadata.copy(),
                        complexity_score=self._calculate_complexity_score(filled_template, template)
                    )
                    
                    cases.append(case)
                    self.generated_queries.add(filled_template)
        
        return cases
    
    def _expand_syntactic_variation(self, config: ExpansionConfig,
                                  category_targets: Dict[TestCaseType, int]) -> List[ExpandedTestCase]:
        """èªæ³•è®ŠåŒ–æ“´å……"""
        cases = []
        
        syntactic_patterns = [
            lambda x: f"è«‹å¹«æˆ‘{x}",
            lambda x: f"æˆ‘æƒ³è¦{x}",
            lambda x: f"èƒ½å¦æ¨è–¦{x}",
            lambda x: f"æœ‰æ²’æœ‰{x}",
            lambda x: f"å“ªè£¡å¯ä»¥æ‰¾åˆ°{x}",
            lambda x: f"æˆ‘æ­£åœ¨å°‹æ‰¾{x}"
        ]
        
        for template in self.templates:
            target_count = category_targets.get(template.category, 3)
            
            for pattern in syntactic_patterns[:target_count]:
                # æå–æ ¸å¿ƒå…§å®¹
                core_content = self._extract_core_content(template.template_text)
                varied_query = pattern(core_content)
                filled_template = self._fill_template_parameters_from_text(varied_query, template)
                
                if filled_template and filled_template not in self.generated_queries:
                    case = ExpandedTestCase(
                        test_case_id=str(uuid.uuid4()),
                        original_template_id=template.template_id,
                        expansion_strategy=ExpansionStrategy.SYNTACTIC_VARIATION,
                        category=template.category,
                        difficulty=template.difficulty,
                        query=filled_template,
                        expected_intent=template.expected_intent,
                        expected_entities=self._extract_expected_entities(filled_template, template),
                        metadata=template.metadata.copy(),
                        complexity_score=self._calculate_complexity_score(filled_template, template)
                    )
                    
                    cases.append(case)
                    self.generated_queries.add(filled_template)
        
        return cases
    
    def _expand_domain_transfer(self, config: ExpansionConfig,
                              category_targets: Dict[TestCaseType, int]) -> List[ExpandedTestCase]:
        """é ˜åŸŸé·ç§»æ“´å……"""
        cases = []
        
        # è·¨è¡Œæ¥­é·ç§»
        industry_mappings = {
            "è»Ÿé«”å·¥ç¨‹å¸«": ["éŠæˆ²é–‹ç™¼è€…", "å€å¡Šéˆé–‹ç™¼è€…", "AIå·¥ç¨‹å¸«"],
            "ç”¢å“ç¶“ç†": ["å°ˆæ¡ˆç¶“ç†", "ç‡Ÿé‹ç¶“ç†", "ç­–ç•¥ç¶“ç†"],
            "è¨­è¨ˆå¸«": ["UIè¨­è¨ˆå¸«", "UXè¨­è¨ˆå¸«", "è¦–è¦ºè¨­è¨ˆå¸«"]
        }
        
        for template in self.templates:
            if template.category in [TestCaseType.BASIC_SEARCH, TestCaseType.SKILL_FOCUSED]:
                target_count = category_targets.get(TestCaseType.INDUSTRY_SPECIFIC, 5)
                
                for i in range(target_count):
                    # æ‡‰ç”¨é ˜åŸŸé·ç§»
                    transferred_template = self._apply_domain_transfer(template, industry_mappings)
                    
                    if transferred_template and transferred_template not in self.generated_queries:
                        case = ExpandedTestCase(
                            test_case_id=str(uuid.uuid4()),
                            original_template_id=template.template_id,
                            expansion_strategy=ExpansionStrategy.DOMAIN_TRANSFER,
                            category=TestCaseType.INDUSTRY_SPECIFIC,
                            difficulty=template.difficulty,
                            query=transferred_template,
                            expected_intent=template.expected_intent,
                            expected_entities=self._extract_expected_entities(transferred_template, template),
                            metadata=template.metadata.copy(),
                            complexity_score=self._calculate_complexity_score(transferred_template, template)
                        )
                        
                        cases.append(case)
                        self.generated_queries.add(transferred_template)
        
        return cases
    
    def _expand_noise_injection(self, config: ExpansionConfig,
                              category_targets: Dict[TestCaseType, int]) -> List[ExpandedTestCase]:
        """å™ªè²æ³¨å…¥æ“´å……"""
        cases = []
        
        noise_types = [
            "typos",  # æ‹¼å¯«éŒ¯èª¤
            "extra_words",  # å¤šé¤˜è©èª
            "informal_language",  # éæ­£å¼èªè¨€
            "abbreviations",  # ç¸®å¯«
            "punctuation_errors"  # æ¨™é»éŒ¯èª¤
        ]
        
        for template in self.templates:
            target_count = category_targets.get(TestCaseType.EDGE_CASE, 2)
            
            for noise_type in noise_types[:target_count]:
                noisy_template = self._inject_noise(template, noise_type)
                
                if noisy_template and noisy_template not in self.generated_queries:
                    case = ExpandedTestCase(
                        test_case_id=str(uuid.uuid4()),
                        original_template_id=template.template_id,
                        expansion_strategy=ExpansionStrategy.NOISE_INJECTION,
                        category=TestCaseType.EDGE_CASE,
                        difficulty=DifficultyLevel.HARD,
                        query=noisy_template,
                        expected_intent=template.expected_intent,
                        expected_entities=self._extract_expected_entities(noisy_template, template),
                        metadata={**template.metadata, "noise_type": noise_type},
                        complexity_score=self._calculate_complexity_score(noisy_template, template) * 1.3
                    )
                    
                    cases.append(case)
                    self.generated_queries.add(noisy_template)
        
        return cases
    
    def _expand_complexity_scaling(self, config: ExpansionConfig,
                                 difficulty_targets: Dict[DifficultyLevel, int]) -> List[ExpandedTestCase]:
        """è¤‡é›œåº¦ç¸®æ”¾æ“´å……"""
        cases = []
        
        for target_difficulty, target_count in difficulty_targets.items():
            if target_difficulty in [DifficultyLevel.EXPERT, DifficultyLevel.EXTREME]:
                # ç”Ÿæˆé«˜è¤‡é›œåº¦æ¡ˆä¾‹
                complex_cases = self._generate_complex_cases(target_difficulty, target_count)
                cases.extend(complex_cases)
        
        return cases
    
    def _expand_multilingual_translation(self, config: ExpansionConfig) -> List[ExpandedTestCase]:
        """å¤šèªè¨€ç¿»è­¯æ“´å……"""
        cases = []
        
        for language, ratio in config.language_distribution.items():
            if language == "zh-TW":
                continue  # è·³éåŸå§‹èªè¨€
            
            target_count = int(config.target_count * ratio * 0.1)  # é™åˆ¶å¤šèªè¨€æ¡ˆä¾‹æ•¸é‡
            
            for template in self.templates[:target_count]:
                translated_query = self._translate_template(template, language)
                
                if translated_query and translated_query not in self.generated_queries:
                    case = ExpandedTestCase(
                        test_case_id=str(uuid.uuid4()),
                        original_template_id=template.template_id,
                        expansion_strategy=ExpansionStrategy.MULTILINGUAL_TRANSLATION,
                        category=TestCaseType.MULTILINGUAL,
                        difficulty=template.difficulty,
                        query=translated_query,
                        expected_intent=template.expected_intent,
                        expected_entities=self._extract_expected_entities(translated_query, template),
                        metadata={**template.metadata, "original_language": "zh-TW"},
                        language=language,
                        complexity_score=self._calculate_complexity_score(translated_query, template)
                    )
                    
                    cases.append(case)
                    self.generated_queries.add(translated_query)
        
        return cases
    
    def _fill_template_parameters(self, template: TestCaseTemplate) -> str:
        """å¡«å……æ¨¡æ¿åƒæ•¸"""
        text = template.template_text
        
        for param in template.parameters:
            if param in self.entity_pools:
                value = random.choice(self.entity_pools[param])
                text = text.replace(f"{{{param}}}", value)
            elif param.endswith("1") or param.endswith("2"):
                # è™•ç†ç·¨è™Ÿåƒæ•¸
                base_param = param[:-1]
                if base_param in self.entity_pools:
                    value = random.choice(self.entity_pools[base_param])
                    text = text.replace(f"{{{param}}}", value)
        
        return text if "{" not in text else None
    
    def _generate_parameter_combinations(self, template: TestCaseTemplate, count: int) -> List[Dict[str, str]]:
        """ç”Ÿæˆåƒæ•¸çµ„åˆ"""
        combinations = []
        
        for _ in range(count):
            combination = {}
            for param in template.parameters:
                if param in self.entity_pools:
                    combination[param] = random.choice(self.entity_pools[param])
                elif param.endswith("1") or param.endswith("2"):
                    base_param = param[:-1]
                    if base_param in self.entity_pools:
                        combination[param] = random.choice(self.entity_pools[base_param])
            
            if combination:
                combinations.append(combination)
        
        return combinations
    
    def _fill_template_with_combination(self, template: TestCaseTemplate, combination: Dict[str, str]) -> str:
        """ç”¨çµ„åˆå¡«å……æ¨¡æ¿"""
        text = template.template_text
        
        for param, value in combination.items():
            text = text.replace(f"{{{param}}}", value)
        
        return text if "{" not in text else None
    
    def _apply_semantic_variations(self, text: str, variations: Dict[str, List[str]]) -> str:
        """æ‡‰ç”¨èªç¾©è®ŠåŒ–"""
        for original, alternatives in variations.items():
            if original in text:
                alternative = random.choice(alternatives)
                text = text.replace(original, alternative, 1)
        
        return text
    
    def _fill_template_parameters_from_text(self, text: str, template: TestCaseTemplate) -> str:
        """å¾æ–‡æœ¬å¡«å……æ¨¡æ¿åƒæ•¸"""
        for param in template.parameters:
            if f"{{{param}}}" in text:
                if param in self.entity_pools:
                    value = random.choice(self.entity_pools[param])
                    text = text.replace(f"{{{param}}}", value)
        
        return text if "{" not in text else text
    
    def _extract_core_content(self, template_text: str) -> str:
        """æå–æ ¸å¿ƒå…§å®¹"""
        # ç§»é™¤å¸¸è¦‹çš„èµ·å§‹è©
        core = template_text
        prefixes = ["æˆ‘æƒ³æ‰¾", "è«‹å¹«æˆ‘æ‰¾", "æœ‰æ²’æœ‰", "å“ªè£¡æœ‰"]
        
        for prefix in prefixes:
            if core.startswith(prefix):
                core = core[len(prefix):]
                break
        
        return core.strip()
    
    def _apply_domain_transfer(self, template: TestCaseTemplate, mappings: Dict[str, List[str]]) -> str:
        """æ‡‰ç”¨é ˜åŸŸé·ç§»"""
        text = self._fill_template_parameters(template)
        
        if not text:
            return None
        
        # æ›¿æ›è·ä½åç¨±
        for original, alternatives in mappings.items():
            if original in text:
                alternative = random.choice(alternatives)
                text = text.replace(original, alternative)
                break
        
        return text
    
    def _inject_noise(self, template: TestCaseTemplate, noise_type: str) -> str:
        """æ³¨å…¥å™ªè²"""
        text = self._fill_template_parameters(template)
        
        if not text:
            return None
        
        if noise_type == "typos":
            # éš¨æ©Ÿæ›¿æ›å­—ç¬¦
            if len(text) > 5:
                pos = random.randint(1, len(text) - 2)
                text = text[:pos] + random.choice("abcdefg") + text[pos + 1:]
        
        elif noise_type == "extra_words":
            # æ·»åŠ å¤šé¤˜è©èª
            extra_words = ["å‘ƒ", "å—¯", "é‚£å€‹", "å°±æ˜¯", "ç„¶å¾Œ"]
            word = random.choice(extra_words)
            pos = random.randint(0, len(text))
            text = text[:pos] + word + text[pos:]
        
        elif noise_type == "informal_language":
            # éæ­£å¼èªè¨€
            text = text.replace("å·¥ä½œ", "æ‰“å·¥")
            text = text.replace("è·ä½", "ä½å­")
        
        elif noise_type == "abbreviations":
            # ç¸®å¯«
            text = text.replace("è»Ÿé«”å·¥ç¨‹å¸«", "è»Ÿå·¥")
            text = text.replace("ç”¢å“ç¶“ç†", "PM")
        
        elif noise_type == "punctuation_errors":
            # æ¨™é»éŒ¯èª¤
            text = text.replace("ï¼Œ", "")
            text = text.replace("ã€‚", "")
        
        return text
    
    def _generate_complex_cases(self, difficulty: DifficultyLevel, count: int) -> List[ExpandedTestCase]:
        """ç”Ÿæˆè¤‡é›œæ¡ˆä¾‹"""
        cases = []
        
        complex_templates = [
            "æˆ‘æ˜¯{experience_level}çš„{job_title}ï¼Œæƒ³è½‰è·åˆ°{industry}ï¼Œéœ€è¦å­¸ç¿’{skill1}å’Œ{skill2}ï¼Œå¸Œæœ›åœ¨{location}æ‰¾åˆ°å¹´è–ª{salary_range}çš„{work_type}å·¥ä½œ",
            "å°‹æ‰¾{company}æˆ–é¡ä¼¼å…¬å¸çš„{job_title}è·ä½ï¼Œè¦æ±‚{skill1}ã€{skill2}ã€{skill3}æŠ€èƒ½ï¼Œ{experience_level}ç¶“é©—ï¼Œå¯æ¥å—{location}æˆ–é ç«¯å·¥ä½œ",
            "æˆ‘æƒ³æ‰¾ä¸€å€‹çµåˆ{skill1}å’Œ{skill2}çš„å‰µæ–°è·ä½ï¼Œæœ€å¥½æ˜¯åœ¨{industry}é ˜åŸŸçš„æ–°å‰µå…¬å¸ï¼Œåœ°é»ä¸é™ä½†å¸Œæœ›æœ‰å½ˆæ€§å·¥ä½œæ™‚é–“"
        ]
        
        for i in range(count):
            template_text = random.choice(complex_templates)
            
            # å¡«å……æ‰€æœ‰åƒæ•¸
            filled_text = template_text
            for param_type, values in self.entity_pools.items():
                pattern = f"{{{param_type}}}"
                if pattern in filled_text:
                    filled_text = filled_text.replace(pattern, random.choice(values))
                
                # è™•ç†ç·¨è™Ÿåƒæ•¸
                for i in range(1, 4):
                    pattern = f"{{{param_type}{i}}}"
                    if pattern in filled_text:
                        filled_text = filled_text.replace(pattern, random.choice(values))
            
            if filled_text and "{" not in filled_text and filled_text not in self.generated_queries:
                case = ExpandedTestCase(
                    test_case_id=str(uuid.uuid4()),
                    original_template_id="complex_generated",
                    expansion_strategy=ExpansionStrategy.COMPLEXITY_SCALING,
                    category=TestCaseType.COMPLEX_SCENARIO,
                    difficulty=difficulty,
                    query=filled_text,
                    expected_intent="job_search",
                    expected_entities=self._extract_entities_from_text(filled_text),
                    metadata={"complexity_level": difficulty.value},
                    complexity_score=0.8 if difficulty == DifficultyLevel.EXPERT else 0.9
                )
                
                cases.append(case)
                self.generated_queries.add(filled_text)
        
        return cases
    
    def _translate_template(self, template: TestCaseTemplate, target_language: str) -> str:
        """ç¿»è­¯æ¨¡æ¿"""
        if target_language not in self.language_patterns:
            return None
        
        patterns = self.language_patterns[target_language]
        
        # ç°¡åŒ–çš„ç¿»è­¯é‚è¼¯
        if target_language == "en-US":
            # è‹±æ–‡ç¿»è­¯
            starter = random.choice(patterns["question_starters"])
            job_title = random.choice(self.entity_pools["job_titles"])
            # ç°¡åŒ–ç¿»è­¯
            return f"{starter} {job_title} {random.choice(patterns['endings'])}"
        
        elif target_language == "ja-JP":
            # æ—¥æ–‡ç¿»è­¯
            starter = random.choice(patterns["question_starters"])
            job_title = random.choice(self.entity_pools["job_titles"])
            return f"{job_title}{random.choice(patterns['connectors'])}{random.choice(patterns['endings'])}{starter}"
        
        else:
            # å…¶ä»–èªè¨€ä½¿ç”¨ç›¸ä¼¼çµæ§‹
            filled_template = self._fill_template_parameters(template)
            return filled_template
    
    def _extract_expected_entities(self, query: str, template: TestCaseTemplate) -> Dict[str, Any]:
        """æå–é æœŸå¯¦é«”"""
        entities = {}
        
        # åŸºæ–¼æ¨¡æ¿å…ƒæ•¸æ“šæå–å¯¦é«”
        if "requires_entities" in template.metadata:
            for entity_type in template.metadata["requires_entities"]:
                entities[entity_type] = self._extract_entity_from_query(query, entity_type)
        
        return entities
    
    def _extract_entity_from_query(self, query: str, entity_type: str) -> List[str]:
        """å¾æŸ¥è©¢ä¸­æå–å¯¦é«”"""
        entities = []
        
        if entity_type in self.entity_pools:
            for entity in self.entity_pools[entity_type]:
                if entity in query:
                    entities.append(entity)
        
        return entities
    
    def _extract_entities_from_text(self, text: str) -> Dict[str, List[str]]:
        """å¾æ–‡æœ¬ä¸­æå–å¯¦é«”"""
        entities = {}
        
        for entity_type, entity_list in self.entity_pools.items():
            found_entities = []
            for entity in entity_list:
                if entity in text:
                    found_entities.append(entity)
            
            if found_entities:
                entities[entity_type] = found_entities
        
        return entities
    
    def _calculate_complexity_score(self, query: str, template: TestCaseTemplate) -> float:
        """è¨ˆç®—è¤‡é›œåº¦åˆ†æ•¸"""
        base_score = 0.5
        
        # åŸºæ–¼é›£åº¦ç­‰ç´š
        difficulty_scores = {
            DifficultyLevel.TRIVIAL: 0.1,
            DifficultyLevel.EASY: 0.3,
            DifficultyLevel.MEDIUM: 0.5,
            DifficultyLevel.HARD: 0.7,
            DifficultyLevel.EXPERT: 0.9,
            DifficultyLevel.EXTREME: 1.0
        }
        
        base_score = difficulty_scores.get(template.difficulty, 0.5)
        
        # åŸºæ–¼æŸ¥è©¢é•·åº¦
        length_factor = min(len(query) / 100, 0.3)
        
        # åŸºæ–¼å¯¦é«”æ•¸é‡
        entity_count = len(self._extract_entities_from_text(query))
        entity_factor = min(entity_count * 0.1, 0.2)
        
        # åŸºæ–¼è¤‡é›œåº¦å› å­
        complexity_factor = 0
        for factor, weight in self.complexity_factors.items():
            if any(keyword in query for keyword in factor.split("_")):
                complexity_factor += weight * 0.1
        
        total_score = base_score + length_factor + entity_factor + complexity_factor
        return min(total_score, 1.0)
    
    def _ensure_diversity(self, similarity_threshold: float) -> None:
        """ç¢ºä¿å¤šæ¨£æ€§"""
        print("ğŸ” ç¢ºä¿æ¸¬è©¦æ¡ˆä¾‹å¤šæ¨£æ€§...")
        
        # ç°¡åŒ–çš„ç›¸ä¼¼åº¦æª¢æŸ¥
        unique_cases = []
        seen_queries = set()
        
        for case in self.expanded_cases:
            # åŸºæœ¬å»é‡
            if case.query not in seen_queries:
                unique_cases.append(case)
                seen_queries.add(case.query)
        
        removed_count = len(self.expanded_cases) - len(unique_cases)
        self.expanded_cases = unique_cases
        
        if removed_count > 0:
            print(f"   ğŸ—‘ï¸ ç§»é™¤äº† {removed_count} å€‹é‡è¤‡æ¡ˆä¾‹")
    
    def _adjust_to_target_count(self, target_count: int) -> None:
        """èª¿æ•´åˆ°ç›®æ¨™æ•¸é‡"""
        current_count = len(self.expanded_cases)
        
        if current_count > target_count:
            # éš¨æ©Ÿæ¡æ¨£åˆ°ç›®æ¨™æ•¸é‡
            self.expanded_cases = random.sample(self.expanded_cases, target_count)
            print(f"   âœ‚ï¸ éš¨æ©Ÿæ¡æ¨£åˆ°ç›®æ¨™æ•¸é‡ {target_count}")
        
        elif current_count < target_count:
            # éœ€è¦ç”Ÿæˆæ›´å¤šæ¡ˆä¾‹
            needed = target_count - current_count
            additional_cases = self._generate_additional_cases(needed)
            self.expanded_cases.extend(additional_cases)
            print(f"   â• é¡å¤–ç”Ÿæˆäº† {len(additional_cases)} å€‹æ¡ˆä¾‹")
    
    def _generate_additional_cases(self, count: int) -> List[ExpandedTestCase]:
        """ç”Ÿæˆé¡å¤–æ¡ˆä¾‹"""
        additional_cases = []
        
        # ä½¿ç”¨ç°¡å–®æ¨¡æ¿å¿«é€Ÿç”Ÿæˆ
        simple_templates = [
            "æ‰¾{job_title}å·¥ä½œ",
            "{location}çš„{job_title}è·ä½",
            "éœ€è¦{skill1}æŠ€èƒ½çš„å·¥ä½œ",
            "å¹´è–ª{salary_range}çš„è·ä½"
        ]
        
        for i in range(count):
            template_text = random.choice(simple_templates)
            
            # å¡«å……åƒæ•¸
            filled_text = template_text
            for param_type, values in self.entity_pools.items():
                pattern = f"{{{param_type}}}"
                if pattern in filled_text:
                    filled_text = filled_text.replace(pattern, random.choice(values))
                
                # è™•ç†ç·¨è™Ÿåƒæ•¸
                for j in range(1, 4):
                    pattern = f"{{{param_type}{j}}}"
                    if pattern in filled_text:
                        filled_text = filled_text.replace(pattern, random.choice(values))
            
            if filled_text and "{" not in filled_text and filled_text not in self.generated_queries:
                case = ExpandedTestCase(
                    test_case_id=str(uuid.uuid4()),
                    original_template_id="additional_generated",
                    expansion_strategy=ExpansionStrategy.TEMPLATE_VARIATION,
                    category=TestCaseType.BASIC_SEARCH,
                    difficulty=DifficultyLevel.EASY,
                    query=filled_text,
                    expected_intent="job_search",
                    expected_entities=self._extract_entities_from_text(filled_text),
                    metadata={"generated_type": "additional"},
                    complexity_score=0.3
                )
                
                additional_cases.append(case)
                self.generated_queries.add(filled_text)
        
        return additional_cases
    
    def export_test_cases(self, output_file: str, format_type: str = "json") -> None:
        """å°å‡ºæ¸¬è©¦æ¡ˆä¾‹"""
        print(f"ğŸ’¾ å°å‡ºæ¸¬è©¦æ¡ˆä¾‹åˆ° {output_file}...")
        
        if format_type == "json":
            self._export_json(output_file)
        elif format_type == "csv":
            self._export_csv(output_file)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ ¼å¼: {format_type}")
        
        print(f"   âœ… æˆåŠŸå°å‡º {len(self.expanded_cases)} å€‹æ¸¬è©¦æ¡ˆä¾‹")
    
    def _export_json(self, output_file: str) -> None:
        """å°å‡ºJSONæ ¼å¼"""
        data = {
            "metadata": {
                "generation_time": datetime.now().isoformat(),
                "total_cases": len(self.expanded_cases),
                "expansion_strategies": list(set(case.expansion_strategy.value for case in self.expanded_cases)),
                "categories": list(set(case.category.value for case in self.expanded_cases)),
                "difficulties": list(set(case.difficulty.value for case in self.expanded_cases)),
                "languages": list(set(case.language for case in self.expanded_cases))
            },
            "test_cases": [
                {
                    "test_case_id": case.test_case_id,
                    "original_template_id": case.original_template_id,
                    "expansion_strategy": case.expansion_strategy.value,
                    "category": case.category.value,
                    "difficulty": case.difficulty.value,
                    "query": case.query,
                    "expected_intent": case.expected_intent,
                    "expected_entities": case.expected_entities,
                    "metadata": case.metadata,
                    "language": case.language,
                    "complexity_score": case.complexity_score,
                    "uniqueness_score": case.uniqueness_score
                }
                for case in self.expanded_cases
            ]
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    
    def _export_csv(self, output_file: str) -> None:
        """å°å‡ºCSVæ ¼å¼"""
        import csv
        
        with open(output_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            
            # å¯«å…¥æ¨™é¡Œ
            writer.writerow([
                'test_case_id', 'original_template_id', 'expansion_strategy',
                'category', 'difficulty', 'query', 'expected_intent',
                'language', 'complexity_score', 'uniqueness_score'
            ])
            
            # å¯«å…¥æ•¸æ“š
            for case in self.expanded_cases:
                writer.writerow([
                    case.test_case_id,
                    case.original_template_id,
                    case.expansion_strategy.value,
                    case.category.value,
                    case.difficulty.value,
                    case.query,
                    case.expected_intent,
                    case.language,
                    case.complexity_score,
                    case.uniqueness_score
                ])
    
    def get_expansion_statistics(self) -> Dict[str, Any]:
        """ç²å–æ“´å……çµ±è¨ˆ"""
        if not self.expanded_cases:
            return {}
        
        stats = {
            "total_cases": len(self.expanded_cases),
            "strategy_distribution": {},
            "category_distribution": {},
            "difficulty_distribution": {},
            "language_distribution": {},
            "complexity_stats": {
                "mean": sum(case.complexity_score for case in self.expanded_cases) / len(self.expanded_cases),
                "min": min(case.complexity_score for case in self.expanded_cases),
                "max": max(case.complexity_score for case in self.expanded_cases)
            }
        }
        
        # ç­–ç•¥åˆ†ä½ˆ
        for case in self.expanded_cases:
            strategy = case.expansion_strategy.value
            stats["strategy_distribution"][strategy] = stats["strategy_distribution"].get(strategy, 0) + 1
        
        # é¡åˆ¥åˆ†ä½ˆ
        for case in self.expanded_cases:
            category = case.category.value
            stats["category_distribution"][category] = stats["category_distribution"].get(category, 0) + 1
        
        # é›£åº¦åˆ†ä½ˆ
        for case in self.expanded_cases:
            difficulty = case.difficulty.value
            stats["difficulty_distribution"][difficulty] = stats["difficulty_distribution"].get(difficulty, 0) + 1
        
        # èªè¨€åˆ†ä½ˆ
        for case in self.expanded_cases:
            language = case.language
            stats["language_distribution"][language] = stats["language_distribution"].get(language, 0) + 1
        
        return stats
    
    def print_expansion_summary(self) -> None:
        """æ‰“å°æ“´å……æ‘˜è¦"""
        if not self.expanded_cases:
            print("âŒ æ²’æœ‰ç”Ÿæˆä»»ä½•æ¸¬è©¦æ¡ˆä¾‹")
            return
        
        stats = self.get_expansion_statistics()
        
        print("\n" + "="*60)
        print("ğŸ“Š LLMæ¸¬è©¦æ¡ˆä¾‹æ“´å……æ‘˜è¦")
        print("="*60)
        
        print(f"\nğŸ“ˆ ç¸½é«”çµ±è¨ˆ:")
        print(f"   ç¸½æ¡ˆä¾‹æ•¸: {stats['total_cases']}")
        print(f"   å¹³å‡è¤‡é›œåº¦: {stats['complexity_stats']['mean']:.2f}")
        print(f"   è¤‡é›œåº¦ç¯„åœ: {stats['complexity_stats']['min']:.2f} - {stats['complexity_stats']['max']:.2f}")
        
        print(f"\nğŸ”§ æ“´å……ç­–ç•¥åˆ†ä½ˆ:")
        for strategy, count in stats['strategy_distribution'].items():
            percentage = (count / stats['total_cases']) * 100
            print(f"   {strategy}: {count} ({percentage:.1f}%)")
        
        print(f"\nğŸ“‚ é¡åˆ¥åˆ†ä½ˆ:")
        for category, count in stats['category_distribution'].items():
            percentage = (count / stats['total_cases']) * 100
            print(f"   {category}: {count} ({percentage:.1f}%)")
        
        print(f"\nâš¡ é›£åº¦åˆ†ä½ˆ:")
        for difficulty, count in stats['difficulty_distribution'].items():
            percentage = (count / stats['total_cases']) * 100
            print(f"   {difficulty}: {count} ({percentage:.1f}%)")
        
        print(f"\nğŸŒ èªè¨€åˆ†ä½ˆ:")
        for language, count in stats['language_distribution'].items():
            percentage = (count / stats['total_cases']) * 100
            print(f"   {language}: {count} ({percentage:.1f}%)")
        
        print("\n" + "="*60)


def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ LLMæ¸¬è©¦æ¡ˆä¾‹æ“´å……å·¥å…·")
    print("è‡ªå‹•ç”Ÿæˆå¤§é‡å¤šæ¨£åŒ–çš„æ¸¬è©¦æ¡ˆä¾‹ï¼Œç”¨æ–¼æ¯”è¼ƒä¸åŒLLMæ¨¡å‹çš„è¼¸å‡ºè¡¨ç¾å·®ç•°\n")
    
    # å‰µå»ºæ“´å……å™¨
    expander = LLMTestCaseExpander()
    
    # è¼‰å…¥åŸºç¤æ¨¡æ¿
    print("ğŸ“š è¼‰å…¥åŸºç¤æ¨¡æ¿...")
    expander.load_base_templates()
    
    # é…ç½®é¸é …
    print("\nâš™ï¸ é…ç½®æ“´å……åƒæ•¸:")
    
    # ç›®æ¨™æ•¸é‡
    while True:
        try:
            target_count = int(input("è«‹è¼¸å…¥ç›®æ¨™æ¸¬è©¦æ¡ˆä¾‹æ•¸é‡ (å»ºè­°1000-5000): ") or "2000")
            if target_count > 0:
                break
            else:
                print("âŒ è«‹è¼¸å…¥æ­£æ•¸")
        except ValueError:
            print("âŒ è«‹è¼¸å…¥æœ‰æ•ˆæ•¸å­—")
    
    # æ“´å……ç­–ç•¥é¸æ“‡
    print("\nğŸ”§ é¸æ“‡æ“´å……ç­–ç•¥ (å¤šé¸ï¼Œç”¨é€—è™Ÿåˆ†éš”):")
    strategies = list(ExpansionStrategy)
    for i, strategy in enumerate(strategies, 1):
        print(f"   {i}. {strategy.value}")
    
    strategy_input = input("è«‹é¸æ“‡ç­–ç•¥ç·¨è™Ÿ (é è¨­å…¨é¸): ") or ",".join(str(i) for i in range(1, len(strategies) + 1))
    
    try:
        selected_indices = [int(x.strip()) - 1 for x in strategy_input.split(",")]
        selected_strategies = [strategies[i] for i in selected_indices if 0 <= i < len(strategies)]
    except:
        selected_strategies = strategies
    
    # èªè¨€åˆ†ä½ˆ
    print("\nğŸŒ èªè¨€åˆ†ä½ˆé…ç½®:")
    print("1. ä»¥ä¸­æ–‡ç‚ºä¸» (ä¸­æ–‡70%, è‹±æ–‡20%, å…¶ä»–10%)")
    print("2. å¤šèªè¨€å¹³è¡¡ (ä¸­æ–‡40%, è‹±æ–‡30%, å…¶ä»–30%)")
    print("3. è‹±æ–‡ç‚ºä¸» (è‹±æ–‡60%, ä¸­æ–‡30%, å…¶ä»–10%)")
    
    lang_choice = input("è«‹é¸æ“‡èªè¨€åˆ†ä½ˆ (é è¨­1): ") or "1"
    
    if lang_choice == "2":
        language_distribution = {
            "zh-TW": 0.4, "en-US": 0.3, "zh-CN": 0.15, "ja-JP": 0.1, "ko-KR": 0.05
        }
    elif lang_choice == "3":
        language_distribution = {
            "en-US": 0.6, "zh-TW": 0.3, "zh-CN": 0.05, "ja-JP": 0.03, "ko-KR": 0.02
        }
    else:
        language_distribution = {
            "zh-TW": 0.7, "en-US": 0.2, "zh-CN": 0.05, "ja-JP": 0.03, "ko-KR": 0.02
        }
    
    # å‰µå»ºé…ç½®
    config = ExpansionConfig(
        target_count=target_count,
        expansion_strategies=selected_strategies,
        language_distribution=language_distribution,
        ensure_diversity=True,
        max_similarity_threshold=0.8
    )
    
    # åŸ·è¡Œæ“´å……
    print(f"\nğŸ”„ é–‹å§‹æ“´å……æ¸¬è©¦æ¡ˆä¾‹...")
    expanded_cases = expander.expand_test_cases(config)
    
    # é¡¯ç¤ºæ‘˜è¦
    expander.print_expansion_summary()
    
    # å°å‡ºé¸é …
    print("\nğŸ’¾ å°å‡ºé¸é …:")
    export_choice = input("æ˜¯å¦å°å‡ºæ¸¬è©¦æ¡ˆä¾‹? (y/n, é è¨­y): ") or "y"
    
    if export_choice.lower() == 'y':
        # é¸æ“‡æ ¼å¼
        print("\nğŸ“„ é¸æ“‡å°å‡ºæ ¼å¼:")
        print("1. JSON (æ¨è–¦)")
        print("2. CSV")
        
        format_choice = input("è«‹é¸æ“‡æ ¼å¼ (é è¨­1): ") or "1"
        format_type = "json" if format_choice == "1" else "csv"
        
        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = f"expanded_test_cases_{timestamp}.{format_type}"
        
        # å°å‡º
        expander.export_test_cases(output_file, format_type)
        
        print(f"\nâœ… æ¸¬è©¦æ¡ˆä¾‹å·²å°å‡ºåˆ°: {output_file}")
    
    # ç”Ÿæˆå°æ¯”å ±å‘Šé¸é …
    print("\nğŸ“Š ç”Ÿæˆå°æ¯”åˆ†æå ±å‘Š:")
    report_choice = input("æ˜¯å¦ç”Ÿæˆæ¸¬è©¦æ¡ˆä¾‹åˆ†æå ±å‘Š? (y/n, é è¨­n): ") or "n"
    
    if report_choice.lower() == 'y':
        # ç”Ÿæˆåˆ†æå ±å‘Š
        analysis_report = {
            "generation_summary": {
                "timestamp": datetime.now().isoformat(),
                "total_cases": len(expanded_cases),
                "target_count": target_count,
                "success_rate": len(expanded_cases) / target_count if target_count > 0 else 0
            },
            "statistics": expander.get_expansion_statistics(),
            "recommendations": {
                "model_comparison_focus": [
                    "é‡é»æ¸¬è©¦è¤‡é›œåº¦è¼ƒé«˜çš„æ¡ˆä¾‹ (complexity_score > 0.7)",
                    "æ¯”è¼ƒä¸åŒèªè¨€ä¸‹çš„æ¨¡å‹è¡¨ç¾å·®ç•°",
                    "é—œæ³¨é‚Šç•Œæ¡ˆä¾‹å’Œå°æŠ—æ€§æ¸¬è©¦çš„è™•ç†èƒ½åŠ›",
                    "è©•ä¼°æ¨¡å‹åœ¨å¤šæŠ€èƒ½çµ„åˆæŸ¥è©¢ä¸Šçš„ç†è§£èƒ½åŠ›"
                ],
                "testing_strategy": [
                    "æŒ‰é›£åº¦ç­‰ç´šåˆ†æ‰¹æ¸¬è©¦ï¼Œå¾ç°¡å–®åˆ°è¤‡é›œ",
                    "ä½¿ç”¨ç›¸åŒæŸ¥è©¢çš„ä¸åŒèªè¨€ç‰ˆæœ¬é€²è¡Œè·¨èªè¨€å°æ¯”",
                    "é‡é»é—œæ³¨æ„åœ–è­˜åˆ¥å’Œå¯¦é«”æå–çš„æº–ç¢ºæ€§",
                    "è¨˜éŒ„æ¨¡å‹åœ¨è™•ç†æ¨¡ç³ŠæŸ¥è©¢æ™‚çš„è¡¨ç¾å·®ç•°"
                ]
            }
        }
        
        report_file = f"test_case_analysis_report_{timestamp}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(analysis_report, f, ensure_ascii=False, indent=2)
        
        print(f"   ğŸ“‹ åˆ†æå ±å‘Šå·²ç”Ÿæˆ: {report_file}")
    
    print("\nğŸ‰ æ¸¬è©¦æ¡ˆä¾‹æ“´å……å®Œæˆ!")
    print("\nğŸ’¡ ä½¿ç”¨å»ºè­°:")
    print("   1. å°‡ç”Ÿæˆçš„æ¸¬è©¦æ¡ˆä¾‹å°å…¥åˆ°LLMæ¸¬è©¦åŸ·è¡Œå¼•æ“")
    print("   2. ä½¿ç”¨ä¸åŒçš„LLMæ¨¡å‹é‹è¡Œç›¸åŒçš„æ¸¬è©¦æ¡ˆä¾‹")
    print("   3. æ¯”è¼ƒå„æ¨¡å‹åœ¨ä¸åŒé¡åˆ¥å’Œé›£åº¦ä¸Šçš„è¡¨ç¾")
    print("   4. é‡é»é—œæ³¨è¤‡é›œåº¦é«˜å’Œé‚Šç•Œæ¡ˆä¾‹çš„è™•ç†å·®ç•°")
    print("   5. åˆ†æå¤šèªè¨€æ¸¬è©¦æ¡ˆä¾‹çš„è·¨èªè¨€ç†è§£èƒ½åŠ›")


if __name__ == "__main__":
    main()