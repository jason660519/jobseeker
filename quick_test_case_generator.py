#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿæ¸¬è©¦æ¡ˆä¾‹ç”Ÿæˆå™¨
å°ˆé–€ç”¨æ–¼å¿«é€Ÿç”Ÿæˆå¤šæ¨£åŒ–çš„LLMæ¸¬è©¦æ¡ˆä¾‹ï¼Œæ”¯æ´å¤šç¨®å ´æ™¯å’Œè¤‡é›œåº¦

Author: JobSpy Team
Date: 2025-01-27
"""

import json
import random
import uuid
from datetime import datetime
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
import itertools


class TestCategory(Enum):
    """æ¸¬è©¦é¡åˆ¥"""
    JOB_SEARCH = "job_search"  # æ±‚è·æœå°‹
    SKILL_QUERY = "skill_query"  # æŠ€èƒ½æŸ¥è©¢
    LOCATION_SEARCH = "location_search"  # åœ°é»æœå°‹
    SALARY_INQUIRY = "salary_inquiry"  # è–ªè³‡æŸ¥è©¢
    CAREER_ADVICE = "career_advice"  # è·æ¶¯å»ºè­°
    COMPANY_INFO = "company_info"  # å…¬å¸è³‡è¨Š
    INTERVIEW_PREP = "interview_prep"  # é¢è©¦æº–å‚™
    RESUME_HELP = "resume_help"  # å±¥æ­·å”åŠ©
    GENERAL_CHAT = "general_chat"  # ä¸€èˆ¬å°è©±
    EDGE_CASE = "edge_case"  # é‚Šç•Œæ¡ˆä¾‹


class ComplexityLevel(Enum):
    """è¤‡é›œåº¦ç­‰ç´š"""
    SIMPLE = "simple"  # ç°¡å–®
    MODERATE = "moderate"  # ä¸­ç­‰
    COMPLEX = "complex"  # è¤‡é›œ
    EXTREME = "extreme"  # æ¥µç«¯


class LanguageCode(Enum):
    """èªè¨€ä»£ç¢¼"""
    ZH_TW = "zh-TW"  # ç¹é«”ä¸­æ–‡
    ZH_CN = "zh-CN"  # ç°¡é«”ä¸­æ–‡
    EN_US = "en-US"  # ç¾å¼è‹±æ–‡
    JA_JP = "ja-JP"  # æ—¥æ–‡
    KO_KR = "ko-KR"  # éŸ“æ–‡


@dataclass
class TestCase:
    """æ¸¬è©¦æ¡ˆä¾‹"""
    test_id: str
    query: str
    category: TestCategory
    complexity: ComplexityLevel
    language: LanguageCode
    expected_intent: str
    expected_entities: Dict[str, Any]
    context: Optional[str] = None
    metadata: Dict[str, Any] = field(default_factory=dict)
    created_at: datetime = field(default_factory=datetime.now)


@dataclass
class GenerationConfig:
    """ç”Ÿæˆé…ç½®"""
    total_cases: int = 1000
    category_distribution: Dict[TestCategory, float] = field(default_factory=dict)
    complexity_distribution: Dict[ComplexityLevel, float] = field(default_factory=dict)
    language_distribution: Dict[LanguageCode, float] = field(default_factory=dict)
    include_edge_cases: bool = True
    edge_case_ratio: float = 0.1
    ensure_diversity: bool = True
    max_similarity_threshold: float = 0.8


class QuickTestCaseGenerator:
    """å¿«é€Ÿæ¸¬è©¦æ¡ˆä¾‹ç”Ÿæˆå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç”Ÿæˆå™¨"""
        self.templates = self._load_templates()
        self.entities = self._load_entities()
        self.generated_cases = []
        self.generation_stats = {}
    
    def _load_templates(self) -> Dict[TestCategory, Dict[ComplexityLevel, List[str]]]:
        """è¼‰å…¥æ¸¬è©¦æ¡ˆä¾‹æ¨¡æ¿"""
        templates = {
            TestCategory.JOB_SEARCH: {
                ComplexityLevel.SIMPLE: [
                    "æˆ‘æƒ³æ‰¾{job_title}çš„å·¥ä½œ",
                    "æœ‰{job_title}çš„è·ç¼ºå—",
                    "å¹«æˆ‘æœå°‹{job_title}å·¥ä½œ",
                    "æ‰¾{location}çš„{job_title}å·¥ä½œ",
                    "æˆ‘è¦æ‡‰å¾µ{job_title}"
                ],
                ComplexityLevel.MODERATE: [
                    "æˆ‘æƒ³åœ¨{location}æ‰¾{job_title}çš„å·¥ä½œï¼Œè–ªæ°´è¦{salary_range}",
                    "æœ‰æ²’æœ‰{company_type}å…¬å¸çš„{job_title}è·ç¼º",
                    "æˆ‘æœ‰{experience_years}å¹´{skill}ç¶“é©—ï¼Œæƒ³æ‰¾{job_title}å·¥ä½œ",
                    "å°‹æ‰¾{work_type}çš„{job_title}è·ä½ï¼Œåœ°é»åœ¨{location}",
                    "æˆ‘æƒ³è½‰è·åˆ°{job_title}ï¼Œéœ€è¦ä»€éº¼æ¢ä»¶"
                ],
                ComplexityLevel.COMPLEX: [
                    "æˆ‘ç›®å‰æ˜¯{current_job}ï¼Œæƒ³è½‰è·åˆ°{target_job}ï¼Œæœ‰{experience_years}å¹´ç¶“é©—ï¼Œå¸Œæœ›åœ¨{location}æ‰¾åˆ°è–ªæ°´{salary_range}çš„{work_type}å·¥ä½œ",
                    "å°‹æ‰¾{location}åœ°å€çš„{job_title}è·ä½ï¼Œè¦æ±‚{skill_list}æŠ€èƒ½ï¼Œå…¬å¸è¦æ¨¡{company_size}ï¼Œè–ªè³‡ç¯„åœ{salary_range}",
                    "æˆ‘æ˜¯{education_level}ç•¢æ¥­ï¼Œä¸»ä¿®{major}ï¼Œæœ‰{experience_years}å¹´{industry}ç¶“é©—ï¼Œæƒ³åœ¨{location}æ‰¾{job_title}å·¥ä½œ",
                    "å¸Œæœ›æ‰¾åˆ°{company_type}çš„{job_title}è·ä½ï¼Œå·¥ä½œåœ°é»{location}ï¼Œè–ªæ°´{salary_range}ï¼Œå·¥ä½œå‹æ…‹{work_type}"
                ],
                ComplexityLevel.EXTREME: [
                    "æˆ‘æ˜¯{education_level}{major}ç•¢æ¥­ï¼Œç›®å‰åœ¨{current_company}æ“”ä»»{current_job}å·²{experience_years}å¹´ï¼Œå°ˆç²¾{skill_list}ï¼Œå› ç‚º{reason}æƒ³è½‰è·åˆ°{target_industry}çš„{target_job}ï¼Œå¸Œæœ›åœ¨{location}æ‰¾åˆ°{company_type}å…¬å¸ï¼Œè–ªè³‡{salary_range}ï¼Œå·¥ä½œå‹æ…‹{work_type}ï¼Œæœ‰{benefit_list}ç¦åˆ©",
                    "å°‹æ‰¾ç¬¦åˆä»¥ä¸‹æ¢ä»¶çš„å·¥ä½œï¼šè·ä½{job_title}ï¼Œåœ°é»{location}ï¼Œè–ªè³‡{salary_range}ï¼Œå…¬å¸{company_type}ï¼Œè¦æ¨¡{company_size}ï¼Œå·¥ä½œå‹æ…‹{work_type}ï¼Œéœ€è¦{skill_list}æŠ€èƒ½ï¼Œ{experience_years}å¹´ä»¥ä¸Šç¶“é©—ï¼Œæä¾›{benefit_list}ç¦åˆ©"
                ]
            },
            TestCategory.SKILL_QUERY: {
                ComplexityLevel.SIMPLE: [
                    "{skill}æ˜¯ä»€éº¼",
                    "æˆ‘éœ€è¦å­¸{skill}å—",
                    "{skill}æ€éº¼å­¸",
                    "{skill}æœ‰ç”¨å—",
                    "å­¸{skill}è¦å¤šä¹…"
                ],
                ComplexityLevel.MODERATE: [
                    "å­¸{skill}å°{job_title}æœ‰å¹«åŠ©å—",
                    "{skill}å’Œ{skill2}å“ªå€‹æ¯”è¼ƒé‡è¦",
                    "æˆ‘æƒ³å­¸{skill}ï¼Œæœ‰æ¨è–¦çš„èª²ç¨‹å—",
                    "{job_title}éœ€è¦ä»€éº¼æŠ€èƒ½",
                    "å¦‚ä½•æå‡{skill}èƒ½åŠ›"
                ],
                ComplexityLevel.COMPLEX: [
                    "æˆ‘æƒ³å¾{current_job}è½‰è·åˆ°{target_job}ï¼Œéœ€è¦å­¸ç¿’å“ªäº›{skill_category}æŠ€èƒ½",
                    "åœ¨{industry}å·¥ä½œï¼Œ{skill_list}é€™äº›æŠ€èƒ½çš„é‡è¦æ€§æ’åºæ˜¯ä»€éº¼",
                    "æˆ‘æœ‰{experience_years}å¹´{current_skill}ç¶“é©—ï¼Œæƒ³å­¸{target_skill}è½‰è·åˆ°{target_job}"
                ],
                ComplexityLevel.EXTREME: [
                    "æˆ‘ç›®å‰æŒæ¡{current_skill_list}æŠ€èƒ½ï¼Œåœ¨{current_industry}æœ‰{experience_years}å¹´ç¶“é©—ï¼Œæƒ³è½‰å…¥{target_industry}æ“”ä»»{target_job}ï¼Œè«‹åˆ†ææˆ‘éœ€è¦è£œå¼·å“ªäº›æŠ€èƒ½ï¼Œå­¸ç¿’é †åºå’Œæ™‚é–“è¦åŠƒ",
                    "æ¯”è¼ƒ{skill_list}é€™äº›æŠ€èƒ½åœ¨{industry_list}ä¸åŒç”¢æ¥­ä¸­çš„æ‡‰ç”¨å’Œé‡è¦æ€§ï¼Œä¸¦çµ¦å‡ºå­¸ç¿’å»ºè­°"
                ]
            },
            TestCategory.LOCATION_SEARCH: {
                ComplexityLevel.SIMPLE: [
                    "{location}æœ‰å·¥ä½œå—",
                    "æˆ‘æƒ³åœ¨{location}å·¥ä½œ",
                    "{location}çš„å·¥ä½œæ©Ÿæœƒ",
                    "æ¬åˆ°{location}å·¥ä½œå¥½å—",
                    "{location}å·¥ä½œç’°å¢ƒå¦‚ä½•"
                ],
                ComplexityLevel.MODERATE: [
                    "{location}çš„{job_title}å·¥ä½œå¤šå—",
                    "æ¯”è¼ƒ{location1}å’Œ{location2}çš„å·¥ä½œæ©Ÿæœƒ",
                    "{location}çš„{industry}ç™¼å±•å¦‚ä½•",
                    "åœ¨{location}å·¥ä½œçš„ç”Ÿæ´»æˆæœ¬",
                    "{location}é©åˆ{job_title}ç™¼å±•å—"
                ],
                ComplexityLevel.COMPLEX: [
                    "æˆ‘æƒ³åœ¨{location_list}ä¸­é¸ä¸€å€‹åœ°æ–¹ç™¼å±•{job_title}è·æ¶¯ï¼Œè«‹æ¯”è¼ƒå„åœ°çš„æ©Ÿæœƒå’Œç”Ÿæ´»å“è³ª",
                    "åˆ†æ{location}çš„{industry}ç”¢æ¥­ç™¼å±•è¶¨å‹¢å’Œ{job_title}è·ä½éœ€æ±‚",
                    "è€ƒæ…®è–ªè³‡ã€ç”Ÿæ´»æˆæœ¬ã€ç™¼å±•æ©Ÿæœƒï¼Œ{location1}å’Œ{location2}å“ªå€‹æ›´é©åˆ{job_title}"
                ],
                ComplexityLevel.EXTREME: [
                    "æˆ‘åœ¨è€ƒæ…®{location_list}é€™äº›åŸå¸‚ç™¼å±•{job_title}è·æ¶¯ï¼Œè«‹å¾è–ªè³‡æ°´å¹³ã€ç”Ÿæ´»æˆæœ¬ã€ç”¢æ¥­ç™¼å±•ã€å·¥ä½œæ©Ÿæœƒã€ç”Ÿæ´»å“è³ªç­‰è§’åº¦é€²è¡Œå…¨é¢æ¯”è¼ƒåˆ†æ",
                    "åˆ†æ{location}åœ¨æœªä¾†{years}å¹´å…§{industry}ç”¢æ¥­çš„ç™¼å±•æ½›åŠ›ï¼Œä»¥åŠå°{job_title}è·ä½çš„å½±éŸ¿"
                ]
            },
            TestCategory.SALARY_INQUIRY: {
                ComplexityLevel.SIMPLE: [
                    "{job_title}è–ªæ°´å¤šå°‘",
                    "æˆ‘çš„è–ªæ°´åˆç†å—",
                    "{location}è–ªæ°´æ°´å¹³",
                    "å¦‚ä½•è«‡è–ªæ°´",
                    "è–ªæ°´å¤ªä½æ€éº¼è¾¦"
                ],
                ComplexityLevel.MODERATE: [
                    "{location}çš„{job_title}å¹³å‡è–ªè³‡",
                    "æœ‰{experience_years}å¹´ç¶“é©—çš„{job_title}è–ªæ°´",
                    "{company_type}çš„{job_title}è–ªè³‡ç¯„åœ",
                    "æˆ‘çš„è–ªæ°´{current_salary}åœ¨å¸‚å ´ä¸Šå¦‚ä½•",
                    "å¦‚ä½•è¦æ±‚åŠ è–ªåˆ°{target_salary}"
                ],
                ComplexityLevel.COMPLEX: [
                    "æ¯”è¼ƒ{location1}å’Œ{location2}çš„{job_title}è–ªè³‡å·®ç•°ï¼Œè€ƒæ…®ç”Ÿæ´»æˆæœ¬",
                    "æˆ‘æœ‰{skill_list}æŠ€èƒ½ï¼Œ{experience_years}å¹´ç¶“é©—ï¼Œåœ¨{location}åš{job_title}æ‡‰è©²æ‹¿å¤šå°‘è–ªæ°´",
                    "åˆ†æ{industry}ä¸­{job_title}çš„è–ªè³‡æˆé•·è¶¨å‹¢"
                ],
                ComplexityLevel.EXTREME: [
                    "æˆ‘ç›®å‰{current_salary}ï¼Œåœ¨{current_location}åš{current_job}ï¼Œæƒ³è½‰è·åˆ°{target_location}çš„{target_job}ï¼Œè«‹åˆ†æè–ªè³‡è®ŠåŒ–å’Œè«‡åˆ¤ç­–ç•¥",
                    "æ¯”è¼ƒ{job_list}é€™äº›è·ä½åœ¨{location_list}ä¸åŒåŸå¸‚çš„è–ªè³‡æ°´å¹³ï¼Œè€ƒæ…®æŠ€èƒ½è¦æ±‚ã€ç¶“é©—éœ€æ±‚ã€ç”Ÿæ´»æˆæœ¬ç­‰å› ç´ "
                ]
            },
            TestCategory.EDGE_CASE: {
                ComplexityLevel.SIMPLE: [
                    "æˆ‘æƒ³æ‰¾å·¥ä½œä½†ä¸çŸ¥é“åšä»€éº¼",
                    "å®Œå…¨æ²’ç¶“é©—å¯ä»¥æ‰¾å·¥ä½œå—",
                    "æˆ‘50æ­²äº†é‚„èƒ½æ‰¾å·¥ä½œå—",
                    "æ²’æœ‰å­¸æ­·èƒ½å·¥ä½œå—",
                    "æˆ‘æƒ³åœ¨å®¶å·¥ä½œ"
                ],
                ComplexityLevel.MODERATE: [
                    "æˆ‘è¢«è£å“¡äº†ï¼Œç¾åœ¨è©²æ€éº¼è¾¦",
                    "æ‡·å­•æœŸé–“å¯ä»¥æ‰¾å·¥ä½œå—",
                    "æˆ‘æœ‰çŠ¯ç½ªç´€éŒ„ï¼Œèƒ½æ‰¾åˆ°å·¥ä½œå—",
                    "èº«é«”æœ‰æ®˜ç–¾ï¼Œå·¥ä½œé¸æ“‡æœ‰é™å—",
                    "æˆ‘æƒ³å‰µæ¥­ä½†æ²’è³‡é‡‘"
                ],
                ComplexityLevel.COMPLEX: [
                    "æˆ‘å·²ç¶“å¤±æ¥­ä¸€å¹´äº†ï¼Œå±¥æ­·ç©ºç™½æœŸæ€éº¼è§£é‡‹",
                    "æˆ‘æƒ³è½‰è¡Œä½†å®Œå…¨æ²’ç›¸é—œç¶“é©—ï¼Œè©²å¦‚ä½•é–‹å§‹",
                    "å› ç‚ºå®¶åº­å› ç´ éœ€è¦é »ç¹è«‹å‡ï¼Œä»€éº¼å·¥ä½œé©åˆ",
                    "æˆ‘æœ‰ç¤¾äº¤ææ‡¼ç—‡ï¼Œé©åˆä»€éº¼å·¥ä½œ"
                ],
                ComplexityLevel.EXTREME: [
                    "æˆ‘æ˜¯å–®è¦ªåª½åª½ï¼Œéœ€è¦å½ˆæ€§å·¥æ™‚ï¼Œæ²’æœ‰é«˜å­¸æ­·ï¼Œæœ‰ä»€éº¼å·¥ä½œé¸æ“‡",
                    "æˆ‘æœ‰æ†‚é¬±ç—‡ç—…å²ï¼Œå·¥ä½œç¶“å¸¸ä¸­æ–·ï¼Œç¾åœ¨æƒ³é‡æ–°é–‹å§‹è·æ¶¯",
                    "æˆ‘å› ç‚ºç…§é¡§å®¶äººé›¢é–‹è·å ´5å¹´ï¼Œç¾åœ¨æƒ³é‡è¿”è·å ´ä½†æŠ€èƒ½å·²ç¶“è½å¾Œ"
                ]
            }
        }
        
        # ç‚ºå…¶ä»–é¡åˆ¥æ·»åŠ åŸºæœ¬æ¨¡æ¿
        for category in TestCategory:
            if category not in templates:
                templates[category] = {
                    ComplexityLevel.SIMPLE: [f"é—œæ–¼{category.value}çš„ç°¡å–®å•é¡Œ"],
                    ComplexityLevel.MODERATE: [f"é—œæ–¼{category.value}çš„ä¸­ç­‰å•é¡Œ"],
                    ComplexityLevel.COMPLEX: [f"é—œæ–¼{category.value}çš„è¤‡é›œå•é¡Œ"],
                    ComplexityLevel.EXTREME: [f"é—œæ–¼{category.value}çš„æ¥µç«¯å•é¡Œ"]
                }
        
        return templates
    
    def _load_entities(self) -> Dict[str, List[str]]:
        """è¼‰å…¥å¯¦é«”æ•¸æ“š"""
        return {
            'job_title': [
                'è»Ÿé«”å·¥ç¨‹å¸«', 'è³‡æ–™ç§‘å­¸å®¶', 'ç”¢å“ç¶“ç†', 'è¨­è¨ˆå¸«', 'è¡ŒéŠ·å°ˆå“¡',
                'æ¥­å‹™ä»£è¡¨', 'äººè³‡å°ˆå“¡', 'è²¡å‹™åˆ†æå¸«', 'å°ˆæ¡ˆç¶“ç†', 'å®¢æœå°ˆå“¡',
                'å‰ç«¯å·¥ç¨‹å¸«', 'å¾Œç«¯å·¥ç¨‹å¸«', 'å…¨ç«¯å·¥ç¨‹å¸«', 'DevOpså·¥ç¨‹å¸«', 'QAå·¥ç¨‹å¸«',
                'UI/UXè¨­è¨ˆå¸«', 'æ•¸ä½è¡ŒéŠ·å°ˆå“¡', 'ç¤¾ç¾¤åª’é«”ç¶“ç†', 'å…§å®¹ç·¨è¼¯', 'ç¿»è­¯å“¡'
            ],
            'location': [
                'å°åŒ—', 'æ–°åŒ—', 'æ¡ƒåœ’', 'å°ä¸­', 'å°å—', 'é«˜é›„',
                'æ–°ç«¹', 'åŸºéš†', 'å®œè˜­', 'èŠ±è“®', 'å°æ±', 'å±æ±',
                'ä¿¡ç¾©å€', 'å¤§å®‰å€', 'ä¸­å±±å€', 'æ¾å±±å€', 'å…§æ¹–å€', 'å—æ¸¯å€',
                'ç¾åœ‹', 'æ—¥æœ¬', 'æ–°åŠ å¡', 'é¦™æ¸¯', 'ä¸Šæµ·', 'æ·±åœ³'
            ],
            'skill': [
                'Python', 'JavaScript', 'Java', 'C++', 'React', 'Vue.js',
                'Node.js', 'Django', 'Flask', 'Spring Boot', 'Docker', 'Kubernetes',
                'AWS', 'Azure', 'GCP', 'MySQL', 'PostgreSQL', 'MongoDB',
                'Git', 'Jenkins', 'Terraform', 'Ansible', 'æ©Ÿå™¨å­¸ç¿’', 'æ·±åº¦å­¸ç¿’',
                'æ•¸æ“šåˆ†æ', 'Excel', 'PowerBI', 'Tableau', 'Photoshop', 'Illustrator',
                'å°ˆæ¡ˆç®¡ç†', 'æºé€šæŠ€å·§', 'é ˜å°èƒ½åŠ›', 'å•é¡Œè§£æ±º', 'å‰µæ„æ€è€ƒ'
            ],
            'company_type': [
                'æ–°å‰µå…¬å¸', 'ä¸­å°ä¼æ¥­', 'å¤§å‹ä¼æ¥­', 'å¤–å•†å…¬å¸', 'æœ¬åœŸä¼æ¥­',
                'ç§‘æŠ€å…¬å¸', 'é‡‘èæ¥­', 'è£½é€ æ¥­', 'æœå‹™æ¥­', 'é›¶å”®æ¥­',
                'éç‡Ÿåˆ©çµ„ç¹”', 'æ”¿åºœæ©Ÿé—œ', 'å­¸è¡“æ©Ÿæ§‹', 'é†«ç™‚æ©Ÿæ§‹', 'åª’é«”æ¥­'
            ],
            'industry': [
                'ç§‘æŠ€æ¥­', 'é‡‘èæ¥­', 'è£½é€ æ¥­', 'æœå‹™æ¥­', 'é›¶å”®æ¥­', 'é†«ç™‚æ¥­',
                'æ•™è‚²æ¥­', 'åª’é«”æ¥­', 'éŠæˆ²æ¥­', 'é›»å•†æ¥­', 'ç‰©æµæ¥­', 'æˆ¿åœ°ç”¢æ¥­',
                'èƒ½æºæ¥­', 'è¾²æ¥­', 'è§€å…‰æ¥­', 'é¤é£²æ¥­', 'æ™‚å°šæ¥­', 'æ±½è»Šæ¥­'
            ],
            'work_type': [
                'å…¨è·', 'å…¼è·', 'é ç«¯å·¥ä½œ', 'æ··åˆè¾¦å…¬', 'å¥‘ç´„å·¥ä½œ', 'è‡ªç”±æ¥æ¡ˆ',
                'å¯¦ç¿’', 'å·¥è®€', 'è‡¨æ™‚å·¥', 'é¡§å•', 'æ´¾é£', 'è¼ªç­åˆ¶'
            ],
            'salary_range': [
                '30-40K', '40-50K', '50-60K', '60-80K', '80-100K', '100-120K',
                '120-150K', '150-200K', '200Kä»¥ä¸Š', 'é¢è­°', 'ä¾ç¶“é©—èª¿æ•´'
            ],
            'experience_years': [
                '0-1å¹´', '1-3å¹´', '3-5å¹´', '5-8å¹´', '8-10å¹´', '10å¹´ä»¥ä¸Š',
                'æ‡‰å±†ç•¢æ¥­', 'æœ‰ç¶“é©—', 'è³‡æ·±', 'å°ˆå®¶ç´š'
            ],
            'education_level': [
                'é«˜ä¸­', 'å°ˆç§‘', 'å¤§å­¸', 'ç¢©å£«', 'åšå£«', 'æŠ€è·', 'è‡ªå­¸'
            ],
            'major': [
                'è³‡è¨Šå·¥ç¨‹', 'é›»æ©Ÿå·¥ç¨‹', 'æ©Ÿæ¢°å·¥ç¨‹', 'å·¥æ¥­å·¥ç¨‹', 'ä¼æ¥­ç®¡ç†',
                'è²¡å‹™é‡‘è', 'æœƒè¨ˆ', 'è¡ŒéŠ·', 'å¿ƒç†å­¸', 'è¨­è¨ˆ', 'å¤–èª', 'æ•¸å­¸',
                'çµ±è¨ˆ', 'ç¶“æ¿Ÿ', 'æ³•å¾‹', 'é†«å­¸', 'è­·ç†', 'æ•™è‚²', 'æ–°èå‚³æ’­'
            ]
        }
    
    def generate_test_cases(self, config: GenerationConfig) -> List[TestCase]:
        """ç”Ÿæˆæ¸¬è©¦æ¡ˆä¾‹"""
        print(f"ğŸš€ é–‹å§‹ç”Ÿæˆ {config.total_cases} å€‹æ¸¬è©¦æ¡ˆä¾‹")
        
        # è¨­ç½®é»˜èªåˆ†ä½ˆ
        if not config.category_distribution:
            config.category_distribution = self._get_default_category_distribution()
        
        if not config.complexity_distribution:
            config.complexity_distribution = self._get_default_complexity_distribution()
        
        if not config.language_distribution:
            config.language_distribution = self._get_default_language_distribution()
        
        # è¨ˆç®—å„é¡åˆ¥çš„æ¡ˆä¾‹æ•¸é‡
        category_counts = self._calculate_category_counts(config)
        
        # ç”Ÿæˆæ¡ˆä¾‹
        generated_cases = []
        
        for category, count in category_counts.items():
            print(f"   ç”Ÿæˆ {category.value}: {count} å€‹æ¡ˆä¾‹")
            
            category_cases = self._generate_category_cases(
                category, count, config
            )
            generated_cases.extend(category_cases)
        
        # ç¢ºä¿å¤šæ¨£æ€§
        if config.ensure_diversity:
            generated_cases = self._ensure_diversity(
                generated_cases, config.max_similarity_threshold
            )
        
        # èª¿æ•´åˆ°ç›®æ¨™æ•¸é‡
        if len(generated_cases) != config.total_cases:
            generated_cases = self._adjust_to_target_count(
                generated_cases, config.total_cases
            )
        
        # éš¨æ©Ÿæ‰“äº‚
        random.shuffle(generated_cases)
        
        self.generated_cases = generated_cases
        self._calculate_generation_stats()
        
        print(f"âœ… æˆåŠŸç”Ÿæˆ {len(generated_cases)} å€‹æ¸¬è©¦æ¡ˆä¾‹")
        
        return generated_cases
    
    def _get_default_category_distribution(self) -> Dict[TestCategory, float]:
        """ç²å–é»˜èªé¡åˆ¥åˆ†ä½ˆ"""
        return {
            TestCategory.JOB_SEARCH: 0.25,
            TestCategory.SKILL_QUERY: 0.15,
            TestCategory.LOCATION_SEARCH: 0.12,
            TestCategory.SALARY_INQUIRY: 0.12,
            TestCategory.CAREER_ADVICE: 0.10,
            TestCategory.COMPANY_INFO: 0.08,
            TestCategory.INTERVIEW_PREP: 0.08,
            TestCategory.RESUME_HELP: 0.05,
            TestCategory.GENERAL_CHAT: 0.03,
            TestCategory.EDGE_CASE: 0.02
        }
    
    def _get_default_complexity_distribution(self) -> Dict[ComplexityLevel, float]:
        """ç²å–é»˜èªè¤‡é›œåº¦åˆ†ä½ˆ"""
        return {
            ComplexityLevel.SIMPLE: 0.3,
            ComplexityLevel.MODERATE: 0.4,
            ComplexityLevel.COMPLEX: 0.25,
            ComplexityLevel.EXTREME: 0.05
        }
    
    def _get_default_language_distribution(self) -> Dict[LanguageCode, float]:
        """ç²å–é»˜èªèªè¨€åˆ†ä½ˆ"""
        return {
            LanguageCode.ZH_TW: 0.6,
            LanguageCode.EN_US: 0.25,
            LanguageCode.ZH_CN: 0.1,
            LanguageCode.JA_JP: 0.03,
            LanguageCode.KO_KR: 0.02
        }
    
    def _calculate_category_counts(self, config: GenerationConfig) -> Dict[TestCategory, int]:
        """è¨ˆç®—å„é¡åˆ¥æ¡ˆä¾‹æ•¸é‡"""
        category_counts = {}
        remaining_cases = config.total_cases
        
        # æŒ‰åˆ†ä½ˆè¨ˆç®—
        for category, ratio in config.category_distribution.items():
            count = int(config.total_cases * ratio)
            category_counts[category] = count
            remaining_cases -= count
        
        # åˆ†é…å‰©é¤˜æ¡ˆä¾‹
        if remaining_cases > 0:
            categories = list(category_counts.keys())
            for i in range(remaining_cases):
                category = categories[i % len(categories)]
                category_counts[category] += 1
        
        return category_counts
    
    def _generate_category_cases(self, category: TestCategory, count: int, 
                               config: GenerationConfig) -> List[TestCase]:
        """ç”Ÿæˆç‰¹å®šé¡åˆ¥çš„æ¡ˆä¾‹"""
        cases = []
        
        for _ in range(count):
            # é¸æ“‡è¤‡é›œåº¦
            complexity = self._choose_complexity(config.complexity_distribution)
            
            # é¸æ“‡èªè¨€
            language = self._choose_language(config.language_distribution)
            
            # ç”Ÿæˆæ¡ˆä¾‹
            test_case = self._generate_single_case(category, complexity, language)
            
            if test_case:
                cases.append(test_case)
        
        return cases
    
    def _choose_complexity(self, distribution: Dict[ComplexityLevel, float]) -> ComplexityLevel:
        """é¸æ“‡è¤‡é›œåº¦"""
        return random.choices(
            list(distribution.keys()),
            weights=list(distribution.values())
        )[0]
    
    def _choose_language(self, distribution: Dict[LanguageCode, float]) -> LanguageCode:
        """é¸æ“‡èªè¨€"""
        return random.choices(
            list(distribution.keys()),
            weights=list(distribution.values())
        )[0]
    
    def _generate_single_case(self, category: TestCategory, 
                            complexity: ComplexityLevel, 
                            language: LanguageCode) -> Optional[TestCase]:
        """ç”Ÿæˆå–®å€‹æ¸¬è©¦æ¡ˆä¾‹"""
        try:
            # ç²å–æ¨¡æ¿
            templates = self.templates.get(category, {}).get(complexity, [])
            if not templates:
                return None
            
            template = random.choice(templates)
            
            # å¡«å……æ¨¡æ¿
            query = self._fill_template(template, language)
            
            # ç”Ÿæˆé æœŸçµæœ
            expected_intent = self._generate_expected_intent(category, complexity)
            expected_entities = self._extract_entities_from_query(query)
            
            # å‰µå»ºæ¸¬è©¦æ¡ˆä¾‹
            test_case = TestCase(
                test_id=str(uuid.uuid4()),
                query=query,
                category=category,
                complexity=complexity,
                language=language,
                expected_intent=expected_intent,
                expected_entities=expected_entities,
                metadata={
                    'template': template,
                    'generated_at': datetime.now().isoformat()
                }
            )
            
            return test_case
            
        except Exception as e:
            print(f"âš ï¸ ç”Ÿæˆæ¡ˆä¾‹å¤±æ•—: {e}")
            return None
    
    def _fill_template(self, template: str, language: LanguageCode) -> str:
        """å¡«å……æ¨¡æ¿"""
        # æ‰¾å‡ºæ¨¡æ¿ä¸­çš„ä½”ä½ç¬¦
        import re
        placeholders = re.findall(r'\{([^}]+)\}', template)
        
        filled_template = template
        
        for placeholder in placeholders:
            # è™•ç†åˆ—è¡¨é¡å‹çš„ä½”ä½ç¬¦
            if '_list' in placeholder:
                base_key = placeholder.replace('_list', '')
                if base_key in self.entities:
                    # é¸æ“‡2-4å€‹å¯¦é«”
                    count = random.randint(2, 4)
                    selected = random.sample(self.entities[base_key], min(count, len(self.entities[base_key])))
                    value = 'ã€'.join(selected)
                else:
                    value = placeholder
            else:
                # å–®å€‹å¯¦é«”
                if placeholder in self.entities:
                    value = random.choice(self.entities[placeholder])
                else:
                    value = placeholder
            
            filled_template = filled_template.replace(f'{{{placeholder}}}', value)
        
        # æ ¹æ“šèªè¨€èª¿æ•´
        if language != LanguageCode.ZH_TW:
            filled_template = self._translate_query(filled_template, language)
        
        return filled_template
    
    def _translate_query(self, query: str, target_language: LanguageCode) -> str:
        """ç¿»è­¯æŸ¥è©¢ï¼ˆç°¡åŒ–ç‰ˆï¼‰"""
        # é€™è£¡æ˜¯ç°¡åŒ–çš„ç¿»è­¯é‚è¼¯ï¼Œå¯¦éš›æ‡‰ç”¨ä¸­å¯ä»¥ä½¿ç”¨ç¿»è­¯API
        translations = {
            LanguageCode.EN_US: {
                'æˆ‘æƒ³æ‰¾': 'I want to find',
                'å·¥ä½œ': 'job',
                'çš„': '',
                'æœ‰': 'Are there any',
                'å—': '?',
                'å¹«æˆ‘æœå°‹': 'Help me search for',
                'è–ªæ°´': 'salary',
                'å¤šå°‘': 'how much',
                'æŠ€èƒ½': 'skills',
                'å­¸ç¿’': 'learn',
                'ç¶“é©—': 'experience'
            },
            LanguageCode.ZH_CN: {
                'å°åŒ—': 'åŒ—äº¬',
                'å°ä¸­': 'ä¸Šæµ·',
                'é«˜é›„': 'æ·±åœ³',
                'æ–°å°å¹£': 'äººæ°‘å¸',
                'è·ç¼º': 'èŒä½'
            }
        }
        
        if target_language in translations:
            for zh_word, translated in translations[target_language].items():
                query = query.replace(zh_word, translated)
        
        return query
    
    def _generate_expected_intent(self, category: TestCategory, 
                                complexity: ComplexityLevel) -> str:
        """ç”Ÿæˆé æœŸæ„åœ–"""
        intent_mapping = {
            TestCategory.JOB_SEARCH: 'job_search',
            TestCategory.SKILL_QUERY: 'skill_inquiry',
            TestCategory.LOCATION_SEARCH: 'location_search',
            TestCategory.SALARY_INQUIRY: 'salary_inquiry',
            TestCategory.CAREER_ADVICE: 'career_advice',
            TestCategory.COMPANY_INFO: 'company_inquiry',
            TestCategory.INTERVIEW_PREP: 'interview_help',
            TestCategory.RESUME_HELP: 'resume_assistance',
            TestCategory.GENERAL_CHAT: 'general_conversation',
            TestCategory.EDGE_CASE: 'edge_case_handling'
        }
        
        base_intent = intent_mapping.get(category, 'unknown')
        
        # æ ¹æ“šè¤‡é›œåº¦èª¿æ•´
        if complexity == ComplexityLevel.COMPLEX:
            base_intent += '_complex'
        elif complexity == ComplexityLevel.EXTREME:
            base_intent += '_extreme'
        
        return base_intent
    
    def _extract_entities_from_query(self, query: str) -> Dict[str, Any]:
        """å¾æŸ¥è©¢ä¸­æå–å¯¦é«”"""
        entities = {}
        
        # ç°¡åŒ–çš„å¯¦é«”æå–é‚è¼¯
        for entity_type, entity_list in self.entities.items():
            for entity in entity_list:
                if entity in query:
                    if entity_type not in entities:
                        entities[entity_type] = []
                    entities[entity_type].append(entity)
        
        return entities
    
    def _ensure_diversity(self, cases: List[TestCase], 
                        threshold: float) -> List[TestCase]:
        """ç¢ºä¿å¤šæ¨£æ€§"""
        # ç°¡åŒ–çš„å¤šæ¨£æ€§æª¢æŸ¥
        unique_cases = []
        seen_queries = set()
        
        for case in cases:
            # ç°¡åŒ–çš„ç›¸ä¼¼åº¦æª¢æŸ¥
            query_words = set(case.query.split())
            
            is_similar = False
            for seen_query in seen_queries:
                seen_words = set(seen_query.split())
                
                if query_words and seen_words:
                    similarity = len(query_words & seen_words) / len(query_words | seen_words)
                    if similarity > threshold:
                        is_similar = True
                        break
            
            if not is_similar:
                unique_cases.append(case)
                seen_queries.add(case.query)
        
        return unique_cases
    
    def _adjust_to_target_count(self, cases: List[TestCase], 
                              target_count: int) -> List[TestCase]:
        """èª¿æ•´åˆ°ç›®æ¨™æ•¸é‡"""
        if len(cases) == target_count:
            return cases
        elif len(cases) > target_count:
            # éš¨æ©Ÿé¸æ“‡
            return random.sample(cases, target_count)
        else:
            # éœ€è¦ç”Ÿæˆæ›´å¤šæ¡ˆä¾‹
            additional_needed = target_count - len(cases)
            
            # è¤‡è£½ç¾æœ‰æ¡ˆä¾‹ä¸¦ç¨ä½œä¿®æ”¹
            additional_cases = []
            for i in range(additional_needed):
                base_case = random.choice(cases)
                
                # å‰µå»ºè®Šé«”
                variant = self._create_variant(base_case)
                additional_cases.append(variant)
            
            return cases + additional_cases
    
    def _create_variant(self, base_case: TestCase) -> TestCase:
        """å‰µå»ºæ¡ˆä¾‹è®Šé«”"""
        # ç°¡å–®çš„è®Šé«”ç”Ÿæˆ
        variant_query = base_case.query
        
        # éš¨æ©Ÿæ›¿æ›ä¸€äº›å¯¦é«”
        for entity_type, entity_list in self.entities.items():
            for entity in entity_list:
                if entity in variant_query:
                    # æœ‰30%æ©Ÿç‡æ›¿æ›
                    if random.random() < 0.3:
                        new_entity = random.choice(entity_list)
                        variant_query = variant_query.replace(entity, new_entity, 1)
                        break
        
        variant = TestCase(
            test_id=str(uuid.uuid4()),
            query=variant_query,
            category=base_case.category,
            complexity=base_case.complexity,
            language=base_case.language,
            expected_intent=base_case.expected_intent,
            expected_entities=self._extract_entities_from_query(variant_query),
            metadata={
                'variant_of': base_case.test_id,
                'generated_at': datetime.now().isoformat()
            }
        )
        
        return variant
    
    def _calculate_generation_stats(self) -> None:
        """è¨ˆç®—ç”Ÿæˆçµ±è¨ˆ"""
        if not self.generated_cases:
            return
        
        # é¡åˆ¥çµ±è¨ˆ
        category_stats = {}
        for category in TestCategory:
            count = sum(1 for case in self.generated_cases if case.category == category)
            category_stats[category.value] = count
        
        # è¤‡é›œåº¦çµ±è¨ˆ
        complexity_stats = {}
        for complexity in ComplexityLevel:
            count = sum(1 for case in self.generated_cases if case.complexity == complexity)
            complexity_stats[complexity.value] = count
        
        # èªè¨€çµ±è¨ˆ
        language_stats = {}
        for language in LanguageCode:
            count = sum(1 for case in self.generated_cases if case.language == language)
            language_stats[language.value] = count
        
        self.generation_stats = {
            'total_cases': len(self.generated_cases),
            'category_distribution': category_stats,
            'complexity_distribution': complexity_stats,
            'language_distribution': language_stats,
            'generation_time': datetime.now().isoformat()
        }
    
    def export_test_cases(self, file_path: str, format_type: str = 'json') -> None:
        """å°å‡ºæ¸¬è©¦æ¡ˆä¾‹"""
        if not self.generated_cases:
            print("âŒ æ²’æœ‰å¯å°å‡ºçš„æ¸¬è©¦æ¡ˆä¾‹")
            return
        
        file_path = Path(file_path)
        file_path.parent.mkdir(parents=True, exist_ok=True)
        
        if format_type.lower() == 'json':
            self._export_json(file_path)
        elif format_type.lower() == 'csv':
            self._export_csv(file_path)
        else:
            print(f"âŒ ä¸æ”¯æ´çš„æ ¼å¼: {format_type}")
            return
        
        print(f"âœ… æ¸¬è©¦æ¡ˆä¾‹å·²å°å‡ºè‡³: {file_path}")
    
    def _export_json(self, file_path: Path) -> None:
        """å°å‡ºç‚ºJSONæ ¼å¼"""
        data = {
            'metadata': {
                'total_cases': len(self.generated_cases),
                'generation_time': datetime.now().isoformat(),
                'generator_version': '1.0.0'
            },
            'statistics': self.generation_stats,
            'test_cases': []
        }
        
        for case in self.generated_cases:
            case_data = {
                'test_id': case.test_id,
                'query': case.query,
                'category': case.category.value,
                'complexity': case.complexity.value,
                'language': case.language.value,
                'expected_intent': case.expected_intent,
                'expected_entities': case.expected_entities,
                'context': case.context,
                'metadata': case.metadata,
                'created_at': case.created_at.isoformat()
            }
            data['test_cases'].append(case_data)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    
    def _export_csv(self, file_path: Path) -> None:
        """å°å‡ºç‚ºCSVæ ¼å¼"""
        import csv
        
        with open(file_path, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            
            # å¯«å…¥æ¨™é¡Œ
            headers = [
                'test_id', 'query', 'category', 'complexity', 'language',
                'expected_intent', 'expected_entities', 'context', 'created_at'
            ]
            writer.writerow(headers)
            
            # å¯«å…¥æ•¸æ“š
            for case in self.generated_cases:
                row = [
                    case.test_id,
                    case.query,
                    case.category.value,
                    case.complexity.value,
                    case.language.value,
                    case.expected_intent,
                    json.dumps(case.expected_entities, ensure_ascii=False),
                    case.context or '',
                    case.created_at.isoformat()
                ]
                writer.writerow(row)
    
    def print_generation_summary(self) -> None:
        """æ‰“å°ç”Ÿæˆæ‘˜è¦"""
        if not self.generation_stats:
            print("âŒ æ²’æœ‰ç”Ÿæˆçµ±è¨ˆæ•¸æ“š")
            return
        
        print("\n" + "="*60)
        print("ğŸ“Š æ¸¬è©¦æ¡ˆä¾‹ç”Ÿæˆæ‘˜è¦")
        print("="*60)
        
        print(f"\nğŸ“ˆ ç¸½é«”çµ±è¨ˆ:")
        print(f"   ç¸½æ¡ˆä¾‹æ•¸: {self.generation_stats['total_cases']}")
        print(f"   ç”Ÿæˆæ™‚é–“: {self.generation_stats['generation_time']}")
        
        print(f"\nğŸ“‚ é¡åˆ¥åˆ†ä½ˆ:")
        for category, count in self.generation_stats['category_distribution'].items():
            percentage = (count / self.generation_stats['total_cases']) * 100
            print(f"   {category}: {count} ({percentage:.1f}%)")
        
        print(f"\nğŸ¯ è¤‡é›œåº¦åˆ†ä½ˆ:")
        for complexity, count in self.generation_stats['complexity_distribution'].items():
            percentage = (count / self.generation_stats['total_cases']) * 100
            print(f"   {complexity}: {count} ({percentage:.1f}%)")
        
        print(f"\nğŸŒ èªè¨€åˆ†ä½ˆ:")
        for language, count in self.generation_stats['language_distribution'].items():
            percentage = (count / self.generation_stats['total_cases']) * 100
            print(f"   {language}: {count} ({percentage:.1f}%)")
        
        print("\n" + "="*60)


def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ å¿«é€Ÿæ¸¬è©¦æ¡ˆä¾‹ç”Ÿæˆå™¨")
    print("å°ˆé–€ç”¨æ–¼å¿«é€Ÿç”Ÿæˆå¤šæ¨£åŒ–çš„LLMæ¸¬è©¦æ¡ˆä¾‹\n")
    
    generator = QuickTestCaseGenerator()
    
    # é…ç½®ç”Ÿæˆåƒæ•¸
    print("âš™ï¸ é…ç½®ç”Ÿæˆåƒæ•¸:")
    
    try:
        total_cases = int(input("æ¸¬è©¦æ¡ˆä¾‹ç¸½æ•¸ (é è¨­1000): ") or "1000")
        total_cases = max(100, min(10000, total_cases))  # é™åˆ¶ç¯„åœ
    except ValueError:
        total_cases = 1000
        print("   ä½¿ç”¨é è¨­å€¼: 1000")
    
    # é¸æ“‡ç”Ÿæˆæ¨¡å¼
    print("\nğŸ¯ é¸æ“‡ç”Ÿæˆæ¨¡å¼:")
    print("   1. å¹³è¡¡æ¨¡å¼ (å„é¡åˆ¥å¹³å‡åˆ†ä½ˆ)")
    print("   2. æ±‚è·å°å‘ (é‡é»ç”Ÿæˆæ±‚è·ç›¸é—œæ¡ˆä¾‹)")
    print("   3. æŠ€èƒ½å°å‘ (é‡é»ç”ŸæˆæŠ€èƒ½æŸ¥è©¢æ¡ˆä¾‹)")
    print("   4. å¤šèªè¨€æ¨¡å¼ (å¢åŠ å¤šèªè¨€æ¡ˆä¾‹)")
    print("   5. é‚Šç•Œæ¡ˆä¾‹æ¨¡å¼ (å¢åŠ é‚Šç•Œæ¡ˆä¾‹)")
    print("   6. è‡ªå®šç¾©æ¨¡å¼")
    
    try:
        mode_choice = int(input("è«‹é¸æ“‡æ¨¡å¼ (é è¨­1): ") or "1")
    except ValueError:
        mode_choice = 1
    
    # å‰µå»ºé…ç½®
    config = GenerationConfig(total_cases=total_cases)
    
    if mode_choice == 2:  # æ±‚è·å°å‘
        config.category_distribution = {
            TestCategory.JOB_SEARCH: 0.4,
            TestCategory.SKILL_QUERY: 0.2,
            TestCategory.SALARY_INQUIRY: 0.15,
            TestCategory.LOCATION_SEARCH: 0.1,
            TestCategory.CAREER_ADVICE: 0.1,
            TestCategory.INTERVIEW_PREP: 0.05
        }
    elif mode_choice == 3:  # æŠ€èƒ½å°å‘
        config.category_distribution = {
            TestCategory.SKILL_QUERY: 0.5,
            TestCategory.JOB_SEARCH: 0.2,
            TestCategory.CAREER_ADVICE: 0.15,
            TestCategory.INTERVIEW_PREP: 0.1,
            TestCategory.RESUME_HELP: 0.05
        }
    elif mode_choice == 4:  # å¤šèªè¨€æ¨¡å¼
        config.language_distribution = {
            LanguageCode.ZH_TW: 0.3,
            LanguageCode.EN_US: 0.3,
            LanguageCode.ZH_CN: 0.2,
            LanguageCode.JA_JP: 0.1,
            LanguageCode.KO_KR: 0.1
        }
    elif mode_choice == 5:  # é‚Šç•Œæ¡ˆä¾‹æ¨¡å¼
        config.category_distribution = {
            TestCategory.EDGE_CASE: 0.3,
            TestCategory.JOB_SEARCH: 0.25,
            TestCategory.SKILL_QUERY: 0.15,
            TestCategory.CAREER_ADVICE: 0.15,
            TestCategory.SALARY_INQUIRY: 0.1,
            TestCategory.LOCATION_SEARCH: 0.05
        }
        config.complexity_distribution = {
            ComplexityLevel.COMPLEX: 0.4,
            ComplexityLevel.EXTREME: 0.3,
            ComplexityLevel.MODERATE: 0.2,
            ComplexityLevel.SIMPLE: 0.1
        }
    elif mode_choice == 6:  # è‡ªå®šç¾©æ¨¡å¼
        print("\nâš™ï¸ è‡ªå®šç¾©é…ç½® (ç›´æ¥æŒ‰Enterä½¿ç”¨é è¨­å€¼):")
        
        try:
            edge_ratio = float(input("é‚Šç•Œæ¡ˆä¾‹æ¯”ä¾‹ (0.0-1.0, é è¨­0.1): ") or "0.1")
            config.edge_case_ratio = max(0.0, min(1.0, edge_ratio))
            
            diversity_choice = input("ç¢ºä¿å¤šæ¨£æ€§? (Y/n): ").strip().lower()
            config.ensure_diversity = diversity_choice != 'n'
            
            if config.ensure_diversity:
                similarity_threshold = float(input("ç›¸ä¼¼åº¦é–¾å€¼ (0.0-1.0, é è¨­0.8): ") or "0.8")
                config.max_similarity_threshold = max(0.0, min(1.0, similarity_threshold))
        
        except ValueError:
            print("   ä½¿ç”¨é è¨­é…ç½®")
    
    # ç”Ÿæˆæ¸¬è©¦æ¡ˆä¾‹
    print(f"\nğŸš€ é–‹å§‹ç”Ÿæˆæ¸¬è©¦æ¡ˆä¾‹...")
    test_cases = generator.generate_test_cases(config)
    
    # æ‰“å°æ‘˜è¦
    generator.print_generation_summary()
    
    # å°å‡ºé¸é …
    print("\nğŸ’¾ å°å‡ºé¸é …:")
    export_choice = input("æ˜¯å¦å°å‡ºæ¸¬è©¦æ¡ˆä¾‹? (Y/n): ").strip().lower()
    
    if export_choice != 'n':
        output_dir = input("è¼¸å‡ºç›®éŒ„ (é è¨­: test_cases): ").strip() or "test_cases"
        
        format_choice = input("å°å‡ºæ ¼å¼ (json/csv, é è¨­json): ").strip().lower() or "json"
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"generated_test_cases_{timestamp}.{format_choice}"
        file_path = Path(output_dir) / filename
        
        generator.export_test_cases(str(file_path), format_choice)
        
        # ç”Ÿæˆçµ±è¨ˆå ±å‘Š
        stats_file = Path(output_dir) / f"generation_stats_{timestamp}.json"
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(generator.generation_stats, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“Š çµ±è¨ˆå ±å‘Šå·²ä¿å­˜è‡³: {stats_file}")
    
    print("\nğŸ‰ æ¸¬è©¦æ¡ˆä¾‹ç”Ÿæˆå®Œæˆ!")
    print("\nğŸ’¡ ä½¿ç”¨å»ºè­°:")
    print("   â€¢ å¯ä»¥å°‡ç”Ÿæˆçš„æ¸¬è©¦æ¡ˆä¾‹ç”¨æ–¼LLMæ¨¡å‹å°æ¯”æ¸¬è©¦")
    print("   â€¢ å»ºè­°å®šæœŸç”Ÿæˆæ–°çš„æ¸¬è©¦æ¡ˆä¾‹ä»¥ä¿æŒæ¸¬è©¦çš„æ™‚æ•ˆæ€§")
    print("   â€¢ å¯ä»¥æ ¹æ“šå¯¦éš›éœ€æ±‚èª¿æ•´é¡åˆ¥å’Œè¤‡é›œåº¦åˆ†ä½ˆ")


if __name__ == "__main__":
    main()