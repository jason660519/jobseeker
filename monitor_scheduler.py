#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LLM JSONèª¿åº¦å™¨ç›£æ§å’Œç®¡ç†å·¥å…·
æä¾›å¯¦æ™‚ç›£æ§ã€æ€§èƒ½åˆ†æå’Œç®¡ç†åŠŸèƒ½

Author: JobSpy Team
Date: 2025-01-27
"""

import os
import sys
import json
import time
import asyncio
import argparse
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import threading
from collections import defaultdict, deque

# å°å…¥å¿…è¦çš„æ¨¡çµ„
try:
    import requests
    REQUESTS_AVAILABLE = True
except ImportError:
    REQUESTS_AVAILABLE = False
    print("è­¦å‘Š: requestsæœªå®‰è£ï¼ŒAPIç›£æ§åŠŸèƒ½å°‡ä¸å¯ç”¨")

try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False
    print("è­¦å‘Š: psutilæœªå®‰è£ï¼Œç³»çµ±ç›£æ§åŠŸèƒ½å°‡å—é™")

try:
    import redis
    REDIS_AVAILABLE = True
except ImportError:
    REDIS_AVAILABLE = False
    print("è­¦å‘Š: redisæœªå®‰è£ï¼ŒRedisç›£æ§åŠŸèƒ½å°‡ä¸å¯ç”¨")

try:
    from rich.console import Console
    from rich.table import Table
    from rich.live import Live
    from rich.panel import Panel
    from rich.progress import Progress, SpinnerColumn, TextColumn
    from rich.layout import Layout
    from rich.text import Text
    RICH_AVAILABLE = True
except ImportError:
    RICH_AVAILABLE = False
    print("æç¤º: å®‰è£richåº«å¯ç²å¾—æ›´å¥½çš„é¡¯ç¤ºæ•ˆæœ: pip install rich")


class SchedulerMonitor:
    """
    èª¿åº¦å™¨ç›£æ§å™¨
    æä¾›å¯¦æ™‚ç›£æ§ã€æ€§èƒ½åˆ†æå’Œç®¡ç†åŠŸèƒ½
    """

    def __init__(self, config_file: str = "scheduler_config.json", api_base_url: str = None):
        self.config_file = Path(config_file)
        self.config = self._load_config()
        
        # APIé…ç½®
        if api_base_url:
            self.api_base_url = api_base_url
        else:
            api_config = self.config.get("api", {})
            host = api_config.get("host", "localhost")
            port = api_config.get("port", 8080)
            self.api_base_url = f"http://{host}:{port}"
        
        # ç›£æ§æ•¸æ“š
        self.metrics_history = deque(maxlen=100)  # ä¿ç•™æœ€è¿‘100å€‹æ•¸æ“šé»
        self.alert_thresholds = {
            "cpu_usage": 80.0,
            "memory_usage": 85.0,
            "queue_size": 1000,
            "error_rate": 10.0,
            "response_time": 5.0
        }
        
        # Redisé€£æ¥
        self.redis_client = None
        if REDIS_AVAILABLE:
            try:
                redis_config = self.config.get("queue", {})
                redis_url = redis_config.get("redis_url", "redis://localhost:6379/0")
                self.redis_client = redis.from_url(redis_url)
            except Exception as e:
                print(f"Redisé€£æ¥å¤±æ•—: {e}")
        
        # Richæ§åˆ¶å°
        self.console = Console() if RICH_AVAILABLE else None
        
        # ç›£æ§ç‹€æ…‹
        self.monitoring = False
        self.monitor_thread = None

    def _load_config(self) -> Dict:
        """è¼‰å…¥é…ç½®æª”æ¡ˆ"""
        
        if self.config_file.exists():
            with open(self.config_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            return {}

    def _make_api_request(self, endpoint: str, method: str = "GET", data: Dict = None) -> Optional[Dict]:
        """ç™¼é€APIè«‹æ±‚"""
        
        if not REQUESTS_AVAILABLE:
            print("requestsåº«æœªå®‰è£ï¼Œç„¡æ³•ç™¼é€APIè«‹æ±‚")
            return None
        
        try:
            url = f"{self.api_base_url}{endpoint}"
            
            if method == "GET":
                response = requests.get(url, timeout=10)
            elif method == "POST":
                response = requests.post(url, json=data, timeout=10)
            elif method == "PUT":
                response = requests.put(url, json=data, timeout=10)
            elif method == "DELETE":
                response = requests.delete(url, timeout=10)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„HTTPæ–¹æ³•: {method}")
            
            response.raise_for_status()
            return response.json()
            
        except requests.exceptions.RequestException as e:
            print(f"APIè«‹æ±‚å¤±æ•— ({endpoint}): {e}")
            return None

    def get_scheduler_status(self) -> Optional[Dict]:
        """ç²å–èª¿åº¦å™¨ç‹€æ…‹"""
        return self._make_api_request("/status")

    def get_performance_metrics(self) -> Optional[Dict]:
        """ç²å–æ€§èƒ½æŒ‡æ¨™"""
        return self._make_api_request("/metrics")

    def get_task_list(self, status: str = None, limit: int = 50) -> Optional[List[Dict]]:
        """ç²å–ä»»å‹™åˆ—è¡¨"""
        endpoint = f"/tasks?limit={limit}"
        if status:
            endpoint += f"&status={status}"
        
        result = self._make_api_request(endpoint)
        return result.get("tasks", []) if result else None

    def get_system_metrics(self) -> Dict:
        """ç²å–ç³»çµ±æŒ‡æ¨™"""
        
        metrics = {
            "timestamp": datetime.now().isoformat(),
            "cpu_usage": 0.0,
            "memory_usage": 0.0,
            "disk_usage": 0.0,
            "network_io": {"bytes_sent": 0, "bytes_recv": 0}
        }
        
        if PSUTIL_AVAILABLE:
            # CPUä½¿ç”¨ç‡
            metrics["cpu_usage"] = psutil.cpu_percent(interval=1)
            
            # è¨˜æ†¶é«”ä½¿ç”¨ç‡
            memory = psutil.virtual_memory()
            metrics["memory_usage"] = memory.percent
            
            # ç£ç¢Ÿä½¿ç”¨ç‡
            disk = psutil.disk_usage('.')
            metrics["disk_usage"] = (disk.used / disk.total) * 100
            
            # ç¶²è·¯IO
            net_io = psutil.net_io_counters()
            metrics["network_io"] = {
                "bytes_sent": net_io.bytes_sent,
                "bytes_recv": net_io.bytes_recv
            }
        
        return metrics

    def get_redis_metrics(self) -> Dict:
        """ç²å–RedisæŒ‡æ¨™"""
        
        metrics = {
            "connected": False,
            "memory_usage": 0,
            "connected_clients": 0,
            "total_commands_processed": 0,
            "queue_sizes": {}
        }
        
        if self.redis_client:
            try:
                info = self.redis_client.info()
                metrics.update({
                    "connected": True,
                    "memory_usage": info.get("used_memory", 0),
                    "connected_clients": info.get("connected_clients", 0),
                    "total_commands_processed": info.get("total_commands_processed", 0)
                })
                
                # ç²å–éšŠåˆ—å¤§å°
                queue_keys = self.redis_client.keys("scheduler:queue:*")
                for key in queue_keys:
                    queue_name = key.decode('utf-8').split(':')[-1]
                    size = self.redis_client.llen(key)
                    metrics["queue_sizes"][queue_name] = size
                    
            except Exception as e:
                print(f"ç²å–RedisæŒ‡æ¨™å¤±æ•—: {e}")
        
        return metrics

    def collect_metrics(self) -> Dict:
        """æ”¶é›†æ‰€æœ‰æŒ‡æ¨™"""
        
        metrics = {
            "timestamp": datetime.now().isoformat(),
            "scheduler": self.get_scheduler_status(),
            "performance": self.get_performance_metrics(),
            "system": self.get_system_metrics(),
            "redis": self.get_redis_metrics()
        }
        
        return metrics

    def check_alerts(self, metrics: Dict) -> List[Dict]:
        """æª¢æŸ¥è­¦å ±æ¢ä»¶"""
        
        alerts = []
        
        # æª¢æŸ¥ç³»çµ±æŒ‡æ¨™
        system_metrics = metrics.get("system", {})
        
        if system_metrics.get("cpu_usage", 0) > self.alert_thresholds["cpu_usage"]:
            alerts.append({
                "type": "warning",
                "message": f"CPUä½¿ç”¨ç‡éé«˜: {system_metrics['cpu_usage']:.1f}%",
                "timestamp": metrics["timestamp"]
            })
        
        if system_metrics.get("memory_usage", 0) > self.alert_thresholds["memory_usage"]:
            alerts.append({
                "type": "warning",
                "message": f"è¨˜æ†¶é«”ä½¿ç”¨ç‡éé«˜: {system_metrics['memory_usage']:.1f}%",
                "timestamp": metrics["timestamp"]
            })
        
        # æª¢æŸ¥RediséšŠåˆ—
        redis_metrics = metrics.get("redis", {})
        queue_sizes = redis_metrics.get("queue_sizes", {})
        
        for queue_name, size in queue_sizes.items():
            if size > self.alert_thresholds["queue_size"]:
                alerts.append({
                    "type": "warning",
                    "message": f"éšŠåˆ— {queue_name} ç©å£“éå¤š: {size} å€‹ä»»å‹™",
                    "timestamp": metrics["timestamp"]
                })
        
        # æª¢æŸ¥èª¿åº¦å™¨ç‹€æ…‹
        scheduler_metrics = metrics.get("scheduler", {})
        if scheduler_metrics and not scheduler_metrics.get("is_running", False):
            alerts.append({
                "type": "error",
                "message": "èª¿åº¦å™¨æœªé‹è¡Œ",
                "timestamp": metrics["timestamp"]
            })
        
        return alerts

    def display_metrics_table(self, metrics: Dict):
        """é¡¯ç¤ºæŒ‡æ¨™è¡¨æ ¼"""
        
        if not RICH_AVAILABLE:
            self._display_metrics_simple(metrics)
            return
        
        # å‰µå»ºä½ˆå±€
        layout = Layout()
        layout.split_column(
            Layout(name="header", size=3),
            Layout(name="body"),
            Layout(name="footer", size=3)
        )
        
        layout["body"].split_row(
            Layout(name="left"),
            Layout(name="right")
        )
        
        # æ¨™é¡Œ
        layout["header"].update(
            Panel(f"LLM JSONèª¿åº¦å™¨ç›£æ§ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", 
                  style="bold blue")
        )
        
        # ç³»çµ±æŒ‡æ¨™è¡¨æ ¼
        system_table = Table(title="ç³»çµ±æŒ‡æ¨™", show_header=True, header_style="bold magenta")
        system_table.add_column("æŒ‡æ¨™", style="cyan")
        system_table.add_column("æ•¸å€¼", style="green")
        system_table.add_column("ç‹€æ…‹", style="yellow")
        
        system_metrics = metrics.get("system", {})
        cpu_usage = system_metrics.get("cpu_usage", 0)
        memory_usage = system_metrics.get("memory_usage", 0)
        disk_usage = system_metrics.get("disk_usage", 0)
        
        system_table.add_row(
            "CPUä½¿ç”¨ç‡", 
            f"{cpu_usage:.1f}%", 
            "ğŸ”´ é«˜" if cpu_usage > 80 else "ğŸŸ¡ ä¸­" if cpu_usage > 50 else "ğŸŸ¢ æ­£å¸¸"
        )
        system_table.add_row(
            "è¨˜æ†¶é«”ä½¿ç”¨ç‡", 
            f"{memory_usage:.1f}%", 
            "ğŸ”´ é«˜" if memory_usage > 85 else "ğŸŸ¡ ä¸­" if memory_usage > 70 else "ğŸŸ¢ æ­£å¸¸"
        )
        system_table.add_row(
            "ç£ç¢Ÿä½¿ç”¨ç‡", 
            f"{disk_usage:.1f}%", 
            "ğŸ”´ é«˜" if disk_usage > 90 else "ğŸŸ¡ ä¸­" if disk_usage > 80 else "ğŸŸ¢ æ­£å¸¸"
        )
        
        layout["left"].update(system_table)
        
        # èª¿åº¦å™¨ç‹€æ…‹è¡¨æ ¼
        scheduler_table = Table(title="èª¿åº¦å™¨ç‹€æ…‹", show_header=True, header_style="bold magenta")
        scheduler_table.add_column("é …ç›®", style="cyan")
        scheduler_table.add_column("æ•¸å€¼", style="green")
        
        scheduler_metrics = metrics.get("scheduler", {})
        if scheduler_metrics:
            scheduler_table.add_row("é‹è¡Œç‹€æ…‹", "ğŸŸ¢ é‹è¡Œä¸­" if scheduler_metrics.get("is_running") else "ğŸ”´ å·²åœæ­¢")
            
            stats = scheduler_metrics.get("scheduler_stats", {})
            scheduler_table.add_row("å·²è™•ç†æª”æ¡ˆ", str(stats.get("total_files_processed", 0)))
            scheduler_table.add_row("è™•ç†æˆåŠŸ", str(stats.get("successful_tasks", 0)))
            scheduler_table.add_row("è™•ç†å¤±æ•—", str(stats.get("failed_tasks", 0)))
            
            worker_stats = scheduler_metrics.get("worker_stats", {})
            scheduler_table.add_row("æ´»èºå·¥ä½œç·šç¨‹", str(worker_stats.get("active_workers", 0)))
            scheduler_table.add_row("ç¸½å·¥ä½œç·šç¨‹", str(worker_stats.get("total_workers", 0)))
        else:
            scheduler_table.add_row("ç‹€æ…‹", "ğŸ”´ ç„¡æ³•é€£æ¥")
        
        layout["right"].update(scheduler_table)
        
        # Rediså’ŒéšŠåˆ—ç‹€æ…‹
        redis_info = []
        redis_metrics = metrics.get("redis", {})
        
        if redis_metrics.get("connected"):
            redis_info.append(f"ğŸŸ¢ Rediså·²é€£æ¥ ({redis_metrics.get('connected_clients', 0)} å€‹å®¢æˆ¶ç«¯)")
            
            queue_sizes = redis_metrics.get("queue_sizes", {})
            if queue_sizes:
                redis_info.append("éšŠåˆ—ç‹€æ…‹:")
                for queue_name, size in queue_sizes.items():
                    status_icon = "ğŸ”´" if size > 1000 else "ğŸŸ¡" if size > 100 else "ğŸŸ¢"
                    redis_info.append(f"  {status_icon} {queue_name}: {size} å€‹ä»»å‹™")
        else:
            redis_info.append("ğŸ”´ Redisé€£æ¥å¤±æ•—")
        
        layout["footer"].update(
            Panel("\n".join(redis_info), title="Redisç‹€æ…‹", style="bold yellow")
        )
        
        self.console.clear()
        self.console.print(layout)

    def _display_metrics_simple(self, metrics: Dict):
        """ç°¡å–®æ–‡æœ¬é¡¯ç¤ºæŒ‡æ¨™"""
        
        print("\n" + "="*60)
        print(f"LLM JSONèª¿åº¦å™¨ç›£æ§ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*60)
        
        # ç³»çµ±æŒ‡æ¨™
        print("\nç³»çµ±æŒ‡æ¨™:")
        print("-" * 20)
        system_metrics = metrics.get("system", {})
        print(f"CPUä½¿ç”¨ç‡: {system_metrics.get('cpu_usage', 0):.1f}%")
        print(f"è¨˜æ†¶é«”ä½¿ç”¨ç‡: {system_metrics.get('memory_usage', 0):.1f}%")
        print(f"ç£ç¢Ÿä½¿ç”¨ç‡: {system_metrics.get('disk_usage', 0):.1f}%")
        
        # èª¿åº¦å™¨ç‹€æ…‹
        print("\nèª¿åº¦å™¨ç‹€æ…‹:")
        print("-" * 20)
        scheduler_metrics = metrics.get("scheduler", {})
        if scheduler_metrics:
            print(f"é‹è¡Œç‹€æ…‹: {'é‹è¡Œä¸­' if scheduler_metrics.get('is_running') else 'å·²åœæ­¢'}")
            
            stats = scheduler_metrics.get("scheduler_stats", {})
            print(f"å·²è™•ç†æª”æ¡ˆ: {stats.get('total_files_processed', 0)}")
            print(f"è™•ç†æˆåŠŸ: {stats.get('successful_tasks', 0)}")
            print(f"è™•ç†å¤±æ•—: {stats.get('failed_tasks', 0)}")
            
            worker_stats = scheduler_metrics.get("worker_stats", {})
            print(f"æ´»èºå·¥ä½œç·šç¨‹: {worker_stats.get('active_workers', 0)}")
            print(f"ç¸½å·¥ä½œç·šç¨‹: {worker_stats.get('total_workers', 0)}")
        else:
            print("ç‹€æ…‹: ç„¡æ³•é€£æ¥")
        
        # Redisç‹€æ…‹
        print("\nRedisç‹€æ…‹:")
        print("-" * 20)
        redis_metrics = metrics.get("redis", {})
        if redis_metrics.get("connected"):
            print(f"é€£æ¥ç‹€æ…‹: å·²é€£æ¥ ({redis_metrics.get('connected_clients', 0)} å€‹å®¢æˆ¶ç«¯)")
            
            queue_sizes = redis_metrics.get("queue_sizes", {})
            if queue_sizes:
                print("éšŠåˆ—ç‹€æ…‹:")
                for queue_name, size in queue_sizes.items():
                    print(f"  {queue_name}: {size} å€‹ä»»å‹™")
        else:
            print("é€£æ¥ç‹€æ…‹: é€£æ¥å¤±æ•—")

    def start_monitoring(self, interval: int = 5):
        """é–‹å§‹å¯¦æ™‚ç›£æ§"""
        
        print(f"é–‹å§‹ç›£æ§èª¿åº¦å™¨ (åˆ·æ–°é–“éš”: {interval}ç§’)")
        print("æŒ‰ Ctrl+C åœæ­¢ç›£æ§")
        
        self.monitoring = True
        
        try:
            while self.monitoring:
                metrics = self.collect_metrics()
                self.metrics_history.append(metrics)
                
                # æª¢æŸ¥è­¦å ±
                alerts = self.check_alerts(metrics)
                if alerts:
                    for alert in alerts:
                        print(f"\nâš ï¸  è­¦å ±: {alert['message']}")
                
                # é¡¯ç¤ºæŒ‡æ¨™
                self.display_metrics_table(metrics)
                
                time.sleep(interval)
                
        except KeyboardInterrupt:
            print("\nç›£æ§å·²åœæ­¢")
            self.monitoring = False

    def generate_report(self, hours: int = 24) -> Dict:
        """ç”Ÿæˆæ€§èƒ½å ±å‘Š"""
        
        print(f"æ­£åœ¨ç”Ÿæˆéå» {hours} å°æ™‚çš„æ€§èƒ½å ±å‘Š...")
        
        # æ”¶é›†ç•¶å‰æŒ‡æ¨™
        current_metrics = self.collect_metrics()
        
        # ç²å–ä»»å‹™çµ±è¨ˆ
        tasks = self.get_task_list(limit=1000)
        
        # åˆ†æä»»å‹™ç‹€æ…‹
        task_stats = defaultdict(int)
        if tasks:
            for task in tasks:
                task_stats[task.get("status", "unknown")] += 1
        
        # ç”Ÿæˆå ±å‘Š
        report = {
            "generated_at": datetime.now().isoformat(),
            "period_hours": hours,
            "current_status": {
                "scheduler_running": current_metrics.get("scheduler", {}).get("is_running", False),
                "redis_connected": current_metrics.get("redis", {}).get("connected", False),
                "system_health": self._assess_system_health(current_metrics)
            },
            "task_statistics": dict(task_stats),
            "performance_summary": {
                "total_tasks": sum(task_stats.values()),
                "success_rate": (task_stats.get("completed", 0) / max(sum(task_stats.values()), 1)) * 100,
                "error_rate": (task_stats.get("failed", 0) / max(sum(task_stats.values()), 1)) * 100
            },
            "system_metrics": current_metrics.get("system", {}),
            "recommendations": self._generate_recommendations(current_metrics, task_stats)
        }
        
        return report

    def _assess_system_health(self, metrics: Dict) -> str:
        """è©•ä¼°ç³»çµ±å¥åº·ç‹€æ³"""
        
        system_metrics = metrics.get("system", {})
        scheduler_metrics = metrics.get("scheduler", {})
        redis_metrics = metrics.get("redis", {})
        
        # æª¢æŸ¥é—œéµæŒ‡æ¨™
        issues = []
        
        if not scheduler_metrics.get("is_running", False):
            issues.append("èª¿åº¦å™¨æœªé‹è¡Œ")
        
        if not redis_metrics.get("connected", False):
            issues.append("Redisé€£æ¥å¤±æ•—")
        
        if system_metrics.get("cpu_usage", 0) > 80:
            issues.append("CPUä½¿ç”¨ç‡éé«˜")
        
        if system_metrics.get("memory_usage", 0) > 85:
            issues.append("è¨˜æ†¶é«”ä½¿ç”¨ç‡éé«˜")
        
        if issues:
            return f"ä¸è‰¯ ({', '.join(issues)})"
        elif (system_metrics.get("cpu_usage", 0) > 50 or 
              system_metrics.get("memory_usage", 0) > 70):
            return "ä¸€èˆ¬"
        else:
            return "è‰¯å¥½"

    def _generate_recommendations(self, metrics: Dict, task_stats: Dict) -> List[str]:
        """ç”Ÿæˆå„ªåŒ–å»ºè­°"""
        
        recommendations = []
        
        system_metrics = metrics.get("system", {})
        scheduler_metrics = metrics.get("scheduler", {})
        redis_metrics = metrics.get("redis", {})
        
        # ç³»çµ±è³‡æºå»ºè­°
        if system_metrics.get("cpu_usage", 0) > 80:
            recommendations.append("è€ƒæ…®å¢åŠ CPUè³‡æºæˆ–æ¸›å°‘ä¸¦ç™¼å·¥ä½œç·šç¨‹æ•¸é‡")
        
        if system_metrics.get("memory_usage", 0) > 85:
            recommendations.append("è€ƒæ…®å¢åŠ è¨˜æ†¶é«”æˆ–å„ªåŒ–è¨˜æ†¶é«”ä½¿ç”¨")
        
        # ä»»å‹™è™•ç†å»ºè­°
        total_tasks = sum(task_stats.values())
        if total_tasks > 0:
            error_rate = (task_stats.get("failed", 0) / total_tasks) * 100
            if error_rate > 10:
                recommendations.append("éŒ¯èª¤ç‡è¼ƒé«˜ï¼Œå»ºè­°æª¢æŸ¥ä»»å‹™è™•ç†é‚è¼¯å’ŒéŒ¯èª¤æ—¥èªŒ")
        
        # éšŠåˆ—å»ºè­°
        queue_sizes = redis_metrics.get("queue_sizes", {})
        for queue_name, size in queue_sizes.items():
            if size > 1000:
                recommendations.append(f"éšŠåˆ— {queue_name} ç©å£“åš´é‡ï¼Œå»ºè­°å¢åŠ å·¥ä½œç·šç¨‹æˆ–å„ªåŒ–è™•ç†é€Ÿåº¦")
        
        # å·¥ä½œç·šç¨‹å»ºè­°
        worker_stats = scheduler_metrics.get("worker_stats", {})
        active_workers = worker_stats.get("active_workers", 0)
        total_workers = worker_stats.get("total_workers", 0)
        
        if total_workers > 0 and (active_workers / total_workers) > 0.9:
            recommendations.append("å·¥ä½œç·šç¨‹ä½¿ç”¨ç‡å¾ˆé«˜ï¼Œè€ƒæ…®å¢åŠ å·¥ä½œç·šç¨‹æ•¸é‡")
        
        if not recommendations:
            recommendations.append("ç³»çµ±é‹è¡Œè‰¯å¥½ï¼Œç„¡éœ€ç‰¹åˆ¥å„ªåŒ–")
        
        return recommendations

    def save_report(self, report: Dict, filename: str = None):
        """ä¿å­˜å ±å‘Šåˆ°æª”æ¡ˆ"""
        
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"scheduler_report_{timestamp}.json"
        
        report_path = Path(filename)
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"å ±å‘Šå·²ä¿å­˜åˆ°: {report_path.absolute()}")

    def restart_scheduler(self) -> bool:
        """é‡å•Ÿèª¿åº¦å™¨"""
        
        print("æ­£åœ¨é‡å•Ÿèª¿åº¦å™¨...")
        
        result = self._make_api_request("/restart", method="POST")
        
        if result and result.get("success"):
            print("èª¿åº¦å™¨é‡å•ŸæˆåŠŸ")
            return True
        else:
            print("èª¿åº¦å™¨é‡å•Ÿå¤±æ•—")
            return False

    def update_config(self, config_updates: Dict) -> bool:
        """æ›´æ–°é…ç½®"""
        
        print("æ­£åœ¨æ›´æ–°é…ç½®...")
        
        result = self._make_api_request("/config", method="PUT", data=config_updates)
        
        if result and result.get("success"):
            print("é…ç½®æ›´æ–°æˆåŠŸ")
            return True
        else:
            print("é…ç½®æ›´æ–°å¤±æ•—")
            return False


def main():
    """ä¸»ç¨‹åºå…¥å£"""
    
    parser = argparse.ArgumentParser(description="LLM JSONèª¿åº¦å™¨ç›£æ§å·¥å…·")
    parser.add_argument("action", 
                       choices=["monitor", "status", "report", "restart", "tasks"],
                       help="è¦åŸ·è¡Œçš„æ“ä½œ")
    parser.add_argument("--config", default="scheduler_config.json",
                       help="é…ç½®æª”æ¡ˆè·¯å¾‘")
    parser.add_argument("--api-url", 
                       help="APIåŸºç¤URL (ä¾‹å¦‚: http://localhost:8080)")
    parser.add_argument("--interval", type=int, default=5,
                       help="ç›£æ§åˆ·æ–°é–“éš”ï¼ˆç§’ï¼‰")
    parser.add_argument("--hours", type=int, default=24,
                       help="å ±å‘Šæ™‚é–“ç¯„åœï¼ˆå°æ™‚ï¼‰")
    parser.add_argument("--output", 
                       help="å ±å‘Šè¼¸å‡ºæª”æ¡ˆå")
    parser.add_argument("--task-status", 
                       choices=["pending", "processing", "completed", "failed"],
                       help="éæ¿¾ä»»å‹™ç‹€æ…‹")
    parser.add_argument("--limit", type=int, default=50,
                       help="ä»»å‹™åˆ—è¡¨é™åˆ¶æ•¸é‡")
    
    args = parser.parse_args()
    
    monitor = SchedulerMonitor(args.config, args.api_url)
    
    if args.action == "monitor":
        monitor.start_monitoring(args.interval)
    
    elif args.action == "status":
        metrics = monitor.collect_metrics()
        monitor.display_metrics_table(metrics)
    
    elif args.action == "report":
        report = monitor.generate_report(args.hours)
        
        # é¡¯ç¤ºå ±å‘Šæ‘˜è¦
        print("\n" + "="*60)
        print("æ€§èƒ½å ±å‘Šæ‘˜è¦")
        print("="*60)
        print(f"ç”Ÿæˆæ™‚é–“: {report['generated_at']}")
        print(f"æ™‚é–“ç¯„åœ: éå» {report['period_hours']} å°æ™‚")
        print(f"ç³»çµ±å¥åº·: {report['current_status']['system_health']}")
        print(f"ç¸½ä»»å‹™æ•¸: {report['performance_summary']['total_tasks']}")
        print(f"æˆåŠŸç‡: {report['performance_summary']['success_rate']:.1f}%")
        print(f"éŒ¯èª¤ç‡: {report['performance_summary']['error_rate']:.1f}%")
        
        print("\nå„ªåŒ–å»ºè­°:")
        for i, rec in enumerate(report['recommendations'], 1):
            print(f"{i}. {rec}")
        
        # ä¿å­˜å ±å‘Š
        if args.output:
            monitor.save_report(report, args.output)
        else:
            monitor.save_report(report)
    
    elif args.action == "restart":
        monitor.restart_scheduler()
    
    elif args.action == "tasks":
        tasks = monitor.get_task_list(args.task_status, args.limit)
        
        if tasks:
            print(f"\næ‰¾åˆ° {len(tasks)} å€‹ä»»å‹™:")
            print("-" * 80)
            
            for task in tasks:
                print(f"ID: {task.get('id', 'N/A')}")
                print(f"ç‹€æ…‹: {task.get('status', 'N/A')}")
                print(f"é¡å‹: {task.get('task_type', 'N/A')}")
                print(f"å‰µå»ºæ™‚é–“: {task.get('created_at', 'N/A')}")
                if task.get('error_message'):
                    print(f"éŒ¯èª¤: {task['error_message']}")
                print("-" * 40)
        else:
            print("æœªæ‰¾åˆ°ä»»å‹™æˆ–ç„¡æ³•é€£æ¥åˆ°API")


if __name__ == "__main__":
    main()