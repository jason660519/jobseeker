#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç°¡å–®çš„LLM APIæ¸¬è©¦
æ¸¬è©¦å¯ç”¨çš„LLMæä¾›å•†ä¸¦é©—è­‰æ„åœ–åˆ†æåŠŸèƒ½

Author: jobseeker Team
Date: 2025-01-27
"""

import os
import json
import time
from typing import Dict, Any

def test_openai_with_litellm():
    """ä½¿ç”¨LiteLLMæ¸¬è©¦OpenAI API"""
    print("ğŸ§ª æ¸¬è©¦OpenAI API (é€šéLiteLLM)...")
    
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("  âŒ OpenAI APIå¯†é‘°æœªè¨­ç½®")
        return False
    
    try:
        import litellm
        
        # è¨­ç½®APIå¯†é‘°
        os.environ["OPENAI_API_KEY"] = api_key
        
        # ç°¡å–®çš„æ¸¬è©¦æ¶ˆæ¯
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹æ±‚è·æ„åœ–åˆ†æåŠ©æ‰‹ã€‚è«‹ç”¨JSONæ ¼å¼å›æ‡‰ã€‚"},
            {"role": "user", "content": "æˆ‘æƒ³æ‰¾Pythonå·¥ç¨‹å¸«çš„å·¥ä½œ"}
        ]
        
        print("  ğŸ“¤ ç™¼é€APIè«‹æ±‚...")
        start_time = time.time()
        
        response = litellm.completion(
            model="gpt-3.5-turbo",
            messages=messages,
            max_tokens=200,
            temperature=0.1
        )
        
        end_time = time.time()
        response_time = end_time - start_time
        
        print(f"  âœ… APIèª¿ç”¨æˆåŠŸ ({response_time:.2f}s)")
        print(f"  ğŸ“ éŸ¿æ‡‰å…§å®¹: {response.choices[0].message.content[:100]}...")
        
        if hasattr(response, 'usage'):
            usage = response.usage
            print(f"  ğŸ“Š Tokenä½¿ç”¨: {usage.prompt_tokens} + {usage.completion_tokens} = {usage.total_tokens}")
        
        return True
        
    except Exception as e:
        print(f"  âŒ OpenAIæ¸¬è©¦å¤±æ•—: {e}")
        return False

def test_anthropic_with_litellm():
    """ä½¿ç”¨LiteLLMæ¸¬è©¦Anthropic API"""
    print("\nğŸ§ª æ¸¬è©¦Anthropic API (é€šéLiteLLM)...")
    
    api_key = os.getenv("ANTHROPIC_API_KEY")
    if not api_key:
        print("  âŒ Anthropic APIå¯†é‘°æœªè¨­ç½®")
        return False
    
    try:
        import litellm
        
        # è¨­ç½®APIå¯†é‘°
        os.environ["ANTHROPIC_API_KEY"] = api_key
        
        # ç°¡å–®çš„æ¸¬è©¦æ¶ˆæ¯
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹æ±‚è·æ„åœ–åˆ†æåŠ©æ‰‹ã€‚è«‹ç”¨JSONæ ¼å¼å›æ‡‰ã€‚"},
            {"role": "user", "content": "å°åŒ—çš„å‰ç«¯é–‹ç™¼è·ä½"}
        ]
        
        print("  ğŸ“¤ ç™¼é€APIè«‹æ±‚...")
        start_time = time.time()
        
        # ä½¿ç”¨æ­£ç¢ºçš„Anthropicæ¨¡å‹åç¨±
        response = litellm.completion(
            model="anthropic/claude-3-haiku-20240307",
            messages=messages,
            max_tokens=200,
            temperature=0.1
        )
        
        end_time = time.time()
        response_time = end_time - start_time
        
        print(f"  âœ… APIèª¿ç”¨æˆåŠŸ ({response_time:.2f}s)")
        print(f"  ğŸ“ éŸ¿æ‡‰å…§å®¹: {response.choices[0].message.content[:100]}...")
        
        if hasattr(response, 'usage'):
            usage = response.usage
            print(f"  ğŸ“Š Tokenä½¿ç”¨: {usage.prompt_tokens} + {usage.completion_tokens} = {usage.total_tokens}")
        
        return True
        
    except Exception as e:
        print(f"  âŒ Anthropicæ¸¬è©¦å¤±æ•—: {e}")
        return False

def test_intent_analysis():
    """æ¸¬è©¦æ„åœ–åˆ†æåŠŸèƒ½"""
    print("\nğŸ§  æ¸¬è©¦æ„åœ–åˆ†æåŠŸèƒ½...")
    
    # é¸æ“‡å¯ç”¨çš„æä¾›å•†
    openai_key = os.getenv("OPENAI_API_KEY")
    anthropic_key = os.getenv("ANTHROPIC_API_KEY")
    
    if not openai_key and not anthropic_key:
        print("  âŒ æ²’æœ‰å¯ç”¨çš„APIå¯†é‘°")
        return False
    
    try:
        import litellm
        
        # é¸æ“‡æ¨¡å‹
        if openai_key:
            model = "gpt-3.5-turbo"
            print("  ğŸ¤– ä½¿ç”¨OpenAIæ¨¡å‹")
        else:
            model = "anthropic/claude-3-haiku-20240307"
            print("  ğŸ¤– ä½¿ç”¨Anthropicæ¨¡å‹")
        
        # æ„åœ–åˆ†ææç¤º
        system_prompt = """
ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æ±‚è·æ„åœ–åˆ†æAIåŠ©æ‰‹ã€‚è«‹åˆ†æç”¨æˆ¶æŸ¥è©¢ä¸¦ä»¥JSONæ ¼å¼å›æ‡‰ï¼š

{
  "is_job_related": boolean,
  "intent_type": "job_search" | "career_advice" | "non_job_related",
  "confidence": float (0.0-1.0),
  "reasoning": "åˆ†æåŸå› ",
  "structured_intent": {
    "job_titles": ["è·ä½åç¨±"],
    "skills": ["æŠ€èƒ½é—œéµè©"],
    "locations": ["åœ°é»"]
  }
}
"""
        
        test_queries = [
            "æˆ‘æƒ³æ‰¾AIå·¥ç¨‹å¸«çš„å·¥ä½œ",
            "ä»Šå¤©å¤©æ°£å¦‚ä½•ï¼Ÿ"
        ]
        
        for query in test_queries:
            print(f"\n  ğŸ“ æ¸¬è©¦æŸ¥è©¢: {query}")
            
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"è«‹åˆ†æé€™å€‹æŸ¥è©¢: {query}"}
            ]
            
            try:
                response = litellm.completion(
                    model=model,
                    messages=messages,
                    max_tokens=300,
                    temperature=0.1
                )
                
                content = response.choices[0].message.content
                print(f"    ğŸ“¤ éŸ¿æ‡‰: {content[:150]}...")
                
                # å˜—è©¦è§£æJSON
                try:
                    analysis = json.loads(content)
                    is_job_related = analysis.get('is_job_related', False)
                    confidence = analysis.get('confidence', 0.0)
                    print(f"    âœ… æ±‚è·ç›¸é—œ: {is_job_related}, ç½®ä¿¡åº¦: {confidence}")
                except json.JSONDecodeError:
                    print("    âš ï¸  éŸ¿æ‡‰ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼")
                
            except Exception as e:
                print(f"    âŒ æŸ¥è©¢å¤±æ•—: {e}")
        
        return True
        
    except Exception as e:
        print(f"  âŒ æ„åœ–åˆ†ææ¸¬è©¦å¤±æ•—: {e}")
        return False

def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("ğŸš€ ç°¡å–®LLM APIæ¸¬è©¦é–‹å§‹...")
    print("=" * 50)
    
    # æª¢æŸ¥LiteLLMå°å…¥
    try:
        import litellm
        print("âœ… LiteLLMå°å…¥æˆåŠŸ")
    except ImportError:
        print("âŒ LiteLLMå°å…¥å¤±æ•—ï¼Œè«‹å®‰è£: pip install litellm")
        return
    
    # æ¸¬è©¦çµæœ
    results = []
    
    # æ¸¬è©¦OpenAI
    if os.getenv("OPENAI_API_KEY"):
        results.append(("OpenAI", test_openai_with_litellm()))
    else:
        print("âš ï¸  è·³éOpenAIæ¸¬è©¦ - APIå¯†é‘°æœªè¨­ç½®")
    
    # æ¸¬è©¦Anthropic
    if os.getenv("ANTHROPIC_API_KEY"):
        results.append(("Anthropic", test_anthropic_with_litellm()))
    else:
        print("âš ï¸  è·³éAnthropicæ¸¬è©¦ - APIå¯†é‘°æœªè¨­ç½®")
    
    # æ¸¬è©¦æ„åœ–åˆ†æ
    if any(result[1] for result in results):
        results.append(("æ„åœ–åˆ†æ", test_intent_analysis()))
    
    # ç¸½çµ
    print("\n" + "=" * 50)
    print("ğŸ“‹ æ¸¬è©¦ç¸½çµ")
    print("=" * 50)
    
    success_count = 0
    for test_name, success in results:
        status = "âœ… æˆåŠŸ" if success else "âŒ å¤±æ•—"
        print(f"  {test_name}: {status}")
        if success:
            success_count += 1
    
    if success_count > 0:
        print(f"\nğŸ‰ {success_count}/{len(results)} é …æ¸¬è©¦æˆåŠŸ!")
        print("ğŸ’¡ LiteLLMå·²æ­£ç¢ºå®‰è£ä¸¦å¯ä»¥ä½¿ç”¨")
        print("ğŸ“ æ‚¨å¯ä»¥åœ¨æ‡‰ç”¨ç¨‹åºä¸­ä½¿ç”¨LLMåŠŸèƒ½")
    else:
        print("\nâŒ æ‰€æœ‰æ¸¬è©¦å¤±æ•—")
        print("ğŸ’¡ è«‹æª¢æŸ¥APIå¯†é‘°è¨­ç½®å’Œç¶²çµ¡é€£æ¥")

if __name__ == "__main__":
    main()