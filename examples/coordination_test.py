#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¦–è¦ºçˆ¬èŸ²èˆ‡å‚³çµ±çˆ¬èŸ²å”èª¿æ©Ÿåˆ¶æ¸¬è©¦è…³æœ¬

æ­¤è…³æœ¬å°ˆé–€æ¸¬è©¦å„ªåŒ–å¾Œçš„å”èª¿æ©Ÿåˆ¶ï¼ŒåŒ…æ‹¬ï¼š
1. æ™ºèƒ½ç­–ç•¥é¸æ“‡
2. å‹•æ…‹æ€§èƒ½è©•ä¼°
3. æ··åˆæ¨¡å¼åŸ·è¡Œ
4. æ€§èƒ½ç›£æ§èˆ‡åé¥‹
"""

import asyncio
import sys
import time
from pathlib import Path
from typing import Dict, Any

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°è·¯å¾‘
sys.path.append(str(Path(__file__).parent.parent))

from jobseeker.seek.enhanced_etl_orchestrator import (
    EnhancedETLOrchestrator,
    ScrapingJobConfig,
    ScrapingStrategy
)
from jobseeker.enhanced_logging import get_enhanced_logger

class CoordinationTester:
    """
    å”èª¿æ©Ÿåˆ¶æ¸¬è©¦å™¨
    """
    
    def __init__(self):
        self.logger = get_enhanced_logger(self.__class__.__name__)
        self.orchestrator = EnhancedETLOrchestrator("coordination_test_output")
        self.test_results = []
    
    async def test_strategy_selection(self):
        """
        æ¸¬è©¦æ™ºèƒ½ç­–ç•¥é¸æ“‡åŠŸèƒ½
        """
        self.logger.info("é–‹å§‹æ¸¬è©¦æ™ºèƒ½ç­–ç•¥é¸æ“‡...")
        
        test_configs = [
            # å°æ•¸æ“šé‡æ¸¬è©¦
            ScrapingJobConfig(
                search_term="python developer",
                max_results=10,
                high_quality_required=True
            ),
            # å¤§æ•¸æ“šé‡æ¸¬è©¦
            ScrapingJobConfig(
                search_term="data scientist",
                max_results=100,
                large_volume_required=True
            ),
            # å¹³è¡¡æ¸¬è©¦
            ScrapingJobConfig(
                search_term="software engineer",
                max_results=50
            )
        ]
        
        for i, config in enumerate(test_configs, 1):
            self.logger.info(f"æ¸¬è©¦é…ç½® {i}: {config.search_term}")
            
            # ç²å–ç­–ç•¥é¸æ“‡å™¨æ¨è–¦çš„ç­–ç•¥
            selected_strategy = self.orchestrator.strategy_selector.select_strategy(config)
            self.logger.info(f"é¸æ“‡çš„ç­–ç•¥: {selected_strategy.value}")
            
            # è¨˜éŒ„ç­–ç•¥é¸æ“‡çµæœ
            self.test_results.append({
                'test_type': 'strategy_selection',
                'config': config.search_term,
                'selected_strategy': selected_strategy.value,
                'max_results': config.max_results,
                'high_quality': config.high_quality_required,
                'large_volume': config.large_volume_required
            })
    
    async def test_performance_tracking(self):
        """
        æ¸¬è©¦æ€§èƒ½è¿½è¹¤åŠŸèƒ½
        """
        self.logger.info("é–‹å§‹æ¸¬è©¦æ€§èƒ½è¿½è¹¤...")
        
        # æ¨¡æ“¬ä¸åŒç­–ç•¥çš„æ€§èƒ½æ•¸æ“š
        performance_data = [
            (ScrapingStrategy.VISUAL_ONLY, True, 15.5, 0.9, 25),
            (ScrapingStrategy.TRADITIONAL_ONLY, True, 8.2, 0.7, 15),
            (ScrapingStrategy.HYBRID, True, 22.1, 0.85, 40),
            (ScrapingStrategy.VISUAL_PRIMARY, False, 30.0, 0.6, 5),
            (ScrapingStrategy.TRADITIONAL_PRIMARY, True, 12.3, 0.8, 20)
        ]
        
        for strategy, success, exec_time, quality, job_count in performance_data:
            self.orchestrator.strategy_selector.update_strategy_performance(
                strategy, success, exec_time, quality, job_count
            )
            self.logger.info(f"æ›´æ–°ç­–ç•¥ {strategy.value} æ€§èƒ½: æˆåŠŸ={success}, æ™‚é–“={exec_time}s, è³ªé‡={quality}")
        
        # æª¢æŸ¥æ€§èƒ½çµ±è¨ˆ
        for strategy in ScrapingStrategy:
            stats = self.orchestrator.strategy_selector.strategy_performance.get(strategy, {})
            if stats:
                self.logger.info(f"ç­–ç•¥ {strategy.value} çµ±è¨ˆ: {stats}")
    
    async def test_hybrid_execution(self):
        """
        æ¸¬è©¦æ··åˆæ¨¡å¼åŸ·è¡Œ
        """
        self.logger.info("é–‹å§‹æ¸¬è©¦æ··åˆæ¨¡å¼åŸ·è¡Œ...")
        
        # å‰µå»ºæ··åˆæ¨¡å¼é…ç½®
        hybrid_config = ScrapingJobConfig(
            search_term="machine learning",
            strategy=ScrapingStrategy.HYBRID,
            max_results=30,
            timeout=60
        )
        
        start_time = time.time()
        
        try:
            # åŸ·è¡Œæ··åˆæ¨¡å¼ä»»å‹™
            result = await self.orchestrator.execute_scraping_job(hybrid_config)
            execution_time = time.time() - start_time
            
            self.logger.info(f"æ··åˆæ¨¡å¼åŸ·è¡Œå®Œæˆ: {execution_time:.2f}ç§’")
            self.logger.info(f"çµæœæ‘˜è¦: {result.get('summary', {})}")
            
            # è¨˜éŒ„æ¸¬è©¦çµæœ
            self.test_results.append({
                'test_type': 'hybrid_execution',
                'execution_time': execution_time,
                'job_count': result.get('summary', {}).get('total_jobs', 0),
                'data_sources': len(result.get('data_sources', [])),
                'success': result.get('success', False)
            })
            
        except Exception as e:
            self.logger.error(f"æ··åˆæ¨¡å¼åŸ·è¡Œå¤±æ•—: {e}")
            self.test_results.append({
                'test_type': 'hybrid_execution',
                'error': str(e),
                'success': False
            })
    
    async def test_adaptive_coordination(self):
        """
        æ¸¬è©¦è‡ªé©æ‡‰å”èª¿åŠŸèƒ½
        """
        self.logger.info("é–‹å§‹æ¸¬è©¦è‡ªé©æ‡‰å”èª¿...")
        
        # æ¸¬è©¦ä¸åŒå ´æ™¯ä¸‹çš„ç­–ç•¥é©æ‡‰
        scenarios = [
            {
                'name': 'é«˜è³ªé‡éœ€æ±‚å ´æ™¯',
                'config': ScrapingJobConfig(
                    search_term="senior developer",
                    high_quality_required=True,
                    max_results=20
                )
            },
            {
                'name': 'å¤§æ•¸æ“šé‡å ´æ™¯',
                'config': ScrapingJobConfig(
                    search_term="developer",
                    large_volume_required=True,
                    max_results=200
                )
            },
            {
                'name': 'å¹³è¡¡å ´æ™¯',
                'config': ScrapingJobConfig(
                    search_term="python",
                    max_results=50
                )
            }
        ]
        
        for scenario in scenarios:
            self.logger.info(f"æ¸¬è©¦å ´æ™¯: {scenario['name']}")
            
            # ç²å–æ¨è–¦ç­–ç•¥
            strategy = self.orchestrator.strategy_selector.select_strategy(scenario['config'])
            self.logger.info(f"æ¨è–¦ç­–ç•¥: {strategy.value}")
            
            # è¨ˆç®—ç­–ç•¥è©•åˆ†
            scores = self.orchestrator.strategy_selector._calculate_strategy_scores(scenario['config'])
            self.logger.info(f"ç­–ç•¥è©•åˆ†: {scores}")
            
            # è¨˜éŒ„çµæœ
            self.test_results.append({
                'test_type': 'adaptive_coordination',
                'scenario': scenario['name'],
                'recommended_strategy': strategy.value,
                'strategy_scores': {k.value: v for k, v in scores.items()}
            })
    
    def generate_test_report(self) -> Dict[str, Any]:
        """
        ç”Ÿæˆæ¸¬è©¦å ±å‘Š
        """
        report = {
            'test_summary': {
                'total_tests': len(self.test_results),
                'test_types': list(set(result['test_type'] for result in self.test_results)),
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
            },
            'strategy_selection_tests': [],
            'performance_tracking_tests': [],
            'hybrid_execution_tests': [],
            'adaptive_coordination_tests': [],
            'orchestrator_stats': self.orchestrator.get_performance_report()
        }
        
        # åˆ†é¡æ¸¬è©¦çµæœ
        for result in self.test_results:
            test_type = result['test_type']
            if test_type == 'strategy_selection':
                report['strategy_selection_tests'].append(result)
            elif test_type == 'performance_tracking':
                report['performance_tracking_tests'].append(result)
            elif test_type == 'hybrid_execution':
                report['hybrid_execution_tests'].append(result)
            elif test_type == 'adaptive_coordination':
                report['adaptive_coordination_tests'].append(result)
        
        return report
    
    async def run_all_tests(self):
        """
        é‹è¡Œæ‰€æœ‰æ¸¬è©¦
        """
        self.logger.info("é–‹å§‹å”èª¿æ©Ÿåˆ¶ç¶œåˆæ¸¬è©¦...")
        
        try:
            # é‹è¡Œå„é …æ¸¬è©¦
            await self.test_strategy_selection()
            await self.test_performance_tracking()
            await self.test_adaptive_coordination()
            await self.test_hybrid_execution()
            
            # ç”Ÿæˆå ±å‘Š
            report = self.generate_test_report()
            
            # è¼¸å‡ºæ¸¬è©¦çµæœ
            self.print_test_results(report)
            
            return report
            
        except Exception as e:
            self.logger.error(f"æ¸¬è©¦åŸ·è¡Œå¤±æ•—: {e}")
            raise
    
    def print_test_results(self, report: Dict[str, Any]):
        """
        æ‰“å°æ¸¬è©¦çµæœ
        """
        print("\n" + "="*80)
        print("å”èª¿æ©Ÿåˆ¶æ¸¬è©¦å ±å‘Š")
        print("="*80)
        
        # æ¸¬è©¦æ‘˜è¦
        summary = report['test_summary']
        print(f"\nğŸ“Š æ¸¬è©¦æ‘˜è¦:")
        print(f"  ç¸½æ¸¬è©¦æ•¸: {summary['total_tests']}")
        print(f"  æ¸¬è©¦é¡å‹: {', '.join(summary['test_types'])}")
        print(f"  æ¸¬è©¦æ™‚é–“: {summary['timestamp']}")
        
        # ç­–ç•¥é¸æ“‡æ¸¬è©¦
        if report['strategy_selection_tests']:
            print(f"\nğŸ¯ ç­–ç•¥é¸æ“‡æ¸¬è©¦:")
            for test in report['strategy_selection_tests']:
                print(f"  {test['config']}: {test['selected_strategy']} (æœ€å¤§çµæœ: {test['max_results']})")
        
        # è‡ªé©æ‡‰å”èª¿æ¸¬è©¦
        if report['adaptive_coordination_tests']:
            print(f"\nğŸ”„ è‡ªé©æ‡‰å”èª¿æ¸¬è©¦:")
            for test in report['adaptive_coordination_tests']:
                print(f"  {test['scenario']}: {test['recommended_strategy']}")
                scores = test['strategy_scores']
                top_strategies = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:3]
                print(f"    å‰ä¸‰ç­–ç•¥è©•åˆ†: {', '.join([f'{k}({v:.2f})' for k, v in top_strategies])}")
        
        # æ··åˆåŸ·è¡Œæ¸¬è©¦
        if report['hybrid_execution_tests']:
            print(f"\nğŸ”€ æ··åˆåŸ·è¡Œæ¸¬è©¦:")
            for test in report['hybrid_execution_tests']:
                if test.get('success'):
                    print(f"  åŸ·è¡Œæ™‚é–“: {test.get('execution_time', 0):.2f}ç§’")
                    print(f"  è·ä½æ•¸é‡: {test.get('job_count', 0)}")
                    print(f"  æ•¸æ“šæºæ•¸: {test.get('data_sources', 0)}")
                else:
                    print(f"  åŸ·è¡Œå¤±æ•—: {test.get('error', 'æœªçŸ¥éŒ¯èª¤')}")
        
        # æ€§èƒ½çµ±è¨ˆ
        stats = report['orchestrator_stats']
        print(f"\nğŸ“ˆ æ€§èƒ½çµ±è¨ˆ:")
        print(f"  å¹³å‡åŸ·è¡Œæ™‚é–“: {stats.get('average_execution_time', 0):.2f}ç§’")
        print(f"  æˆåŠŸç‡: {stats.get('success_rate', 0):.1f}%")
        print(f"  ç¸½è™•ç†è·ä½: {stats.get('total_jobs_collected', 0)}")
        
        print("\n" + "="*80)
        print("âœ… å”èª¿æ©Ÿåˆ¶æ¸¬è©¦å®Œæˆ!")
        print("="*80)

async def main():
    """
    ä¸»å‡½æ•¸
    """
    tester = CoordinationTester()
    
    try:
        await tester.run_all_tests()
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)