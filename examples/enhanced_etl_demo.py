#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼·å‹ETLæµç¨‹æ¼”ç¤ºè…³æœ¬
å±•ç¤ºå¦‚ä½•ä½¿ç”¨æ–°çš„æ•´åˆæ¶æ§‹é€²è¡Œæ™ºèƒ½åŒ–æ•¸æ“šæŠ“å–å’Œè™•ç†

Author: JobSpy Team
Date: 2025-01-05
"""

import asyncio
import sys
from pathlib import Path
from datetime import datetime

# æ·»åŠ é …ç›®è·¯å¾‘
sys.path.append(str(Path(__file__).parent.parent))

from jobseeker.seek.enhanced_etl_orchestrator import (
    EnhancedETLOrchestrator,
    ScrapingJobConfig,
    ScrapingStrategy
)


class EnhancedETLDemo:
    """
    å¢å¼·å‹ETLæ¼”ç¤ºé¡
    å±•ç¤ºå„ç¨®ä½¿ç”¨å ´æ™¯å’ŒåŠŸèƒ½
    """
    
    def __init__(self):
        self.orchestrator = EnhancedETLOrchestrator(
            output_path="./demo_output"
        )
    
    async def demo_basic_usage(self):
        """
        æ¼”ç¤ºåŸºæœ¬ä½¿ç”¨æ–¹æ³•
        """
        print("\n" + "="*80)
        print("æ¼”ç¤º1: åŸºæœ¬ä½¿ç”¨ - æ··åˆæ¨¡å¼çˆ¬èŸ²")
        print("="*80)
        
        # åŸºæœ¬é…ç½®
        job_config = ScrapingJobConfig(
            search_term="data scientist",
            location="Melbourne VIC",
            max_results=10,
            strategy=ScrapingStrategy.HYBRID
        )
        
        print(f"æœç´¢é…ç½®: {job_config.search_term} @ {job_config.location}")
        print(f"ç­–ç•¥: {job_config.strategy.value}")
        
        # åŸ·è¡Œä»»å‹™
        result = await self.orchestrator.execute_scraping_job(job_config)
        
        # é¡¯ç¤ºçµæœ
        self._display_result(result, "åŸºæœ¬ä½¿ç”¨")
        
        return result
    
    async def demo_visual_primary(self):
        """
        æ¼”ç¤ºè¦–è¦ºçˆ¬èŸ²ç‚ºä¸»çš„é«˜è³ªé‡æŠ“å–
        """
        print("\n" + "="*80)
        print("æ¼”ç¤º2: è¦–è¦ºçˆ¬èŸ²ç‚ºä¸» - é«˜è³ªé‡æ•¸æ“šæŠ“å–")
        print("="*80)
        
        # é«˜è³ªé‡é…ç½®
        job_config = ScrapingJobConfig(
            search_term="senior software engineer",
            location="Sydney NSW",
            max_results=5,
            strategy=ScrapingStrategy.VISUAL_PRIMARY,
            high_quality_required=True,
            enable_cross_validation=True
        )
        
        print(f"æœç´¢é…ç½®: {job_config.search_term} @ {job_config.location}")
        print(f"ç­–ç•¥: {job_config.strategy.value}")
        print(f"é«˜è³ªé‡æ¨¡å¼: {job_config.high_quality_required}")
        
        # åŸ·è¡Œä»»å‹™
        result = await self.orchestrator.execute_scraping_job(job_config)
        
        # é¡¯ç¤ºçµæœ
        self._display_result(result, "è¦–è¦ºçˆ¬èŸ²ç‚ºä¸»")
        
        return result
    
    async def demo_traditional_primary(self):
        """
        æ¼”ç¤ºå‚³çµ±çˆ¬èŸ²ç‚ºä¸»çš„å¤§é‡æ•¸æ“šæŠ“å–
        """
        print("\n" + "="*80)
        print("æ¼”ç¤º3: å‚³çµ±çˆ¬èŸ²ç‚ºä¸» - å¤§é‡æ•¸æ“šæŠ“å–")
        print("="*80)
        
        # å¤§é‡æ•¸æ“šé…ç½®
        job_config = ScrapingJobConfig(
            search_term="python",
            location="Australia",
            max_results=50,
            max_pages=3,
            strategy=ScrapingStrategy.TRADITIONAL_PRIMARY,
            large_volume_required=True
        )
        
        print(f"æœç´¢é…ç½®: {job_config.search_term} @ {job_config.location}")
        print(f"ç­–ç•¥: {job_config.strategy.value}")
        print(f"å¤§é‡æ•¸æ“šæ¨¡å¼: {job_config.large_volume_required}")
        print(f"æœ€å¤§é æ•¸: {job_config.max_pages}")
        
        # åŸ·è¡Œä»»å‹™
        result = await self.orchestrator.execute_scraping_job(job_config)
        
        # é¡¯ç¤ºçµæœ
        self._display_result(result, "å‚³çµ±çˆ¬èŸ²ç‚ºä¸»")
        
        return result
    
    async def demo_strategy_comparison(self):
        """
        æ¼”ç¤ºä¸åŒç­–ç•¥çš„æ€§èƒ½æ¯”è¼ƒ
        """
        print("\n" + "="*80)
        print("æ¼”ç¤º4: ç­–ç•¥æ€§èƒ½æ¯”è¼ƒ")
        print("="*80)
        
        strategies = [
            ScrapingStrategy.VISUAL_ONLY,
            ScrapingStrategy.TRADITIONAL_ONLY,
            ScrapingStrategy.HYBRID
        ]
        
        results = {}
        
        for strategy in strategies:
            print(f"\næ¸¬è©¦ç­–ç•¥: {strategy.value}")
            print("-" * 40)
            
            job_config = ScrapingJobConfig(
                search_term="web developer",
                location="Brisbane QLD",
                max_results=5,
                strategy=strategy
            )
            
            result = await self.orchestrator.execute_scraping_job(job_config)
            results[strategy.value] = result
            
            if result['success']:
                print(f"âœ“ æˆåŠŸ: {result['total_jobs']} å€‹è·ä½")
                print(f"  åŸ·è¡Œæ™‚é–“: {result['execution_time']:.2f}ç§’")
                
                # é¡¯ç¤ºæ•¸æ“šæºæ‘˜è¦
                for source, summary in result['data_sources_summary'].items():
                    print(f"  {source}: {summary['job_count']} å€‹è·ä½ ({summary['execution_time']:.2f}ç§’)")
            else:
                print(f"âœ— å¤±æ•—: {result.get('error')}")
        
        # æ€§èƒ½æ¯”è¼ƒ
        print("\n" + "="*40)
        print("æ€§èƒ½æ¯”è¼ƒæ‘˜è¦")
        print("="*40)
        
        for strategy_name, result in results.items():
            if result['success']:
                efficiency = result['total_jobs'] / result['execution_time'] if result['execution_time'] > 0 else 0
                print(f"{strategy_name:20}: {result['total_jobs']:3d} è·ä½, {result['execution_time']:6.2f}ç§’, {efficiency:5.2f} è·ä½/ç§’")
        
        return results
    
    async def demo_data_export(self):
        """
        æ¼”ç¤ºæ•¸æ“šå°å‡ºåŠŸèƒ½
        """
        print("\n" + "="*80)
        print("æ¼”ç¤º5: æ•¸æ“šå°å‡ºåŠŸèƒ½")
        print("="*80)
        
        # åŸ·è¡Œä¸€å€‹åŸºæœ¬ä»»å‹™
        job_config = ScrapingJobConfig(
            search_term="machine learning",
            location="Perth WA",
            max_results=8,
            strategy=ScrapingStrategy.HYBRID
        )
        
        result = await self.orchestrator.execute_scraping_job(job_config)
        
        if result['success']:
            print(f"æˆåŠŸæŠ“å– {result['total_jobs']} å€‹è·ä½")
            
            # å°å‡ºå¤šç¨®æ ¼å¼
            exported_files = await self.orchestrator.export_results(
                result, 
                formats=['json', 'csv']
            )
            
            print("\nå°å‡ºæ–‡ä»¶:")
            for file_path in exported_files:
                file_size = Path(file_path).stat().st_size
                print(f"  {file_path} ({file_size:,} bytes)")
        
        return result
    
    def demo_performance_monitoring(self):
        """
        æ¼”ç¤ºæ€§èƒ½ç›£æ§åŠŸèƒ½
        """
        print("\n" + "="*80)
        print("æ¼”ç¤º6: æ€§èƒ½ç›£æ§å ±å‘Š")
        print("="*80)
        
        # ç²å–æ€§èƒ½å ±å‘Š
        performance_report = self.orchestrator.get_performance_report()
        
        print("æ•´é«”æ€§èƒ½çµ±è¨ˆ:")
        print(f"  ç¸½è™•ç†è·ä½æ•¸: {performance_report['total_jobs_processed']}")
        print(f"  æˆåŠŸè·ä½æ•¸: {performance_report['successful_jobs']}")
        print(f"  å¤±æ•—è·ä½æ•¸: {performance_report['failed_jobs']}")
        print(f"  æˆåŠŸç‡: {performance_report['success_rate']:.2%}")
        print(f"  å¹³å‡åŸ·è¡Œæ™‚é–“: {performance_report['average_execution_time']:.2f}ç§’")
        
        print("\nç­–ç•¥ä½¿ç”¨çµ±è¨ˆ:")
        for strategy, count in performance_report['strategy_usage'].items():
            print(f"  {strategy}: {count} æ¬¡")
        
        print("\nETLè³ªé‡çµ±è¨ˆ:")
        etl_stats = performance_report['etl_quality_stats']
        for metric, value in etl_stats.items():
            print(f"  {metric}: {value}")
        
        return performance_report
    
    def _display_result(self, result: dict, demo_name: str):
        """
        é¡¯ç¤ºåŸ·è¡Œçµæœ
        
        Args:
            result: åŸ·è¡Œçµæœ
            demo_name: æ¼”ç¤ºåç¨±
        """
        print(f"\n{demo_name} - åŸ·è¡Œçµæœ:")
        print("-" * 40)
        
        if result['success']:
            print(f"âœ“ åŸ·è¡ŒæˆåŠŸ")
            print(f"  ç­–ç•¥: {result['strategy_used']}")
            print(f"  è·ä½æ•¸é‡: {result['total_jobs']}")
            print(f"  åŸ·è¡Œæ™‚é–“: {result['execution_time']:.2f}ç§’")
            
            # é¡¯ç¤ºæ•¸æ“šæºæ‘˜è¦
            print("  æ•¸æ“šæºæ‘˜è¦:")
            for source, summary in result['data_sources_summary'].items():
                status = "âœ“" if summary['success'] else "âœ—"
                print(f"    {status} {source}: {summary['job_count']} å€‹è·ä½ ({summary['execution_time']:.2f}ç§’)")
            
            # é¡¯ç¤ºè³ªé‡å ±å‘Š
            quality_report = result.get('quality_report', {})
            if quality_report:
                print("  æ•¸æ“šè³ªé‡:")
                print(f"    æœ‰æ•ˆè·ä½: {quality_report.get('valid_jobs', 0)}")
                print(f"    ç„¡æ•ˆè·ä½: {quality_report.get('invalid_jobs', 0)}")
                print(f"    å»é‡ç§»é™¤: {quality_report.get('duplicates_removed', 0)}")
            
            # é¡¯ç¤ºå‰3å€‹è·ä½
            if result['jobs']:
                print("  å‰3å€‹è·ä½:")
                for i, job in enumerate(result['jobs'][:3], 1):
                    title = job.get('title', 'æœªçŸ¥è·ä½')
                    company = job.get('company', 'æœªçŸ¥å…¬å¸')
                    location = job.get('location', 'æœªçŸ¥åœ°é»')
                    print(f"    {i}. {title} - {company} ({location})")
        else:
            print(f"âœ— åŸ·è¡Œå¤±æ•—: {result.get('error')}")
    
    async def run_all_demos(self):
        """
        é‹è¡Œæ‰€æœ‰æ¼”ç¤º
        """
        print("ğŸš€ å¢å¼·å‹ETLæµç¨‹æ¼”ç¤ºé–‹å§‹")
        print(f"æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        try:
            # é‹è¡Œå„å€‹æ¼”ç¤º
            await self.demo_basic_usage()
            await self.demo_visual_primary()
            await self.demo_traditional_primary()
            await self.demo_strategy_comparison()
            await self.demo_data_export()
            self.demo_performance_monitoring()
            
            print("\n" + "="*80)
            print("ğŸ‰ æ‰€æœ‰æ¼”ç¤ºå®Œæˆ!")
            print("="*80)
            
        except Exception as e:
            print(f"\nâŒ æ¼”ç¤ºéç¨‹ä¸­å‡ºéŒ¯: {e}")
            import traceback
            traceback.print_exc()


async def main():
    """
    ä¸»å‡½æ•¸
    """
    demo = EnhancedETLDemo()
    
    # æª¢æŸ¥å‘½ä»¤è¡Œåƒæ•¸
    if len(sys.argv) > 1:
        demo_name = sys.argv[1].lower()
        
        if demo_name == "basic":
            await demo.demo_basic_usage()
        elif demo_name == "visual":
            await demo.demo_visual_primary()
        elif demo_name == "traditional":
            await demo.demo_traditional_primary()
        elif demo_name == "comparison":
            await demo.demo_strategy_comparison()
        elif demo_name == "export":
            await demo.demo_data_export()
        elif demo_name == "performance":
            demo.demo_performance_monitoring()
        elif demo_name == "all":
            await demo.run_all_demos()
        else:
            print(f"æœªçŸ¥çš„æ¼”ç¤ºåç¨±: {demo_name}")
            print("å¯ç”¨çš„æ¼”ç¤º: basic, visual, traditional, comparison, export, performance, all")
    else:
        # é»˜èªé‹è¡Œæ‰€æœ‰æ¼”ç¤º
        await demo.run_all_demos()


if __name__ == "__main__":
    print("""
    å¢å¼·å‹ETLæµç¨‹æ¼”ç¤ºè…³æœ¬
    
    ä½¿ç”¨æ–¹æ³•:
        python enhanced_etl_demo.py [æ¼”ç¤ºåç¨±]
    
    å¯ç”¨æ¼”ç¤º:
        basic       - åŸºæœ¬ä½¿ç”¨æ¼”ç¤º
        visual      - è¦–è¦ºçˆ¬èŸ²ç‚ºä¸»æ¼”ç¤º
        traditional - å‚³çµ±çˆ¬èŸ²ç‚ºä¸»æ¼”ç¤º
        comparison  - ç­–ç•¥æ€§èƒ½æ¯”è¼ƒ
        export      - æ•¸æ“šå°å‡ºåŠŸèƒ½
        performance - æ€§èƒ½ç›£æ§å ±å‘Š
        all         - é‹è¡Œæ‰€æœ‰æ¼”ç¤º (é»˜èª)
    
    ç¤ºä¾‹:
        python enhanced_etl_demo.py basic
        python enhanced_etl_demo.py comparison
        python enhanced_etl_demo.py all
    """)
    
    asyncio.run(main())