#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
èª¿è©¦é é¢çµæ§‹
"""

import asyncio
from playwright.async_api import async_playwright


async def debug_page_structure():
    """èª¿è©¦é é¢çµæ§‹"""
    print("ğŸ” èª¿è©¦é é¢çµæ§‹...")
    
    try:
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            context = await browser.new_context(
                viewport={'width': 1920, 'height': 1080},
                user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            )
            page = await context.new_page()
            
            # è¨ªå•æœå°‹é é¢
            search_url = "https://www.104.com.tw/jobs/search/?keyword=Pythonå·¥ç¨‹å¸«"
            print(f"ğŸ“„ è¨ªå•: {search_url}")
            
            await page.goto(search_url, timeout=60000)
            await page.wait_for_load_state('networkidle')
            
            # æª¢æŸ¥é é¢æ¨™é¡Œ
            title = await page.title()
            print(f"ğŸ“„ é é¢æ¨™é¡Œ: {title}")
            
            # æª¢æŸ¥æ˜¯å¦æœ‰è·ä½åˆ—è¡¨
            print("\nğŸ” æª¢æŸ¥è·ä½åˆ—è¡¨:")
            
            # æª¢æŸ¥å„ç¨®å¯èƒ½çš„é¸æ“‡å™¨
            selectors = [
                '.job-list',
                '.job-list > div',
                '.job-item',
                '.job-card',
                '.job-list-item',
                '[data-job-id]',
                '.job-info',
                '.job-title',
                'article',
                '.job',
                '.list-item',
                '.search-result',
                '.result-item'
            ]
            
            for selector in selectors:
                try:
                    elements = await page.query_selector_all(selector)
                    print(f"  {selector}: {len(elements)} å€‹å…ƒç´ ")
                    
                    if elements and len(elements) > 0:
                        # æª¢æŸ¥ç¬¬ä¸€å€‹å…ƒç´ çš„å…§å®¹
                        first_element = elements[0]
                        text_content = await first_element.evaluate('el => el.textContent')
                        print(f"    ç¬¬ä¸€å€‹å…ƒç´ å…§å®¹: {text_content[:200]}...")
                        
                        # æª¢æŸ¥æ˜¯å¦æœ‰è·ä½ç›¸é—œçš„å…§å®¹
                        if any(keyword in text_content for keyword in ['å·¥ç¨‹å¸«', 'Python', 'è»Ÿé«”', 'é–‹ç™¼']):
                            print(f"    âœ… æ‰¾åˆ°è·ä½ç›¸é—œå…§å®¹!")
                            
                            # æª¢æŸ¥é€™å€‹å…ƒç´ æ˜¯å¦æœ‰éˆæ¥
                            links = await first_element.query_selector_all('a')
                            print(f"    åŒ…å« {len(links)} å€‹éˆæ¥")
                            
                            for i, link in enumerate(links[:3]):
                                href = await link.evaluate('el => el.href')
                                text = await link.evaluate('el => el.textContent')
                                print(f"      éˆæ¥ {i+1}: {href} - {text[:50]}...")
                            
                            break
                        
                except Exception as e:
                    print(f"  {selector}: éŒ¯èª¤ - {e}")
            
            # æª¢æŸ¥é é¢æ˜¯å¦åŒ…å«è·ä½è³‡è¨Š
            print("\nğŸ” æª¢æŸ¥é é¢å…§å®¹:")
            page_content = await page.content()
            
            if 'Python' in page_content:
                print("  âœ… é é¢åŒ…å« 'Python'")
            if 'å·¥ç¨‹å¸«' in page_content:
                print("  âœ… é é¢åŒ…å« 'å·¥ç¨‹å¸«'")
            if 'è·ä½' in page_content:
                print("  âœ… é é¢åŒ…å« 'è·ä½'")
            if 'å·¥ä½œ' in page_content:
                print("  âœ… é é¢åŒ…å« 'å·¥ä½œ'")
            
            # æª¢æŸ¥æ˜¯å¦æœ‰éŒ¯èª¤è¨Šæ¯
            print("\nğŸ” æª¢æŸ¥éŒ¯èª¤è¨Šæ¯:")
            error_selectors = [
                '.error',
                '.no-result',
                '.empty',
                '.not-found',
                '[class*="error"]',
                '[class*="empty"]',
                '[class*="no-result"]',
                '.no-data',
                '.no-jobs'
            ]
            
            for selector in error_selectors:
                try:
                    elements = await page.query_selector_all(selector)
                    if elements:
                        for element in elements:
                            text = await element.evaluate('el => el.textContent')
                            if text.strip():
                                print(f"  {selector}: {text.strip()}")
                except:
                    pass
            
            # æª¢æŸ¥é é¢æ˜¯å¦æ­£å¸¸è¼‰å…¥
            print("\nğŸ” æª¢æŸ¥é é¢è¼‰å…¥ç‹€æ…‹:")
            current_url = page.url
            print(f"  ç•¶å‰URL: {current_url}")
            
            # æª¢æŸ¥æ˜¯å¦æœ‰é‡å®šå‘
            if 'search' not in current_url:
                print("  âš ï¸  å¯èƒ½ç™¼ç”Ÿäº†é‡å®šå‘")
            
            # æª¢æŸ¥é é¢æ˜¯å¦åŒ…å«æœå°‹çµæœ
            if 'æœå°‹çµæœ' in page_content or 'search results' in page_content.lower():
                print("  âœ… é é¢åŒ…å«æœå°‹çµæœ")
            else:
                print("  âŒ é é¢ä¸åŒ…å«æœå°‹çµæœ")
            
            await browser.close()
            
    except Exception as e:
        print(f"âŒ èª¿è©¦å¤±æ•—: {e}")


if __name__ == "__main__":
    asyncio.run(debug_page_structure())
