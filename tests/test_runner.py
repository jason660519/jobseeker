#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
JobSpy æ¸¬è©¦åŸ·è¡Œå™¨

é€™å€‹è…³æœ¬æä¾›äº†ä¾¿æ·çš„æ¸¬è©¦åŸ·è¡Œä»‹é¢ï¼Œæ”¯æ´ä¸åŒé¡å‹çš„æ¸¬è©¦åŸ·è¡Œã€
è¦†è“‹ç‡å ±å‘Šç”Ÿæˆå’Œæ¸¬è©¦çµæœåˆ†æã€‚
æ”¯æ´æ‰€æœ‰9å€‹æ±‚è·ç¶²ç«™çš„æ¸¬è©¦ï¼šLinkedIn, Indeed, ZipRecruiter, Glassdoor, Google, Bayt, Naukri, BDJobs, Seek

ä½¿ç”¨æ–¹å¼:
    python test_runner.py --help
    python test_runner.py --unit
    python test_runner.py --integration
    python test_runner.py --performance
    python test_runner.py --all --coverage

ä½œè€…: JobSpy Team
æ—¥æœŸ: 2024
"""

import os
import sys
import argparse
import subprocess
import time
import json
from pathlib import Path
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from datetime import datetime

# è¨­å®šå°ˆæ¡ˆæ ¹ç›®éŒ„
project_root = Path(__file__).parent.parent  # å›åˆ° JobSpy æ ¹ç›®éŒ„
tests_dir = Path(__file__).parent  # tests è³‡æ–™å¤¾
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(tests_dir))

try:
    from tests.test_config import (
        TestConfig, TestEnvironment, get_test_config,
        check_test_environment, setup_test_environment,
        cleanup_test_environment
    )
except ImportError:
    print("è­¦å‘Š: ç„¡æ³•å°å…¥æ¸¬è©¦é…ç½®ï¼Œä½¿ç”¨é è¨­è¨­å®š")
    TestConfig = None
    TestEnvironment = None


@dataclass
class TestResult:
    """æ¸¬è©¦çµæœé¡åˆ¥"""
    test_type: str
    passed: int
    failed: int
    skipped: int
    errors: int
    duration: float
    coverage: Optional[float] = None
    exit_code: int = 0
    output: str = ""
    
    @property
    def total(self) -> int:
        """ç¸½æ¸¬è©¦æ•¸é‡"""
        return self.passed + self.failed + self.skipped + self.errors
    
    @property
    def success_rate(self) -> float:
        """æˆåŠŸç‡"""
        if self.total == 0:
            return 0.0
        return (self.passed / self.total) * 100
    
    def to_dict(self) -> Dict[str, Any]:
        """è½‰æ›ç‚ºå­—å…¸"""
        return {
            'test_type': self.test_type,
            'passed': self.passed,
            'failed': self.failed,
            'skipped': self.skipped,
            'errors': self.errors,
            'total': self.total,
            'duration': self.duration,
            'success_rate': self.success_rate,
            'coverage': self.coverage,
            'exit_code': self.exit_code
        }


class TestRunner:
    """æ¸¬è©¦åŸ·è¡Œå™¨é¡åˆ¥"""
    
    def __init__(self, config: Optional[TestConfig] = None):
        """åˆå§‹åŒ–æ¸¬è©¦åŸ·è¡Œå™¨"""
        self.config = config or (get_test_config() if TestConfig else None)
        self.project_root = Path(__file__).parent
        self.test_dir = self.project_root / "tests"
        self.results: List[TestResult] = []
        
        # ç¢ºä¿æ¸¬è©¦ç›®éŒ„å­˜åœ¨
        if not self.test_dir.exists():
            raise FileNotFoundError(f"æ¸¬è©¦ç›®éŒ„ä¸å­˜åœ¨: {self.test_dir}")
    
    def check_dependencies(self) -> bool:
        """æª¢æŸ¥æ¸¬è©¦ä¾è³´"""
        print("ğŸ” æª¢æŸ¥æ¸¬è©¦ç’°å¢ƒ...")
        
        # æª¢æŸ¥ pytest
        try:
            result = subprocess.run(
                [sys.executable, "-m", "pytest", "--version"],
                capture_output=True,
                text=True,
                timeout=10
            )
            if result.returncode != 0:
                print("âŒ pytest æœªå®‰è£æˆ–ç„¡æ³•åŸ·è¡Œ")
                return False
            print(f"âœ… {result.stdout.strip()}")
        except (subprocess.TimeoutExpired, FileNotFoundError):
            print("âŒ pytest æœªå®‰è£")
            return False
        
        # æª¢æŸ¥æ¸¬è©¦ç’°å¢ƒ
        if TestConfig:
            env_checks = check_test_environment()
            failed_checks = [k for k, v in env_checks.items() if not v]
            
            if failed_checks:
                print(f"âš ï¸  ç’°å¢ƒæª¢æŸ¥å¤±æ•—: {', '.join(failed_checks)}")
                return False
            
            print("âœ… æ¸¬è©¦ç’°å¢ƒæª¢æŸ¥é€šé")
        
        return True
    
    def install_dependencies(self) -> bool:
        """å®‰è£æ¸¬è©¦ä¾è³´"""
        print("ğŸ“¦ å®‰è£æ¸¬è©¦ä¾è³´...")
        
        requirements_files = [
            self.project_root / "requirements-test.txt",
            self.project_root / "requirements.txt"
        ]
        
        for req_file in requirements_files:
            if req_file.exists():
                try:
                    result = subprocess.run(
                        [sys.executable, "-m", "pip", "install", "-r", str(req_file)],
                        capture_output=True,
                        text=True,
                        timeout=300
                    )
                    
                    if result.returncode == 0:
                        print(f"âœ… å·²å®‰è£ {req_file.name}")
                    else:
                        print(f"âŒ å®‰è£ {req_file.name} å¤±æ•—: {result.stderr}")
                        return False
                        
                except subprocess.TimeoutExpired:
                    print(f"âŒ å®‰è£ {req_file.name} è¶…æ™‚")
                    return False
        
        return True
    
    def run_pytest(self, args: List[str], test_type: str = "general") -> TestResult:
        """åŸ·è¡Œ pytest"""
        print(f"ğŸ§ª åŸ·è¡Œ {test_type} æ¸¬è©¦...")
        
        # æ§‹å»ºå®Œæ•´å‘½ä»¤
        cmd = [sys.executable, "-m", "pytest"] + args
        
        if self.config and self.config.verbose_logging:
            cmd.append("-v")
        
        print(f"åŸ·è¡Œå‘½ä»¤: {' '.join(cmd)}")
        
        start_time = time.time()
        
        try:
            result = subprocess.run(
                cmd,
                cwd=self.project_root,
                capture_output=True,
                text=True,
                timeout=self.config.performance_timeout if self.config else 300
            )
            
            duration = time.time() - start_time
            
            # è§£ææ¸¬è©¦çµæœ
            test_result = self._parse_pytest_output(
                result.stdout + result.stderr,
                test_type,
                duration,
                result.returncode
            )
            
            test_result.output = result.stdout + result.stderr
            
            if result.returncode == 0:
                print(f"âœ… {test_type} æ¸¬è©¦å®Œæˆ ({duration:.2f}s)")
            else:
                print(f"âŒ {test_type} æ¸¬è©¦å¤±æ•— ({duration:.2f}s)")
            
            return test_result
            
        except subprocess.TimeoutExpired:
            duration = time.time() - start_time
            print(f"â° {test_type} æ¸¬è©¦è¶…æ™‚ ({duration:.2f}s)")
            
            return TestResult(
                test_type=test_type,
                passed=0,
                failed=0,
                skipped=0,
                errors=1,
                duration=duration,
                exit_code=124,  # è¶…æ™‚é€€å‡ºç¢¼
                output="æ¸¬è©¦åŸ·è¡Œè¶…æ™‚"
            )
    
    def _parse_pytest_output(self, output: str, test_type: str, duration: float, exit_code: int) -> TestResult:
        """è§£æ pytest è¼¸å‡º"""
        passed = failed = skipped = errors = 0
        coverage = None
        
        lines = output.split('\n')
        
        for line in lines:
            line = line.strip()
            
            # è§£ææ¸¬è©¦çµæœçµ±è¨ˆ
            if "passed" in line and ("failed" in line or "error" in line or "skipped" in line):
                # ä¾‹å¦‚: "5 passed, 2 failed, 1 skipped in 10.5s"
                parts = line.split()
                for i, part in enumerate(parts):
                    if part == "passed" and i > 0:
                        try:
                            passed = int(parts[i-1])
                        except ValueError:
                            pass
                    elif part == "failed" and i > 0:
                        try:
                            failed = int(parts[i-1])
                        except ValueError:
                            pass
                    elif part == "skipped" and i > 0:
                        try:
                            skipped = int(parts[i-1])
                        except ValueError:
                            pass
                    elif part == "error" and i > 0:
                        try:
                            errors = int(parts[i-1])
                        except ValueError:
                            pass
            
            # è§£æè¦†è“‹ç‡
            elif "TOTAL" in line and "%" in line:
                # ä¾‹å¦‚: "TOTAL    1000    200     80%"
                parts = line.split()
                for part in parts:
                    if part.endswith('%'):
                        try:
                            coverage = float(part[:-1])
                        except ValueError:
                            pass
        
        return TestResult(
            test_type=test_type,
            passed=passed,
            failed=failed,
            skipped=skipped,
            errors=errors,
            duration=duration,
            coverage=coverage,
            exit_code=exit_code
        )
    
    def run_unit_tests(self, coverage: bool = False) -> TestResult:
        """åŸ·è¡Œå–®å…ƒæ¸¬è©¦"""
        args = ["tests/unit", "-m", "unit"]
        
        if coverage:
            args.extend([
                "--cov=jobspy",
                "--cov-report=term-missing",
                "--cov-report=html:htmlcov"
            ])
        
        result = self.run_pytest(args, "å–®å…ƒæ¸¬è©¦")
        self.results.append(result)
        return result
    
    def run_integration_tests(self, coverage: bool = False) -> TestResult:
        """åŸ·è¡Œæ•´åˆæ¸¬è©¦"""
        args = ["tests/integration", "-m", "integration"]
        
        if coverage:
            args.extend([
                "--cov=jobspy",
                "--cov-append",
                "--cov-report=term-missing"
            ])
        
        result = self.run_pytest(args, "æ•´åˆæ¸¬è©¦")
        self.results.append(result)
        return result
    
    def run_performance_tests(self) -> TestResult:
        """åŸ·è¡Œæ•ˆèƒ½æ¸¬è©¦"""
        args = ["tests/performance", "-m", "performance", "--tb=short"]
        
        result = self.run_pytest(args, "æ•ˆèƒ½æ¸¬è©¦")
        self.results.append(result)
        return result
    
    def run_network_tests(self) -> TestResult:
        """åŸ·è¡Œç¶²è·¯æ¸¬è©¦"""
        args = ["tests", "-m", "requires_network", "--tb=short"]
        
        result = self.run_pytest(args, "ç¶²è·¯æ¸¬è©¦")
        self.results.append(result)
        return result
    
    def run_all_tests(self, coverage: bool = False, include_network: bool = False) -> List[TestResult]:
        """åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦"""
        print("ğŸš€ é–‹å§‹åŸ·è¡Œå®Œæ•´æ¸¬è©¦å¥—ä»¶...")
        
        # å–®å…ƒæ¸¬è©¦
        self.run_unit_tests(coverage=coverage)
        
        # æ•´åˆæ¸¬è©¦
        self.run_integration_tests(coverage=coverage)
        
        # æ•ˆèƒ½æ¸¬è©¦
        self.run_performance_tests()
        
        # ç¶²è·¯æ¸¬è©¦ï¼ˆå¯é¸ï¼‰
        if include_network:
            self.run_network_tests()
        
        return self.results
    
    def run_smoke_tests(self) -> TestResult:
        """åŸ·è¡Œå†’ç…™æ¸¬è©¦"""
        args = ["tests", "-m", "smoke", "--tb=line"]
        
        result = self.run_pytest(args, "å†’ç…™æ¸¬è©¦")
        self.results.append(result)
        return result
    
    def run_quick_tests(self) -> TestResult:
        """åŸ·è¡Œå¿«é€Ÿæ¸¬è©¦"""
        args = ["tests", "-m", "fast", "--tb=line"]
        
        result = self.run_pytest(args, "å¿«é€Ÿæ¸¬è©¦")
        self.results.append(result)
        return result
    
    def run_code_quality_checks(self) -> Dict[str, bool]:
        """åŸ·è¡Œç¨‹å¼ç¢¼å“è³ªæª¢æŸ¥"""
        print("ğŸ” åŸ·è¡Œç¨‹å¼ç¢¼å“è³ªæª¢æŸ¥...")
        
        checks = {}
        
        # Black æ ¼å¼æª¢æŸ¥
        try:
            result = subprocess.run(
                [sys.executable, "-m", "black", "--check", "."],
                cwd=self.project_root,
                capture_output=True,
                timeout=60
            )
            checks['black'] = result.returncode == 0
            if checks['black']:
                print("âœ… Black æ ¼å¼æª¢æŸ¥é€šé")
            else:
                print("âŒ Black æ ¼å¼æª¢æŸ¥å¤±æ•—")
        except (subprocess.TimeoutExpired, FileNotFoundError):
            checks['black'] = False
            print("âš ï¸  Black æœªå®‰è£æˆ–åŸ·è¡Œå¤±æ•—")
        
        # isort å°å…¥æ’åºæª¢æŸ¥
        try:
            result = subprocess.run(
                [sys.executable, "-m", "isort", "--check-only", "."],
                cwd=self.project_root,
                capture_output=True,
                timeout=60
            )
            checks['isort'] = result.returncode == 0
            if checks['isort']:
                print("âœ… isort å°å…¥æ’åºæª¢æŸ¥é€šé")
            else:
                print("âŒ isort å°å…¥æ’åºæª¢æŸ¥å¤±æ•—")
        except (subprocess.TimeoutExpired, FileNotFoundError):
            checks['isort'] = False
            print("âš ï¸  isort æœªå®‰è£æˆ–åŸ·è¡Œå¤±æ•—")
        
        # Flake8 ç¨‹å¼ç¢¼é¢¨æ ¼æª¢æŸ¥
        try:
            result = subprocess.run(
                [sys.executable, "-m", "flake8", "."],
                cwd=self.project_root,
                capture_output=True,
                timeout=60
            )
            checks['flake8'] = result.returncode == 0
            if checks['flake8']:
                print("âœ… Flake8 ç¨‹å¼ç¢¼é¢¨æ ¼æª¢æŸ¥é€šé")
            else:
                print("âŒ Flake8 ç¨‹å¼ç¢¼é¢¨æ ¼æª¢æŸ¥å¤±æ•—")
        except (subprocess.TimeoutExpired, FileNotFoundError):
            checks['flake8'] = False
            print("âš ï¸  Flake8 æœªå®‰è£æˆ–åŸ·è¡Œå¤±æ•—")
        
        # MyPy é¡å‹æª¢æŸ¥
        try:
            result = subprocess.run(
                [sys.executable, "-m", "mypy", "jobspy"],
                cwd=self.project_root,
                capture_output=True,
                timeout=120
            )
            checks['mypy'] = result.returncode == 0
            if checks['mypy']:
                print("âœ… MyPy é¡å‹æª¢æŸ¥é€šé")
            else:
                print("âŒ MyPy é¡å‹æª¢æŸ¥å¤±æ•—")
        except (subprocess.TimeoutExpired, FileNotFoundError):
            checks['mypy'] = False
            print("âš ï¸  MyPy æœªå®‰è£æˆ–åŸ·è¡Œå¤±æ•—")
        
        return checks
    
    def generate_report(self, output_file: Optional[str] = None) -> str:
        """ç”Ÿæˆæ¸¬è©¦å ±å‘Š"""
        if not self.results:
            return "æ²’æœ‰æ¸¬è©¦çµæœå¯å ±å‘Š"
        
        report_lines = []
        report_lines.append("# JobSpy æ¸¬è©¦å ±å‘Š")
        report_lines.append(f"ç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append("")
        
        # ç¸½è¦½
        total_passed = sum(r.passed for r in self.results)
        total_failed = sum(r.failed for r in self.results)
        total_skipped = sum(r.skipped for r in self.results)
        total_errors = sum(r.errors for r in self.results)
        total_duration = sum(r.duration for r in self.results)
        
        report_lines.append("## æ¸¬è©¦ç¸½è¦½")
        report_lines.append(f"- ç¸½æ¸¬è©¦æ•¸: {total_passed + total_failed + total_skipped + total_errors}")
        report_lines.append(f"- é€šé: {total_passed}")
        report_lines.append(f"- å¤±æ•—: {total_failed}")
        report_lines.append(f"- è·³é: {total_skipped}")
        report_lines.append(f"- éŒ¯èª¤: {total_errors}")
        report_lines.append(f"- ç¸½åŸ·è¡Œæ™‚é–“: {total_duration:.2f}s")
        
        if total_passed + total_failed + total_errors > 0:
            success_rate = (total_passed / (total_passed + total_failed + total_errors)) * 100
            report_lines.append(f"- æˆåŠŸç‡: {success_rate:.1f}%")
        
        report_lines.append("")
        
        # è©³ç´°çµæœ
        report_lines.append("## è©³ç´°çµæœ")
        for result in self.results:
            report_lines.append(f"### {result.test_type}")
            report_lines.append(f"- é€šé: {result.passed}")
            report_lines.append(f"- å¤±æ•—: {result.failed}")
            report_lines.append(f"- è·³é: {result.skipped}")
            report_lines.append(f"- éŒ¯èª¤: {result.errors}")
            report_lines.append(f"- åŸ·è¡Œæ™‚é–“: {result.duration:.2f}s")
            report_lines.append(f"- æˆåŠŸç‡: {result.success_rate:.1f}%")
            
            if result.coverage is not None:
                report_lines.append(f"- è¦†è“‹ç‡: {result.coverage:.1f}%")
            
            report_lines.append("")
        
        report_content = "\n".join(report_lines)
        
        # ä¿å­˜å ±å‘Š
        if output_file:
            output_path = Path(output_file)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            output_path.write_text(report_content, encoding='utf-8')
            print(f"ğŸ“Š æ¸¬è©¦å ±å‘Šå·²ä¿å­˜åˆ°: {output_path}")
        
        return report_content
    
    def save_results_json(self, output_file: str) -> None:
        """ä¿å­˜æ¸¬è©¦çµæœç‚º JSON"""
        results_data = {
            'timestamp': datetime.now().isoformat(),
            'results': [result.to_dict() for result in self.results],
            'summary': {
                'total_passed': sum(r.passed for r in self.results),
                'total_failed': sum(r.failed for r in self.results),
                'total_skipped': sum(r.skipped for r in self.results),
                'total_errors': sum(r.errors for r in self.results),
                'total_duration': sum(r.duration for r in self.results)
            }
        }
        
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results_data, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ æ¸¬è©¦çµæœå·²ä¿å­˜åˆ°: {output_path}")
    
    def cleanup(self) -> None:
        """æ¸…ç†æ¸¬è©¦ç’°å¢ƒ"""
        if self.config:
            cleanup_test_environment(self.config)
        
        # æ¸…ç†æ¸¬è©¦ç”¢ç”Ÿçš„æª”æ¡ˆ
        cleanup_patterns = [
            "**/.pytest_cache",
            "**/__pycache__",
            "**/*.pyc",
            "**/*.pyo",
            ".coverage",
            "htmlcov",
            "test-results.xml",
            "coverage.xml"
        ]
        
        for pattern in cleanup_patterns:
            for path in self.project_root.glob(pattern):
                if path.is_file():
                    path.unlink()
                elif path.is_dir():
                    import shutil
                    shutil.rmtree(path, ignore_errors=True)


def main():
    """ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(
        description="JobSpy æ¸¬è©¦åŸ·è¡Œå™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¯„ä¾‹:
  python test_runner.py --unit                    # åŸ·è¡Œå–®å…ƒæ¸¬è©¦
  python test_runner.py --integration             # åŸ·è¡Œæ•´åˆæ¸¬è©¦
  python test_runner.py --performance             # åŸ·è¡Œæ•ˆèƒ½æ¸¬è©¦
  python test_runner.py --all --coverage          # åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦ä¸¦ç”Ÿæˆè¦†è“‹ç‡å ±å‘Š
  python test_runner.py --smoke                   # åŸ·è¡Œå†’ç…™æ¸¬è©¦
  python test_runner.py --quick                   # åŸ·è¡Œå¿«é€Ÿæ¸¬è©¦
  python test_runner.py --check                   # åŸ·è¡Œç¨‹å¼ç¢¼å“è³ªæª¢æŸ¥
  python test_runner.py --install                 # å®‰è£æ¸¬è©¦ä¾è³´
        """
    )
    
    # æ¸¬è©¦é¡å‹é¸é …
    test_group = parser.add_mutually_exclusive_group()
    test_group.add_argument("--unit", action="store_true", help="åŸ·è¡Œå–®å…ƒæ¸¬è©¦")
    test_group.add_argument("--integration", action="store_true", help="åŸ·è¡Œæ•´åˆæ¸¬è©¦")
    test_group.add_argument("--performance", action="store_true", help="åŸ·è¡Œæ•ˆèƒ½æ¸¬è©¦")
    test_group.add_argument("--network", action="store_true", help="åŸ·è¡Œç¶²è·¯æ¸¬è©¦")
    test_group.add_argument("--all", action="store_true", help="åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦")
    test_group.add_argument("--smoke", action="store_true", help="åŸ·è¡Œå†’ç…™æ¸¬è©¦")
    test_group.add_argument("--quick", action="store_true", help="åŸ·è¡Œå¿«é€Ÿæ¸¬è©¦")
    
    # å…¶ä»–é¸é …
    parser.add_argument("--coverage", action="store_true", help="ç”Ÿæˆè¦†è“‹ç‡å ±å‘Š")
    parser.add_argument("--include-network", action="store_true", help="åŒ…å«ç¶²è·¯æ¸¬è©¦ï¼ˆåƒ…ç”¨æ–¼ --allï¼‰")
    parser.add_argument("--check", action="store_true", help="åŸ·è¡Œç¨‹å¼ç¢¼å“è³ªæª¢æŸ¥")
    parser.add_argument("--install", action="store_true", help="å®‰è£æ¸¬è©¦ä¾è³´")
    parser.add_argument("--report", type=str, help="ç”Ÿæˆæ¸¬è©¦å ±å‘Šåˆ°æŒ‡å®šæª”æ¡ˆ")
    parser.add_argument("--json", type=str, help="ä¿å­˜æ¸¬è©¦çµæœç‚º JSON æ ¼å¼")
    parser.add_argument("--cleanup", action="store_true", help="æ¸…ç†æ¸¬è©¦ç’°å¢ƒ")
    parser.add_argument("--verbose", "-v", action="store_true", help="è©³ç´°è¼¸å‡º")
    
    args = parser.parse_args()
    
    # å¦‚æœæ²’æœ‰æŒ‡å®šä»»ä½•é¸é …ï¼Œé¡¯ç¤ºå¹«åŠ©
    if not any([
        args.unit, args.integration, args.performance, args.network,
        args.all, args.smoke, args.quick, args.check, args.install,
        args.cleanup
    ]):
        parser.print_help()
        return 1
    
    try:
        # å‰µå»ºæ¸¬è©¦åŸ·è¡Œå™¨
        config = None
        if TestConfig:
            config = get_test_config()
            if args.verbose:
                config.verbose_logging = True
        
        runner = TestRunner(config)
        
        # å®‰è£ä¾è³´
        if args.install:
            if not runner.install_dependencies():
                print("âŒ ä¾è³´å®‰è£å¤±æ•—")
                return 1
            print("âœ… ä¾è³´å®‰è£å®Œæˆ")
            return 0
        
        # æª¢æŸ¥ä¾è³´
        if not runner.check_dependencies():
            print("âŒ ä¾è³´æª¢æŸ¥å¤±æ•—ï¼Œè«‹å…ˆåŸ·è¡Œ: python test_runner.py --install")
            return 1
        
        # ç¨‹å¼ç¢¼å“è³ªæª¢æŸ¥
        if args.check:
            checks = runner.run_code_quality_checks()
            failed_checks = [k for k, v in checks.items() if not v]
            
            if failed_checks:
                print(f"âŒ ç¨‹å¼ç¢¼å“è³ªæª¢æŸ¥å¤±æ•—: {', '.join(failed_checks)}")
                return 1
            else:
                print("âœ… æ‰€æœ‰ç¨‹å¼ç¢¼å“è³ªæª¢æŸ¥é€šé")
                return 0
        
        # åŸ·è¡Œæ¸¬è©¦
        exit_code = 0
        
        if args.unit:
            result = runner.run_unit_tests(coverage=args.coverage)
            exit_code = result.exit_code
        
        elif args.integration:
            result = runner.run_integration_tests(coverage=args.coverage)
            exit_code = result.exit_code
        
        elif args.performance:
            result = runner.run_performance_tests()
            exit_code = result.exit_code
        
        elif args.network:
            result = runner.run_network_tests()
            exit_code = result.exit_code
        
        elif args.smoke:
            result = runner.run_smoke_tests()
            exit_code = result.exit_code
        
        elif args.quick:
            result = runner.run_quick_tests()
            exit_code = result.exit_code
        
        elif args.all:
            results = runner.run_all_tests(
                coverage=args.coverage,
                include_network=args.include_network
            )
            exit_code = max(r.exit_code for r in results) if results else 0
        
        # ç”Ÿæˆå ±å‘Š
        if args.report:
            runner.generate_report(args.report)
        
        # ä¿å­˜ JSON çµæœ
        if args.json:
            runner.save_results_json(args.json)
        
        # æ¸…ç†
        if args.cleanup:
            runner.cleanup()
            print("ğŸ§¹ æ¸¬è©¦ç’°å¢ƒå·²æ¸…ç†")
        
        # é¡¯ç¤ºç¸½çµ
        if runner.results:
            print("\n" + "="*50)
            print("ğŸ“Š æ¸¬è©¦ç¸½çµ")
            print("="*50)
            
            for result in runner.results:
                status = "âœ…" if result.exit_code == 0 else "âŒ"
                print(f"{status} {result.test_type}: {result.passed}é€šé, {result.failed}å¤±æ•—, {result.skipped}è·³é ({result.duration:.2f}s)")
            
            total_failed = sum(r.failed + r.errors for r in runner.results)
            if total_failed == 0:
                print("\nğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼")
            else:
                print(f"\nâš ï¸  æœ‰ {total_failed} å€‹æ¸¬è©¦å¤±æ•—")
        
        return exit_code
    
    except KeyboardInterrupt:
        print("\nâ¹ï¸  æ¸¬è©¦è¢«ç”¨æˆ¶ä¸­æ–·")
        return 130
    
    except Exception as e:
        print(f"âŒ æ¸¬è©¦åŸ·è¡Œå™¨éŒ¯èª¤: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())