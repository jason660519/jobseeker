#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼·ç‰ˆTW104çˆ¬èŸ²æ¸¬è©¦
"""

import asyncio
import json
import sys
import os
from datetime import datetime
from pathlib import Path

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ°Pythonè·¯å¾‘
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from jobseeker.tw104.enhanced_tw104 import EnhancedTW104Scraper


class EnhancedTW104Tester:
    """å¢å¼·ç‰ˆTW104çˆ¬èŸ²æ¸¬è©¦å™¨"""
    
    def __init__(self):
        self.scraper = EnhancedTW104Scraper(headless=True)
        self.test_results = []
    
    async def test_basic_search(self):
        """æ¸¬è©¦åŸºæœ¬æœå°‹åŠŸèƒ½"""
        print("ğŸ” æ¸¬è©¦åŸºæœ¬æœå°‹åŠŸèƒ½...")
        
        try:
            jobs = await self.scraper.search_jobs(
                keyword="Pythonå·¥ç¨‹å¸«",
                max_pages=2
            )
            
            result = {
                "test_name": "åŸºæœ¬æœå°‹åŠŸèƒ½",
                "success": len(jobs) > 0,
                "job_count": len(jobs),
                "timestamp": datetime.now().isoformat()
            }
            
            if jobs:
                print(f"âœ… åŸºæœ¬æœå°‹æˆåŠŸï¼Œæ‰¾åˆ° {len(jobs)} å€‹è·ä½")
                # é¡¯ç¤ºå‰3å€‹è·ä½è³‡è¨Š
                for i, job in enumerate(jobs[:3]):
                    print(f"  {i+1}. {job.get('title', 'N/A')} - {job.get('company', 'N/A')}")
            else:
                print("âŒ åŸºæœ¬æœå°‹å¤±æ•—ï¼Œæ²’æœ‰æ‰¾åˆ°è·ä½")
            
            return result
            
        except Exception as e:
            print(f"âŒ åŸºæœ¬æœå°‹æ¸¬è©¦å¤±æ•—: {e}")
            return {
                "test_name": "åŸºæœ¬æœå°‹åŠŸèƒ½",
                "success": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    async def test_search_with_location(self):
        """æ¸¬è©¦å¸¶åœ°å€çš„æœå°‹"""
        print("ğŸ” æ¸¬è©¦å¸¶åœ°å€çš„æœå°‹...")
        
        try:
            jobs = await self.scraper.search_jobs(
                keyword="è»Ÿé«”å·¥ç¨‹å¸«",
                location="6001001000",  # å°åŒ—å¸‚
                max_pages=2
            )
            
            result = {
                "test_name": "å¸¶åœ°å€æœå°‹",
                "success": len(jobs) > 0,
                "job_count": len(jobs),
                "timestamp": datetime.now().isoformat()
            }
            
            if jobs:
                print(f"âœ… å¸¶åœ°å€æœå°‹æˆåŠŸï¼Œæ‰¾åˆ° {len(jobs)} å€‹è·ä½")
                # æª¢æŸ¥åœ°å€è³‡è¨Š
                locations = [job.get('location', '') for job in jobs if job.get('location')]
                unique_locations = set(locations)
                print(f"  åœ°å€åˆ†ä½ˆ: {list(unique_locations)[:5]}")
            else:
                print("âŒ å¸¶åœ°å€æœå°‹å¤±æ•—ï¼Œæ²’æœ‰æ‰¾åˆ°è·ä½")
            
            return result
            
        except Exception as e:
            print(f"âŒ å¸¶åœ°å€æœå°‹æ¸¬è©¦å¤±æ•—: {e}")
            return {
                "test_name": "å¸¶åœ°å€æœå°‹",
                "success": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    async def test_search_with_category(self):
        """æ¸¬è©¦å¸¶è·å‹™é¡åˆ¥çš„æœå°‹"""
        print("ğŸ” æ¸¬è©¦å¸¶è·å‹™é¡åˆ¥çš„æœå°‹...")
        
        try:
            jobs = await self.scraper.search_jobs(
                keyword="å‰ç«¯å·¥ç¨‹å¸«",
                job_category="2007000000",  # è»Ÿé«”å·¥ç¨‹å¸«
                max_pages=2
            )
            
            result = {
                "test_name": "å¸¶è·å‹™é¡åˆ¥æœå°‹",
                "success": len(jobs) > 0,
                "job_count": len(jobs),
                "timestamp": datetime.now().isoformat()
            }
            
            if jobs:
                print(f"âœ… å¸¶è·å‹™é¡åˆ¥æœå°‹æˆåŠŸï¼Œæ‰¾åˆ° {len(jobs)} å€‹è·ä½")
                # æª¢æŸ¥è·ä½æ¨™é¡Œ
                titles = [job.get('title', '') for job in jobs if job.get('title')]
                print(f"  è·ä½æ¨™é¡Œç¯„ä¾‹: {titles[:3]}")
            else:
                print("âŒ å¸¶è·å‹™é¡åˆ¥æœå°‹å¤±æ•—ï¼Œæ²’æœ‰æ‰¾åˆ°è·ä½")
            
            return result
            
        except Exception as e:
            print(f"âŒ å¸¶è·å‹™é¡åˆ¥æœå°‹æ¸¬è©¦å¤±æ•—: {e}")
            return {
                "test_name": "å¸¶è·å‹™é¡åˆ¥æœå°‹",
                "success": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    async def test_multiple_keywords(self):
        """æ¸¬è©¦å¤šå€‹é—œéµå­—æœå°‹"""
        print("ğŸ” æ¸¬è©¦å¤šå€‹é—œéµå­—æœå°‹...")
        
        keywords = ["è³‡æ–™åˆ†æå¸«", "ç”¢å“ç¶“ç†", "UIè¨­è¨ˆå¸«"]
        results = []
        
        for keyword in keywords:
            try:
                print(f"  æœå°‹é—œéµå­—: {keyword}")
                jobs = await self.scraper.search_jobs(
                    keyword=keyword,
                    max_pages=1
                )
                
                result = {
                    "keyword": keyword,
                    "success": len(jobs) > 0,
                    "job_count": len(jobs)
                }
                results.append(result)
                
                if jobs:
                    print(f"    âœ… æ‰¾åˆ° {len(jobs)} å€‹è·ä½")
                else:
                    print(f"    âŒ æ²’æœ‰æ‰¾åˆ°è·ä½")
                
                # æœå°‹é–“éš”
                await asyncio.sleep(2)
                
            except Exception as e:
                print(f"    âŒ æœå°‹å¤±æ•—: {e}")
                results.append({
                    "keyword": keyword,
                    "success": False,
                    "error": str(e)
                })
        
        # çµ±è¨ˆçµæœ
        successful_searches = sum(1 for r in results if r.get("success", False))
        total_jobs = sum(r.get("job_count", 0) for r in results)
        
        return {
            "test_name": "å¤šå€‹é—œéµå­—æœå°‹",
            "success": successful_searches > 0,
            "successful_searches": successful_searches,
            "total_keywords": len(keywords),
            "total_jobs": total_jobs,
            "keyword_results": results,
            "timestamp": datetime.now().isoformat()
        }
    
    async def test_job_details(self):
        """æ¸¬è©¦è·ä½è©³ç´°è³‡è¨Šç²å–"""
        print("ğŸ” æ¸¬è©¦è·ä½è©³ç´°è³‡è¨Šç²å–...")
        
        try:
            # å…ˆæœå°‹ä¸€äº›è·ä½
            jobs = await self.scraper.search_jobs(
                keyword="Pythonå·¥ç¨‹å¸«",
                max_pages=1
            )
            
            if not jobs:
                return {
                    "test_name": "è·ä½è©³ç´°è³‡è¨Šç²å–",
                    "success": False,
                    "error": "æ²’æœ‰æ‰¾åˆ°è·ä½é€²è¡Œè©³ç´°è³‡è¨Šæ¸¬è©¦",
                    "timestamp": datetime.now().isoformat()
                }
            
            # ç²å–ç¬¬ä¸€å€‹è·ä½çš„è©³ç´°è³‡è¨Š
            first_job = jobs[0]
            job_url = first_job.get('job_url', '')
            
            if not job_url:
                return {
                    "test_name": "è·ä½è©³ç´°è³‡è¨Šç²å–",
                    "success": False,
                    "error": "è·ä½æ²’æœ‰URL",
                    "timestamp": datetime.now().isoformat()
                }
            
            print(f"  ç²å–è·ä½è©³ç´°è³‡è¨Š: {first_job.get('title', 'N/A')}")
            details = await self.scraper.get_job_details(job_url)
            
            result = {
                "test_name": "è·ä½è©³ç´°è³‡è¨Šç²å–",
                "success": bool(details),
                "job_title": first_job.get('title', ''),
                "job_url": job_url,
                "details_keys": list(details.keys()) if details else [],
                "timestamp": datetime.now().isoformat()
            }
            
            if details:
                print(f"âœ… æˆåŠŸç²å–è·ä½è©³ç´°è³‡è¨Šï¼ŒåŒ…å« {len(details)} å€‹æ¬„ä½")
                print(f"  è©³ç´°è³‡è¨Šæ¬„ä½: {list(details.keys())}")
            else:
                print("âŒ ç²å–è·ä½è©³ç´°è³‡è¨Šå¤±æ•—")
            
            return result
            
        except Exception as e:
            print(f"âŒ è·ä½è©³ç´°è³‡è¨Šæ¸¬è©¦å¤±æ•—: {e}")
            return {
                "test_name": "è·ä½è©³ç´°è³‡è¨Šç²å–",
                "success": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    async def test_statistics(self):
        """æ¸¬è©¦çµ±è¨ˆåŠŸèƒ½"""
        print("ğŸ” æ¸¬è©¦çµ±è¨ˆåŠŸèƒ½...")
        
        try:
            # å…ˆæœå°‹ä¸€äº›è·ä½
            jobs = await self.scraper.search_jobs(
                keyword="å·¥ç¨‹å¸«",
                max_pages=2
            )
            
            if not jobs:
                return {
                    "test_name": "çµ±è¨ˆåŠŸèƒ½",
                    "success": False,
                    "error": "æ²’æœ‰æ‰¾åˆ°è·ä½é€²è¡Œçµ±è¨ˆæ¸¬è©¦",
                    "timestamp": datetime.now().isoformat()
                }
            
            # ç²å–çµ±è¨ˆè³‡è¨Š
            stats = self.scraper.get_statistics()
            
            result = {
                "test_name": "çµ±è¨ˆåŠŸèƒ½",
                "success": bool(stats),
                "statistics": stats,
                "timestamp": datetime.now().isoformat()
            }
            
            if stats:
                print(f"âœ… çµ±è¨ˆåŠŸèƒ½æ­£å¸¸")
                print(f"  ç¸½è·ä½æ•¸: {stats.get('total_jobs', 0)}")
                print(f"  å…¬å¸æ•¸: {stats.get('unique_companies', 0)}")
                print(f"  åœ°å€æ•¸: {stats.get('unique_locations', 0)}")
                print(f"  æœ‰è–ªè³‡è³‡è¨Šçš„è·ä½: {stats.get('jobs_with_salary', 0)}")
            else:
                print("âŒ çµ±è¨ˆåŠŸèƒ½å¤±æ•—")
            
            return result
            
        except Exception as e:
            print(f"âŒ çµ±è¨ˆåŠŸèƒ½æ¸¬è©¦å¤±æ•—: {e}")
            return {
                "test_name": "çµ±è¨ˆåŠŸèƒ½",
                "success": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    async def run_all_tests(self):
        """é‹è¡Œæ‰€æœ‰æ¸¬è©¦"""
        print("ğŸš€ é–‹å§‹å¢å¼·ç‰ˆTW104çˆ¬èŸ²æ¸¬è©¦...")
        
        tests = [
            self.test_basic_search,
            self.test_search_with_location,
            self.test_search_with_category,
            self.test_multiple_keywords,
            self.test_job_details,
            self.test_statistics
        ]
        
        for test_func in tests:
            try:
                result = await test_func()
                self.test_results.append(result)
                print()  # ç©ºè¡Œåˆ†éš”
            except Exception as e:
                print(f"âŒ æ¸¬è©¦ {test_func.__name__} åŸ·è¡Œå¤±æ•—: {e}")
                self.test_results.append({
                    "test_name": test_func.__name__,
                    "success": False,
                    "error": str(e),
                    "timestamp": datetime.now().isoformat()
                })
        
        # ç”Ÿæˆæ¸¬è©¦å ±å‘Š
        self.generate_report()
    
    def generate_report(self):
        """ç”Ÿæˆæ¸¬è©¦å ±å‘Š"""
        if not self.test_results:
            print("âŒ æ²’æœ‰æ¸¬è©¦çµæœå¯å ±å‘Š")
            return
        
        # çµ±è¨ˆçµæœ
        total_tests = len(self.test_results)
        successful_tests = sum(1 for r in self.test_results if r.get("success", False))
        success_rate = successful_tests / total_tests * 100
        
        report = {
            "test_summary": {
                "total_tests": total_tests,
                "successful_tests": successful_tests,
                "success_rate": success_rate,
                "test_type": "enhanced_tw104_scraper"
            },
            "test_results": self.test_results,
            "generated_at": datetime.now().isoformat()
        }
        
        # ä¿å­˜å ±å‘Š
        report_path = Path("tests/results/enhanced_tw104_test_report.json")
        report_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        # é¡¯ç¤ºå ±å‘Š
        print(f"{'='*60}")
        print(f"ğŸ“Š å¢å¼·ç‰ˆTW104çˆ¬èŸ²æ¸¬è©¦å ±å‘Š")
        print(f"{'='*60}")
        print(f"ç¸½æ¸¬è©¦æ•¸: {total_tests}")
        print(f"æˆåŠŸæ¸¬è©¦æ•¸: {successful_tests}")
        print(f"æˆåŠŸç‡: {success_rate:.1f}%")
        print(f"è©³ç´°å ±å‘Šå·²ä¿å­˜è‡³: {report_path}")
        
        # é¡¯ç¤ºå¤±æ•—çš„æ¸¬è©¦
        failed_tests = [r for r in self.test_results if not r.get("success", False)]
        if failed_tests:
            print(f"\nâŒ å¤±æ•—çš„æ¸¬è©¦:")
            for test in failed_tests:
                print(f"  - {test.get('test_name', 'Unknown')}: {test.get('error', 'Unknown error')}")
        
        return report


async def main():
    """ä¸»å‡½æ•¸"""
    tester = EnhancedTW104Tester()
    await tester.run_all_tests()


if __name__ == "__main__":
    asyncio.run(main())
