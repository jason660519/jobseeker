# JobSpy æ•¸æ“šç®¡ç†æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

JobSpy ç¾åœ¨ä½¿ç”¨çµ±ä¸€çš„æ•¸æ“šç®¡ç†ç³»çµ±ä¾†çµ„ç¹”å’Œå­˜å„²æ‰€æœ‰çˆ¬èŸ²æ•¸æ“šã€‚é€™å€‹ç³»çµ±æä¾›äº†ï¼š

- âœ… **çµ±ä¸€çš„ç›®éŒ„çµæ§‹**
- âœ… **æ¨™æº–åŒ–çš„æ–‡ä»¶å‘½å**
- âœ… **å®Œæ•´çš„æ•¸æ“šç´¢å¼•**
- âœ… **è‡ªå‹•æ¸…ç†å’Œæ­¸æª”**
- âœ… **å¤šæ ¼å¼å°å‡ºæ”¯æŒ**

## ğŸ“ ç›®éŒ„çµæ§‹

```
data/
â”œâ”€â”€ raw/                           # åŸå§‹æ•¸æ“š
â”‚   â”œâ”€â”€ by_date/                   # æŒ‰æ—¥æœŸåˆ†é¡
â”‚   â”‚   â”œâ”€â”€ 20250127/
â”‚   â”‚   â”‚   â”œâ”€â”€ linkedin/
â”‚   â”‚   â”‚   â”œâ”€â”€ indeed/
â”‚   â”‚   â”‚   â””â”€â”€ glassdoor/
â”‚   â”‚   â””â”€â”€ 20250128/
â”‚   â””â”€â”€ by_site/                   # æŒ‰ç¶²ç«™åˆ†é¡
â”‚       â”œâ”€â”€ linkedin/
â”‚       â”œâ”€â”€ indeed/
â”‚       â””â”€â”€ glassdoor/
â”œâ”€â”€ processed/                     # è™•ç†å¾Œçš„æ•¸æ“š
â”‚   â”œâ”€â”€ csv/
â”‚   â”œâ”€â”€ json/
â”‚   â””â”€â”€ combined/
â”œâ”€â”€ exports/                       # ç”¨æˆ¶å°å‡º
â”‚   â”œâ”€â”€ csv/
â”‚   â””â”€â”€ json/
â”œâ”€â”€ reports/                       # å ±å‘Šå’Œæ‘˜è¦
â”‚   â”œâ”€â”€ daily/
â”‚   â”œâ”€â”€ weekly/
â”‚   â””â”€â”€ monthly/
â”œâ”€â”€ archive/                       # æ­¸æª”æ•¸æ“š
â””â”€â”€ index/                         # æ•¸æ“šç´¢å¼•
    â””â”€â”€ data_index.json
```

## ğŸš€ å¿«é€Ÿé–‹å§‹

### 1. è¨­ç½®æ•¸æ“šç›®éŒ„

```bash
# å‰µå»ºæ•¸æ“šç›®éŒ„çµæ§‹
make setup

# æˆ–è€…ä½¿ç”¨ Python
python -c "from jobseeker.data_manager import data_manager; print('âœ… è¨­ç½®å®Œæˆ')"
```

### 2. é·ç§»ç¾æœ‰æ•¸æ“š

```bash
# é·ç§»æ‰€æœ‰ç¾æœ‰æ•¸æ“šåˆ°æ–°çµæ§‹
make migrate

# æˆ–è€…ç›´æ¥é‹è¡Œè…³æœ¬
python scripts/migrate_existing_data.py
```

### 3. æŸ¥çœ‹æ•¸æ“šæ‘˜è¦

```bash
# é¡¯ç¤ºæ•¸æ“šæ‘˜è¦
make summary

# æˆ–è€…ä½¿ç”¨æŸ¥è©¢å·¥å…·
python scripts/query_data.py --summary
```

## ğŸ”§ æ•¸æ“šç®¡ç†å‘½ä»¤

### åŸºæœ¬å‘½ä»¤

```bash
# é¡¯ç¤ºæ•¸æ“šæ‘˜è¦
python scripts/manage_data.py summary

# æŸ¥è©¢ç‰¹å®šç¶²ç«™çš„æ•¸æ“š
python scripts/manage_data.py query --site linkedin

# æŸ¥è©¢ç‰¹å®šæ—¥æœŸçš„æ•¸æ“š
python scripts/manage_data.py query --date 20250127

# æŸ¥è©¢ç‰¹å®šæœå°‹è©çš„æ•¸æ“š
python scripts/manage_data.py query --search-term "python engineer"
```

### æ¸…ç†å‘½ä»¤

```bash
# æ¸…ç† 30 å¤©å‰çš„æ•¸æ“š
make cleanup

# è©¦é‹è¡Œæ¸…ç† (ä¸å¯¦éš›åˆªé™¤)
make cleanup-dry

# è‡ªå®šç¾©ä¿ç•™å¤©æ•¸
python scripts/cleanup_data.py --retention-days 60
```

## ğŸ”§ é«˜ç´šç”¨æ³•

### 1. ä½¿ç”¨æ•¸æ“šç®¡ç†å™¨ API

```python
from jobseeker.data_manager import data_manager

# ä¿å­˜åŸå§‹æ•¸æ“š
filepath = data_manager.save_raw_data(
    site="linkedin",
    data=job_data,
    search_term="python engineer",
    location="taipei"
)

# ä¿å­˜è™•ç†å¾Œçš„æ•¸æ“š
processed_path = data_manager.save_processed_data(
    data=job_data,
    format="csv"
)

# å°å‡ºæ•¸æ“š
export_path = data_manager.save_export_data(
    data=job_data,
    format="json",
    search_term="python engineer",
    location="taipei"
)
```

### 2. æŸ¥è©¢å’Œåˆ†ææ•¸æ“š

```python
from scripts.query_data import DataQuery

query = DataQuery()

# ç²å–æ‰€æœ‰ç¶²ç«™
sites = query.list_sites()

# ç²å–ç‰¹å®šç¶²ç«™çš„æ•¸æ“š
linkedin_data = query.get_data_by_site("linkedin")

# åˆ†æè·ä½æ•¸æ“š
jobs = query.load_job_data("path/to/file.json")
analysis = query.analyze_jobs(jobs)
```

## ğŸ“ˆ æ•¸æ“šåˆ†æ

### 1. åŸºæœ¬åˆ†æ

```bash
# åˆ†æè·ä½æ•¸æ“š
python scripts/query_data.py --analyze --export analysis_report.json

# æŒ‰ç¶²ç«™åˆ†æ
python scripts/query_data.py --site linkedin --analyze
```

### 2. ç”Ÿæˆå ±å‘Š

```bash
# ç”Ÿæˆæ—¥å ±
python -c "from jobseeker.data_manager import data_manager; data_manager.generate_report('daily')"

# ç”Ÿæˆé€±å ±
python -c "from jobseeker.data_manager import data_manager; data_manager.generate_report('weekly')"
```

## ğŸ”„ æ•¸æ“šé·ç§»

### å¾èˆŠç³»çµ±é·ç§»

1. **å‚™ä»½ç¾æœ‰æ•¸æ“š**
   ```bash
   make backup
   ```

2. **é‹è¡Œé·ç§»è…³æœ¬**
   ```bash
   make migrate
   ```

3. **é©—è­‰é·ç§»çµæœ**
   ```bash
   make summary
   ```

### é·ç§»å ±å‘Š

é·ç§»å®Œæˆå¾Œæœƒç”Ÿæˆ `data/migration_report.json`ï¼ŒåŒ…å«ï¼š
- é·ç§»çš„æ–‡ä»¶æ•¸é‡
- æŒ‰ç¶²ç«™åˆ†é¡çš„çµ±è¨ˆ
- æŒ‰æ ¼å¼åˆ†é¡çš„çµ±è¨ˆ
- è©³ç´°çš„é·ç§»æ—¥èªŒ

## ğŸ§¹ æ•¸æ“šæ¸…ç†

### è‡ªå‹•æ¸…ç†

ç³»çµ±æœƒè‡ªå‹•æ¸…ç†è¶…éä¿ç•™æœŸçš„æ•¸æ“šï¼š

```python
# æ¸…ç† 30 å¤©å‰çš„æ•¸æ“š
data_manager.cleanup_old_data(30)

# å£“ç¸®æ­¸æª”æ•¸æ“š
data_manager.compress_archive(7)
```

### æ‰‹å‹•æ¸…ç†

```bash
# æ¸…ç†ä¸¦å£“ç¸®
python scripts/cleanup_data.py --retention-days 30 --compress-days 7

# å„ªåŒ–å­˜å„²ç©ºé–“
python scripts/cleanup_data.py --optimize
```

## ğŸ“‹ æœ€ä½³å¯¦è¸

### 1. å®šæœŸç¶­è­·

```bash
# æ¯é€±é‹è¡Œä¸€æ¬¡
make cleanup
make summary
```

### 2. ç›£æ§å­˜å„²

```bash
# æª¢æŸ¥å­˜å„²ä½¿ç”¨æƒ…æ³
python scripts/manage_data.py summary
```

### 3. å‚™ä»½é‡è¦æ•¸æ“š

```bash
# å®šæœŸå‚™ä»½
make backup
```

## ğŸ†˜ æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

1. **æ•¸æ“šç›®éŒ„ä¸å­˜åœ¨**
   ```bash
   make setup
   ```

2. **ç´¢å¼•æ–‡ä»¶æå£**
   ```bash
   python -c "from jobseeker.data_manager import data_manager; data_manager.update_index()"
   ```

### æ¢å¾©æ•¸æ“š

```bash
# å¾å‚™ä»½æ¢å¾©
make restore BACKUP_FILE=backup_20250127_143022.tar.gz
```

## ğŸ“ æ”¯æŒ

å¦‚æœé‡åˆ°å•é¡Œï¼Œè«‹ï¼š

1. æª¢æŸ¥é…ç½®æ˜¯å¦æ­£ç¢º
2. æŸ¥çœ‹é·ç§»å ±å‘Š
3. é‹è¡Œæ•¸æ“šé©—è­‰
4. è¯ç¹«é–‹ç™¼åœ˜éšŠ

---

**æ³¨æ„**: é€™å€‹æ•¸æ“šç®¡ç†ç³»çµ±æ˜¯å‘å¾Œå…¼å®¹çš„ï¼Œç¾æœ‰çš„çˆ¬èŸ²ä»£ç¢¼ç„¡éœ€ä¿®æ”¹å³å¯ä½¿ç”¨æ–°çš„æ•¸æ“šç®¡ç†åŠŸèƒ½ã€‚
