# LiteLLM Docker ä»£ç†æœå‹™å™¨éƒ¨ç½²æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

LiteLLMæ˜¯ä¸€å€‹å¼·å¤§çš„LLMä»£ç†æœå‹™å™¨ï¼Œå¯ä»¥çµ±ä¸€èª¿ç”¨å¤šå€‹LLMæä¾›å•†çš„APIï¼ŒåŒ…æ‹¬OpenAIã€Anthropicã€DeepSeekã€Googleç­‰ã€‚é€šéDockeréƒ¨ç½²ï¼Œæ‚¨å¯ä»¥å¿«é€Ÿæ­å»ºä¸€å€‹çµ±ä¸€çš„LLM APIç¶²é—œã€‚

## ğŸ¯ ä¸»è¦åŠŸèƒ½

- **çµ±ä¸€APIæ¥å£** - ä½¿ç”¨OpenAIæ ¼å¼èª¿ç”¨æ‰€æœ‰LLMæä¾›å•†
- **è² è¼‰å‡è¡¡** - è‡ªå‹•åœ¨å¤šå€‹æ¨¡å‹é–“åˆ†é…è«‹æ±‚
- **æ•…éšœè½‰ç§»** - ç•¶ä¸€å€‹APIä¸å¯ç”¨æ™‚è‡ªå‹•åˆ‡æ›åˆ°å‚™ç”¨API
- **é€Ÿç‡é™åˆ¶** - æ§åˆ¶æ¯å€‹æ¨¡å‹çš„è«‹æ±‚é »ç‡
- **ä½¿ç”¨ç›£æ§** - è¿½è¹¤APIä½¿ç”¨æƒ…æ³å’Œæˆæœ¬
- **ç·©å­˜æ”¯æŒ** - æ¸›å°‘é‡è¤‡è«‹æ±‚çš„æˆæœ¬

## ğŸš€ å¿«é€Ÿé–‹å§‹

### 1. å‰ç½®è¦æ±‚

- Docker Desktop (Windows/Mac) æˆ– Docker Engine (Linux)
- è‡³å°‘ä¸€å€‹LLM APIå¯†é‘° (OpenAIã€Anthropicã€DeepSeekç­‰)

### 2. è¨­ç½®APIå¯†é‘°

åœ¨PowerShellä¸­è¨­ç½®ç’°å¢ƒè®Šé‡ï¼š

```powershell
# è¨­ç½®APIå¯†é‘°
$env:OPENAI_API_KEY="your-openai-api-key"
$env:ANTHROPIC_API_KEY="your-anthropic-api-key"
$env:DEEPSEEK_API_KEY="your-deepseek-api-key"
$env:GOOGLE_API_KEY="your-google-api-key"
```

### 3. å•Ÿå‹•æœå‹™

#### æ–¹æ³•ä¸€ï¼šä½¿ç”¨å•Ÿå‹•è…³æœ¬ï¼ˆæ¨è–¦ï¼‰

```batch
# é›™æ“Šé‹è¡Œæˆ–åœ¨å‘½ä»¤è¡ŒåŸ·è¡Œ
start_litellm_docker.bat
```

#### æ–¹æ³•äºŒï¼šæ‰‹å‹•å•Ÿå‹•

```bash
# å•Ÿå‹•æ‰€æœ‰æœå‹™
docker compose -f docker-compose.litellm.yml up -d

# æŸ¥çœ‹æ—¥èªŒ
docker compose -f docker-compose.litellm.yml logs -f litellm-proxy

# åœæ­¢æœå‹™
docker compose -f docker-compose.litellm.yml down
```

### 4. é©—è­‰éƒ¨ç½²

```bash
# é‹è¡Œæ¸¬è©¦è…³æœ¬
python test_litellm_docker.py
```

## ğŸ”§ é…ç½®èªªæ˜

### litellm_config.yaml

ä¸»è¦é…ç½®æ–‡ä»¶ï¼Œå®šç¾©äº†å¯ç”¨çš„æ¨¡å‹å’Œè·¯ç”±ç­–ç•¥ï¼š

```yaml
model_list:
  # OpenAI æ¨¡å‹
  - model_name: gpt-4o
    litellm_params:
      model: openai/gpt-4o
      api_key: os.environ/OPENAI_API_KEY
      rpm: 60

  # Anthropic æ¨¡å‹
  - model_name: claude-3-haiku
    litellm_params:
      model: anthropic/claude-3-haiku-20240307
      api_key: os.environ/ANTHROPIC_API_KEY
      rpm: 60

  # DeepSeek æ¨¡å‹
  - model_name: deepseek-chat
    litellm_params:
      model: deepseek/deepseek-chat
      api_key: os.environ/DEEPSEEK_API_KEY
      api_base: https://api.deepseek.com
      rpm: 60
```

### docker-compose.litellm.yml

Docker Composeé…ç½®ï¼ŒåŒ…å«ï¼š
- **litellm-proxy** - ä¸»è¦çš„ä»£ç†æœå‹™
- **redis** - ç·©å­˜æœå‹™ï¼ˆå¯é¸ï¼‰
- **postgres** - æ•¸æ“šåº«æœå‹™ï¼ˆå¯é¸ï¼‰

## ğŸŒ API ä½¿ç”¨

### å¥åº·æª¢æŸ¥

```bash
curl http://localhost:4000/health
```

### ç²å–æ¨¡å‹åˆ—è¡¨

```bash
curl http://localhost:4000/v1/models
```

### èŠå¤©å®Œæˆ

```bash
curl -X POST http://localhost:4000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer sk-litellm-master-key" \
  -d '{
    "model": "claude-3-haiku",
    "messages": [
      {"role": "user", "content": "Hello, how are you?"}
    ],
    "max_tokens": 100
  }'
```

### Python å®¢æˆ¶ç«¯ç¤ºä¾‹

```python
import openai

# é…ç½®å®¢æˆ¶ç«¯æŒ‡å‘LiteLLMä»£ç†
client = openai.OpenAI(
    base_url="http://localhost:4000/v1",
    api_key="sk-litellm-master-key"
)

# ä½¿ç”¨ä»»ä½•é…ç½®çš„æ¨¡å‹
response = client.chat.completions.create(
    model="claude-3-haiku",  # æˆ– "deepseek-chat", "gpt-4o" ç­‰
    messages=[
        {"role": "user", "content": "ä½ å¥½ï¼Œè«‹ä»‹ç´¹ä¸€ä¸‹ä½ è‡ªå·±"}
    ],
    max_tokens=100
)

print(response.choices[0].message.content)
```

## ğŸ” ç›£æ§å’Œç®¡ç†

### Web UI

è¨ªå• http://localhost:4000 æŸ¥çœ‹Webç®¡ç†ç•Œé¢ï¼Œå¯ä»¥ï¼š
- æŸ¥çœ‹æ¨¡å‹ç‹€æ…‹
- ç›£æ§APIä½¿ç”¨æƒ…æ³
- ç®¡ç†ç”¨æˆ¶å’Œå¯†é‘°
- æŸ¥çœ‹æ—¥èªŒå’Œçµ±è¨ˆ

### æ—¥èªŒæŸ¥çœ‹

```bash
# æŸ¥çœ‹å¯¦æ™‚æ—¥èªŒ
docker compose -f docker-compose.litellm.yml logs -f litellm-proxy

# æŸ¥çœ‹ç‰¹å®šæ™‚é–“çš„æ—¥èªŒ
docker compose -f docker-compose.litellm.yml logs --since="1h" litellm-proxy
```

### æ€§èƒ½ç›£æ§

```bash
# æŸ¥çœ‹å®¹å™¨è³‡æºä½¿ç”¨
docker stats litellm-proxy

# æŸ¥çœ‹å®¹å™¨è©³ç´°ä¿¡æ¯
docker inspect litellm-proxy
```

## ğŸ› ï¸ æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

1. **å®¹å™¨å•Ÿå‹•å¤±æ•—**
   ```bash
   # æª¢æŸ¥Dockeræ˜¯å¦é‹è¡Œ
   docker version
   
   # æª¢æŸ¥ç«¯å£æ˜¯å¦è¢«å ç”¨
   netstat -an | findstr :4000
   ```

2. **APIèª¿ç”¨å¤±æ•—**
   ```bash
   # æª¢æŸ¥APIå¯†é‘°æ˜¯å¦æ­£ç¢ºè¨­ç½®
   docker compose -f docker-compose.litellm.yml exec litellm-proxy env | grep API_KEY
   
   # æª¢æŸ¥é…ç½®æ–‡ä»¶
   docker compose -f docker-compose.litellm.yml exec litellm-proxy cat /app/config.yaml
   ```

3. **æ¨¡å‹ä¸å¯ç”¨**
   - ç¢ºèªAPIå¯†é‘°æœ‰æ•ˆ
   - æª¢æŸ¥APIé…é¡æ˜¯å¦ç”¨å®Œ
   - é©—è­‰æ¨¡å‹åç¨±æ˜¯å¦æ­£ç¢º

### èª¿è©¦æ¨¡å¼

å•Ÿç”¨è©³ç´°æ—¥èªŒï¼š

```yaml
# åœ¨docker-compose.litellm.ymlä¸­æ·»åŠ 
environment:
  - LITELLM_LOG=DEBUG
```

## ğŸ”’ å®‰å…¨è€ƒæ…®

1. **æ›´æ”¹é»˜èªå¯†é‘°**
   ```yaml
   environment:
     - LITELLM_MASTER_KEY=your-secure-master-key
   ```

2. **é™åˆ¶ç¶²çµ¡è¨ªå•**
   ```yaml
   ports:
     - "127.0.0.1:4000:4000"  # åªå…è¨±æœ¬åœ°è¨ªå•
   ```

3. **ä½¿ç”¨HTTPS**
   - åœ¨ç”Ÿç”¢ç’°å¢ƒä¸­é…ç½®åå‘ä»£ç†ï¼ˆå¦‚Nginxï¼‰
   - ä½¿ç”¨SSLè­‰æ›¸åŠ å¯†é€šä¿¡

## ğŸ“š é€²éšé…ç½®

### è² è¼‰å‡è¡¡

```yaml
router_settings:
  routing_strategy: "least-busy"  # æˆ– "simple-shuffle", "latency-based"
  model_group_alias:
    gpt-4: ["gpt-4o", "gpt-4-turbo"]
    claude: ["claude-3-haiku", "claude-3-sonnet"]
```

### é€Ÿç‡é™åˆ¶

```yaml
model_list:
  - model_name: gpt-4o
    litellm_params:
      model: openai/gpt-4o
      rpm: 60        # æ¯åˆ†é˜è«‹æ±‚æ•¸
      tpm: 100000    # æ¯åˆ†é˜tokenæ•¸
```

### ç·©å­˜é…ç½®

```yaml
router_settings:
  redis_host: redis
  redis_port: 6379
  cache_responses: true
  cache_kwargs:
    ttl: 3600  # ç·©å­˜1å°æ™‚
```

## ğŸ¤ æ•´åˆåˆ°JobSpy

åœ¨JobSpyå°ˆæ¡ˆä¸­ä½¿ç”¨LiteLLMä»£ç†ï¼š

```python
# ä¿®æ”¹jobseeker/litellm_client.py
class LiteLLMClient:
    def __init__(self, base_url="http://localhost:4000/v1", api_key="sk-litellm-master-key"):
        self.client = openai.OpenAI(
            base_url=base_url,
            api_key=api_key
        )
    
    def call(self, model, messages, **kwargs):
        return self.client.chat.completions.create(
            model=model,
            messages=messages,
            **kwargs
        )
```

## ğŸ“ æ”¯æŒå’Œè³‡æº

- **å®˜æ–¹æ–‡æª”**: https://docs.litellm.ai/
- **GitHub**: https://github.com/BerriAI/litellm
- **Discordç¤¾ç¾¤**: https://discord.gg/wuPM9dRgDw
- **å•é¡Œå›å ±**: https://github.com/BerriAI/litellm/issues

---

**æ³¨æ„**: é€™æ˜¯ä¸€å€‹é–‹ç™¼ç’°å¢ƒé…ç½®ã€‚åœ¨ç”Ÿç”¢ç’°å¢ƒä¸­ï¼Œè«‹ç¢ºä¿é©ç•¶çš„å®‰å…¨æªæ–½ã€ç›£æ§å’Œå‚™ä»½ç­–ç•¥ã€‚