name: jobseeker Tests

# è§¸ç™¼æ¢ä»¶
on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # æ¯å¤© UTC 02:00 åŸ·è¡Œï¼ˆå°ç£æ™‚é–“ 10:00ï¼‰
    - cron: '0 2 * * *'
  workflow_dispatch:
    # å…è¨±æ‰‹å‹•è§¸ç™¼

# ç’°å¢ƒè®Šæ•¸
env:
  PYTHON_VERSION: '3.10'
  CACHE_VERSION: v1

jobs:
  # ç¨‹å¼ç¢¼å“è³ªæª¢æŸ¥
  code-quality:
    name: Code Quality
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ env.CACHE_VERSION }}-${{ hashFiles('requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-${{ env.CACHE_VERSION }}-
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install flake8 black isort mypy bandit safety
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
        if [ -f requirements-dev.txt ]; then pip install -r requirements-dev.txt; fi
    
    - name: Run Black (code formatting)
      run: black --check --diff jobseeker tests
    
    - name: Run isort (import sorting)
      run: isort --check-only --diff jobseeker tests
    
    - name: Run Flake8 (linting)
      run: |
        flake8 jobseeker tests \
          --max-line-length=88 \
          --extend-ignore=E203,W503 \
          --statistics \
          --count
    
    - name: Run mypy (type checking)
      run: |
        mypy jobseeker \
          --ignore-missing-imports \
          --no-strict-optional \
          --show-error-codes
      continue-on-error: true  # mypy éŒ¯èª¤ä¸æœƒå°è‡´ CI å¤±æ•—
    
    - name: Run Bandit (security check)
      run: |
        bandit -r jobseeker \
          -f json \
          -o bandit-report.json
      continue-on-error: true
    
    - name: Run Safety (dependency security check)
      run: |
        safety check \
          --json \
          --output safety-report.json
      continue-on-error: true
    
    - name: Upload security reports
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json

  # å–®å…ƒæ¸¬è©¦
  unit-tests:
    name: Unit Tests
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ['3.10', '3.11', '3.12']
        exclude:
          # æ’é™¤ä¸€äº›çµ„åˆä»¥ç¯€çœ CI æ™‚é–“
          - os: macos-latest
            python-version: '3.10'
          - os: windows-latest
             python-version: '3.10'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: |
          ~/.cache/pip
          ~/AppData/Local/pip/Cache
          ~/Library/Caches/pip
        key: ${{ runner.os }}-pip-${{ env.CACHE_VERSION }}-${{ matrix.python-version }}-${{ hashFiles('requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-${{ env.CACHE_VERSION }}-${{ matrix.python-version }}-
          ${{ runner.os }}-pip-${{ env.CACHE_VERSION }}-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest pytest-asyncio pytest-cov pytest-xdist pytest-timeout pytest-mock
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
        if [ -f requirements-dev.txt ]; then pip install -r requirements-dev.txt; fi
      shell: bash
    
    - name: Run unit tests
      run: |
        python -m pytest tests/unit \
          -v \
          --tb=short \
          --strict-markers \
          --disable-warnings \
          --cov=jobseeker \
          --cov-report=xml \
          --cov-report=term-missing \
          --junit-xml=junit-unit.xml \
          --timeout=300
    
    - name: Upload test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: unit-test-results-${{ matrix.os }}-${{ matrix.python-version }}
        path: |
          junit-unit.xml
          coverage.xml
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.9'
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false

  # æ•´åˆæ¸¬è©¦
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: unit-tests
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ env.CACHE_VERSION }}-${{ hashFiles('requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-${{ env.CACHE_VERSION }}-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest pytest-asyncio pytest-cov pytest-xdist pytest-timeout
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
        if [ -f requirements-dev.txt ]; then pip install -r requirements-dev.txt; fi
    
    - name: Run integration tests
      run: |
        python -m pytest tests/integration \
          -v \
          --tb=short \
          --strict-markers \
          --disable-warnings \
          -m "integration" \
          --junit-xml=junit-integration.xml \
          --timeout=600
      env:
        # è¨­ç½®æ¸¬è©¦ç’°å¢ƒè®Šæ•¸
        jobseeker_TEST_MODE: "integration"
        jobseeker_CACHE_ENABLED: "true"
        jobseeker_LOG_LEVEL: "INFO"
    
    - name: Upload integration test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: integration-test-results
        path: junit-integration.xml

  # æ•ˆèƒ½æ¸¬è©¦
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    needs: unit-tests
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ env.CACHE_VERSION }}-${{ hashFiles('requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-${{ env.CACHE_VERSION }}-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest pytest-asyncio pytest-benchmark psutil
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
        if [ -f requirements-dev.txt ]; then pip install -r requirements-dev.txt; fi
    
    - name: Run performance tests
      run: |
        python -m pytest tests/performance \
          -v \
          --tb=short \
          --strict-markers \
          --disable-warnings \
          -m "performance" \
          --benchmark-json=benchmark.json \
          --junit-xml=junit-performance.xml \
          --timeout=1200
      env:
        jobseeker_TEST_MODE: "performance"
        jobseeker_PERFORMANCE_BASELINE: "true"
    
    - name: Upload performance test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: performance-test-results
        path: |
          junit-performance.xml
          benchmark.json

  # ç¶²è·¯æ¸¬è©¦ï¼ˆå¯é¸ï¼‰
  network-tests:
    name: Network Tests
    runs-on: ubuntu-latest
    needs: unit-tests
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ env.CACHE_VERSION }}-${{ hashFiles('requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-${{ env.CACHE_VERSION }}-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest pytest-asyncio pytest-timeout
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
        if [ -f requirements-dev.txt ]; then pip install -r requirements-dev.txt; fi
    
    - name: Run network tests
      run: |
        python -m pytest tests \
          -v \
          --tb=short \
          --strict-markers \
          --disable-warnings \
          -m "requires_network" \
          --junit-xml=junit-network.xml \
          --timeout=900
      env:
        jobseeker_TEST_MODE: "network"
        jobseeker_NETWORK_TIMEOUT: "30"
    
    - name: Upload network test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: network-test-results
        path: junit-network.xml

  # æ¸¬è©¦å ±å‘Šå½™ç¸½
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [code-quality, unit-tests, integration-tests, performance-tests]
    if: always()
    
    steps:
    - name: Download all test artifacts
      uses: actions/download-artifact@v3
    
    - name: Display test summary
      run: |
        echo "## æ¸¬è©¦åŸ·è¡Œæ‘˜è¦" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # æª¢æŸ¥å„å€‹æ¸¬è©¦éšæ®µçš„çµæœ
        if [ "${{ needs.code-quality.result }}" == "success" ]; then
          echo "âœ… ç¨‹å¼ç¢¼å“è³ªæª¢æŸ¥: é€šé" >> $GITHUB_STEP_SUMMARY
        else
          echo "âŒ ç¨‹å¼ç¢¼å“è³ªæª¢æŸ¥: å¤±æ•—" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ "${{ needs.unit-tests.result }}" == "success" ]; then
          echo "âœ… å–®å…ƒæ¸¬è©¦: é€šé" >> $GITHUB_STEP_SUMMARY
        else
          echo "âŒ å–®å…ƒæ¸¬è©¦: å¤±æ•—" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ "${{ needs.integration-tests.result }}" == "success" ]; then
          echo "âœ… æ•´åˆæ¸¬è©¦: é€šé" >> $GITHUB_STEP_SUMMARY
        else
          echo "âŒ æ•´åˆæ¸¬è©¦: å¤±æ•—" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ "${{ needs.performance-tests.result }}" == "success" ]; then
          echo "âœ… æ•ˆèƒ½æ¸¬è©¦: é€šé" >> $GITHUB_STEP_SUMMARY
        else
          echo "âŒ æ•ˆèƒ½æ¸¬è©¦: å¤±æ•—" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### æ¸¬è©¦è¦†è“‹ç‡" >> $GITHUB_STEP_SUMMARY
        echo "è©³ç´°çš„è¦†è“‹ç‡å ±å‘Šè«‹æŸ¥çœ‹ Codecovã€‚" >> $GITHUB_STEP_SUMMARY
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### æ¸¬è©¦æª”æ¡ˆ" >> $GITHUB_STEP_SUMMARY
        echo "æ‰€æœ‰æ¸¬è©¦çµæœæª”æ¡ˆå·²ä¸Šå‚³ç‚º artifactsï¼Œå¯åœ¨ Actions é é¢ä¸‹è¼‰ã€‚" >> $GITHUB_STEP_SUMMARY
    
    - name: Comment PR with test results
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const { owner, repo, number } = context.issue;
          
          const codeQuality = '${{ needs.code-quality.result }}' === 'success' ? 'âœ…' : 'âŒ';
          const unitTests = '${{ needs.unit-tests.result }}' === 'success' ? 'âœ…' : 'âŒ';
          const integrationTests = '${{ needs.integration-tests.result }}' === 'success' ? 'âœ…' : 'âŒ';
          const performanceTests = '${{ needs.performance-tests.result }}' === 'success' ? 'âœ…' : 'âŒ';
          
          const body = `## ğŸ§ª æ¸¬è©¦çµæœæ‘˜è¦
          
          | æ¸¬è©¦é¡å‹ | çµæœ |
          |---------|------|
          | ç¨‹å¼ç¢¼å“è³ªæª¢æŸ¥ | ${codeQuality} |
          | å–®å…ƒæ¸¬è©¦ | ${unitTests} |
          | æ•´åˆæ¸¬è©¦ | ${integrationTests} |
          | æ•ˆèƒ½æ¸¬è©¦ | ${performanceTests} |
          
          è©³ç´°çµæœè«‹æŸ¥çœ‹ [Actions é é¢](https://github.com/${owner}/${repo}/actions/runs/${{ github.run_id }})ã€‚
          `;
          
          github.rest.issues.createComment({
            owner,
            repo,
            issue_number: number,
            body
          });

  # éƒ¨ç½²æ¸¬è©¦å ±å‘Šï¼ˆåƒ…åœ¨ä¸»åˆ†æ”¯ï¼‰
  deploy-reports:
    name: Deploy Test Reports
    runs-on: ubuntu-latest
    needs: [test-summary]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Download test artifacts
      uses: actions/download-artifact@v3
    
    - name: Setup Pages
      uses: actions/configure-pages@v3
    
    - name: Build test report site
      run: |
        mkdir -p public
        echo "<h1>jobseeker æ¸¬è©¦å ±å‘Š</h1>" > public/index.html
        echo "<p>æœ€å¾Œæ›´æ–°: $(date)</p>" >> public/index.html
        
        # è¤‡è£½æ¸¬è©¦å ±å‘Šæª”æ¡ˆ
        find . -name "*.xml" -o -name "*.json" -o -name "*.html" | while read file; do
          cp "$file" public/ 2>/dev/null || true
        done
    
    - name: Upload Pages artifact
      uses: actions/upload-pages-artifact@v2
      with:
        path: public
    
    - name: Deploy to GitHub Pages
      uses: actions/deploy-pages@v2
      id: deployment

# æ¬Šé™è¨­å®š
permissions:
  contents: read
  pages: write
  id-token: write
  pull-requests: write
  checks: write
