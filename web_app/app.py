#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
jobseeker ç¶²é æ‡‰ç”¨
æä¾›ç°¡å–®æ˜“ç”¨çš„ç¶²é ç•Œé¢ï¼Œè®“ä¸€èˆ¬æ°‘çœ¾ç„¡éœ€ç¨‹å¼è¨­è¨ˆçŸ¥è­˜å³å¯ä½¿ç”¨è·ä½æœå°‹åŠŸèƒ½

åŠŸèƒ½:
1. ç¶²é ç•Œé¢ - ç°¡æ½”çš„æœå°‹è¡¨å–®
2. API ç«¯é» - RESTful API æ”¯æ´
3. å³æ™‚æœå°‹ - AJAX æ”¯æ´çš„å‹•æ…‹æœå°‹
4. çµæœå±•ç¤º - ç¾è§€çš„è·ä½åˆ—è¡¨å’Œè©³ç´°è³‡è¨Š
5. ä¸‹è¼‰åŠŸèƒ½ - CSV å’Œ JSON æ ¼å¼ä¸‹è¼‰

Author: jobseeker Team
Date: 2025-01-27
"""

import os
import sys
import json
import uuid
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
# æ”¯æ´æœ¬åœ°é–‹ç™¼å’Œ Railway éƒ¨ç½²ç’°å¢ƒ
project_root = Path(__file__).parent.parent
if project_root.name == 'web_app':  # Railway éƒ¨ç½²æ™‚çš„æƒ…æ³
    project_root = project_root.parent
sys.path.insert(0, str(project_root))

from flask import Flask, render_template, request, jsonify, send_file, flash, redirect, url_for, make_response
from flask_sqlalchemy import SQLAlchemy
from flask_login import LoginManager, login_user, logout_user, login_required, current_user, UserMixin
from werkzeug.security import generate_password_hash, check_password_hash
import time
from flask_cors import CORS
import pandas as pd

# å°å…¥ jobseeker æ ¸å¿ƒåŠŸèƒ½
try:
    from jobseeker.smart_router import smart_router
    from jobseeker.model import Site, Country
    from jobseeker.query_parser import parse_user_query_smart
    from jobseeker.intent_analyzer import analyze_user_intent, is_job_related
    from jobseeker.llm_intent_analyzer import LLMIntentAnalyzer
    from jobseeker.intelligent_decision_engine import DecisionResult, ProcessingStrategy, PlatformSelectionMode
except ImportError as e:
    print(f"è­¦å‘Š: ç„¡æ³•å°å…¥ jobseeker æ¨¡çµ„: {e}")
    print("è«‹ç¢ºä¿å·²æ­£ç¢ºå®‰è£ jobseeker å¥—ä»¶")
    sys.exit(1)

# å‰µå»º Flask æ‡‰ç”¨
app = Flask(__name__)
app.secret_key = os.environ.get('SECRET_KEY', 'jobseeker-web-app-secret-key-2025')

# å•Ÿç”¨ CORS æ”¯æ´
CORS(app)

# é…ç½®
app.config.update(
    MAX_CONTENT_LENGTH=16 * 1024 * 1024,  # 16MB æœ€å¤§ä¸Šå‚³å¤§å°
    UPLOAD_FOLDER=project_root / 'web_app' / 'downloads',
    TEMPLATES_AUTO_RELOAD=True,
    DEBUG=os.environ.get('FLASK_DEBUG', 'False').lower() == 'true',
    SQLALCHEMY_DATABASE_URI=f"sqlite:///{project_root / 'web_app' / 'db' / 'app.db'}",
    SQLALCHEMY_TRACK_MODIFICATIONS=False
)

# ç¢ºä¿ä¸‹è¼‰ç›®éŒ„å­˜åœ¨
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)
os.makedirs(project_root / 'web_app' / 'db', exist_ok=True)

# å…¨åŸŸè®Šæ•¸å„²å­˜æœå°‹çµæœ
search_results_cache = {}

# åˆå§‹åŒ–LLMæ„åœ–åˆ†æå™¨
# å˜—è©¦ä½¿ç”¨çœŸå¯¦çš„LLMæä¾›å•†ï¼Œå¦‚æœæ²’æœ‰APIå¯†é‘°å‰‡å›é€€åˆ°æ¨¡æ“¬æ¨¡å¼
try:
    from jobseeker.llm_intent_analyzer import LLMProvider
    
    # æª¢æŸ¥æ˜¯å¦æœ‰OpenAI APIå¯†é‘°
    openai_api_key = os.getenv('OPENAI_API_KEY')
    if openai_api_key:
        llm_intent_analyzer = LLMIntentAnalyzer(
            provider=LLMProvider.OPENAI_GPT35,
            api_key=openai_api_key,
            fallback_to_basic=True
        )
        print("âœ… LLMæ„åœ–åˆ†æå™¨å·²å•Ÿç”¨ - ä½¿ç”¨OpenAI GPT-3.5")
    else:
        # æ²’æœ‰APIå¯†é‘°ï¼Œä½¿ç”¨æ¨¡æ“¬æ¨¡å¼
        llm_intent_analyzer = LLMIntentAnalyzer(
            provider=LLMProvider.OPENAI_GPT35,  # æä¾›å•†è¨­ç½®ä½†æ²’æœ‰APIå¯†é‘°æœƒè‡ªå‹•å›é€€åˆ°æ¨¡æ“¬
            api_key=None,
            fallback_to_basic=True
        )
        print("âš ï¸  LLMæ„åœ–åˆ†æå™¨ä½¿ç”¨æ¨¡æ“¬æ¨¡å¼ - è«‹è¨­ç½®OPENAI_API_KEYç’°å¢ƒè®Šé‡ä»¥å•Ÿç”¨çœŸå¯¦LLM")
except Exception as e:
    # å¦‚æœå°å…¥å¤±æ•—ï¼Œä½¿ç”¨é»˜èªåˆå§‹åŒ–
    llm_intent_analyzer = LLMIntentAnalyzer()
    print(f"âš ï¸  LLMæ„åœ–åˆ†æå™¨åˆå§‹åŒ–å¤±æ•—ï¼Œä½¿ç”¨é»˜èªæ¨¡å¼: {e}")

db = SQLAlchemy(app)
login_manager = LoginManager(app)
login_manager.login_view = 'login'


class User(db.Model, UserMixin):
    id = db.Column(db.Integer, primary_key=True)
    email = db.Column(db.String(255), unique=True, nullable=False)
    password_hash = db.Column(db.String(255), nullable=False)
    created_at = db.Column(db.DateTime, default=datetime.utcnow)

    def set_password(self, password: str):
        self.password_hash = generate_password_hash(password)

    def check_password(self, password: str) -> bool:
        return check_password_hash(self.password_hash, password)


class Favorite(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    user_id = db.Column(db.Integer, db.ForeignKey('user.id'), nullable=False)
    title = db.Column(db.String(512))
    company = db.Column(db.String(512))
    location = db.Column(db.String(512))
    site = db.Column(db.String(64))
    job_url = db.Column(db.String(1024))
    job_url_direct = db.Column(db.String(1024))
    saved_at = db.Column(db.DateTime, default=datetime.utcnow)

    user = db.relationship('User', backref=db.backref('favorites', lazy=True))


class TestRun(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    started_at = db.Column(db.DateTime, default=datetime.utcnow)
    finished_at = db.Column(db.DateTime, nullable=True)
    total = db.Column(db.Integer, default=0)
    passed = db.Column(db.Integer, default=0)
    failed = db.Column(db.Integer, default=0)
    skipped = db.Column(db.Integer, default=0)
    duration_sec = db.Column(db.Float, default=0.0)


class TestCaseResult(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    run_id = db.Column(db.Integer, db.ForeignKey('test_run.id'), nullable=False)
    name = db.Column(db.String(255), nullable=False)
    status = db.Column(db.String(16), nullable=False)  # pass/fail/skip
    duration_ms = db.Column(db.Integer, default=0)
    message = db.Column(db.Text, nullable=True)
    created_at = db.Column(db.DateTime, default=datetime.utcnow)
    run = db.relationship('TestRun', backref=db.backref('cases', lazy=True))


@login_manager.user_loader
def load_user(user_id):
    return User.query.get(int(user_id))


@login_manager.unauthorized_handler
def unauthorized():
    # API è«‹æ±‚è¿”å› 401 JSONï¼Œå…¶é¤˜å°å‘ç™»å…¥é 
    if request.path.startswith('/api/'):
        return jsonify({'success': False, 'error': 'æœªç™»å…¥'}), 401
    flash('è«‹å…ˆç™»å…¥', 'warning')
    return redirect(url_for('login', next=request.url))


def is_admin_user() -> bool:
    if not current_user.is_authenticated:
        return False
    admin_emails = os.environ.get('ADMIN_EMAILS', '')
    allow = [e.strip().lower() for e in admin_emails.split(',') if e.strip()]
    if not allow:
        # Default: no admins unless explicitly configured
        return False
    return current_user.email.lower() in allow


def admin_required(fn):
    from functools import wraps
    @wraps(fn)
    def wrapper(*args, **kwargs):
        if not current_user.is_authenticated:
            return unauthorized()
        if not is_admin_user():
            flash('éœ€è¦ç®¡ç†å“¡æ¬Šé™', 'error')
            return redirect(url_for('index'))
        return fn(*args, **kwargs)
    return wrapper

# åˆå§‹åŒ–è³‡æ–™åº«
with app.app_context():
    db.create_all()

@app.context_processor
def inject_global_flags():
    return {'is_admin': is_admin_user()}

@app.route('/')
def index():
    """
    é¦–é  - é¡¯ç¤ºæœå°‹è¡¨å–®
    """
    return render_template('index.html')


@app.route('/debug')
def debug_test():
    """
    èª¿è©¦æ¸¬è©¦é é¢
    """
    return render_template('debug_test.html')


@app.route('/search', methods=['POST'])
def search_jobs():
    """
    åŸ·è¡Œè·ä½æœå°‹ (æ”¯æ´åˆ†é )
    
    æ¥å— JSON æˆ–è¡¨å–®æ•¸æ“š
    è¿”å›æœå°‹çµæœçš„ JSON éŸ¿æ‡‰ï¼ŒåŒ…å«åˆ†é è³‡è¨Š
    """
    try:
        # ç²å–è«‹æ±‚æ•¸æ“š
        if request.is_json:
            data = request.get_json()
        else:
            data = request.form.to_dict()
        
        # æå–æœå°‹åƒæ•¸ï¼ˆå–®æ¬„è¼¸å…¥ï¼Œåœ°é»å¯ç”±è§£æå¾—å‡ºï¼‰
        user_query = data.get('query', '').strip()
        location = data.get('location', '').strip() if data.get('location') is not None else ''
        results_wanted = int(data.get('results_wanted', 20))
        hours_old = data.get('hours_old')
        selected_sites = data.get('selected_sites', '')
        
        # æ–°å¢åˆ†é åƒæ•¸
        page = int(data.get('page', 1))
        per_page = int(data.get('per_page', 20))
        
        # é©—è­‰åˆ†é åƒæ•¸
        if page < 1:
            page = 1
        if per_page < 1 or per_page > 100:
            per_page = 20
        
        # è§£æå–®æ¬„æŸ¥è©¢ï¼ˆLLM-ready è¦å‰‡å¼è§£æï¼‰
        parsed = parse_user_query_smart(user_query)

        # è‹¥æœªé¡¯å¼æä¾›åœ°é»ï¼Œä½¿ç”¨è§£æåˆ°çš„åœ°é»
        derived_location = location if location else (parsed.location or '')

        # å˜—è©¦æ¨æ–·åœ‹å®¶ï¼ˆä¾› Indeed/Glassdoor ç­‰åŸŸåé¸æ“‡ï¼‰
        derived_country = None
        try:
            if parsed.location:
                # Country.from_string æ”¯æ´è‹±æ–‡é—œéµè©ï¼Œå¦‚ 'australia','uk','usa','taiwan'
                derived_country = Country.from_string(parsed.location).value[0]
        except Exception:
            derived_country = None

        # è™•ç†é¸æ“‡çš„ç¶²ç«™
        site_name = None
        if selected_sites:
            # å¦‚æœselected_sitesæ˜¯å­—ç¬¦ä¸²ï¼Œè½‰æ›ç‚ºåˆ—è¡¨
            if isinstance(selected_sites, str):
                sites_list = [site.strip() for site in selected_sites.split(',') if site.strip()]
            else:
                # å¦‚æœå·²ç¶“æ˜¯åˆ—è¡¨ï¼Œç›´æ¥ä½¿ç”¨
                sites_list = [site.strip() for site in selected_sites if site.strip()]
            
            if len(sites_list) == 1:
                # å¦‚æœåªé¸æ“‡äº†ä¸€å€‹ç¶²ç«™ï¼Œä½¿ç”¨è©²ç¶²ç«™
                site_name = sites_list[0]
            elif len(sites_list) > 1:
                # å¦‚æœé¸æ“‡äº†å¤šå€‹ç¶²ç«™ï¼Œä½¿ç”¨æ™ºèƒ½è·¯ç”±ä½†é™åˆ¶åœ¨é¸æ“‡çš„ç¶²ç«™å…§
                print(f"å¤šå¹³å°æœå°‹: {sites_list}")
                # ä¿æŒ site_name ç‚º Noneï¼Œè®“æ™ºèƒ½è·¯ç”±è™•ç†ï¼Œä½†æœƒé€šé selected_sites é™åˆ¶
            # å¦‚æœé¸æ“‡äº†å¤šå€‹ç¶²ç«™ï¼Œä¿æŒ site_name ç‚º Noneï¼ˆæœå°‹æ‰€æœ‰ç¶²ç«™ï¼‰
        elif parsed.site_hints and len(parsed.site_hints) == 1:
            # ä½¿ç”¨æŸ¥è©¢ä¸­çš„å–®ä¸€ç«™é»æç¤º
            site_name = parsed.site_hints[0]
        
        # é©—è­‰è¼¸å…¥
        if not user_query:
            return jsonify({
                'success': False,
                'error': 'è«‹è¼¸å…¥æœå°‹é—œéµå­—'
            }), 400
        
        # ä½¿ç”¨LLMæ™ºèƒ½æ„åœ–åˆ†æå™¨é€²è¡Œåˆ†æå’Œæ±ºç­–
        try:
            llm_intent_result, decision_result = llm_intent_analyzer.analyze_intent_with_decision(user_query)
            
            # æª¢æŸ¥æ˜¯å¦ç‚ºæ±‚è·ç›¸é—œæŸ¥è©¢
            if not llm_intent_result.is_job_related:
                return jsonify({
                    'success': False,
                    'error': llm_intent_result.rejection_message or 'æŠ±æ­‰ï¼Œæˆ‘æ˜¯AIåŠ©æ‰‹ï¼Œåƒ…èƒ½å”åŠ©æ‚¨è™•ç†æ±‚è·ç›¸é—œå•é¡Œï¼Œç„¡æ³•é€²è¡Œä¸€èˆ¬èŠå¤©ã€‚',
                    'intent_analysis': {
                        'intent_type': llm_intent_result.intent_type.value if llm_intent_result.intent_type else 'unclear',
                        'confidence': llm_intent_result.confidence,
                        'analysis_method': 'llm' if llm_intent_result.llm_used else 'basic'
                    },
                    'decision_analysis': {
                        'strategy': decision_result.strategy.value if decision_result else 'unknown',
                        'confidence': decision_result.confidence if decision_result else 0.0,
                        'reasoning': decision_result.reasoning if decision_result else ''
                    }
                }), 400
            
            # æ ¹æ“šæ±ºç­–çµæœèª¿æ•´æœç´¢åƒæ•¸
            if decision_result and decision_result.strategy != ProcessingStrategy.REJECT_QUERY:
                # ä½¿ç”¨æ±ºç­–å¼•æ“æ¨è–¦çš„å¹³å°
                if decision_result.recommended_platforms:
                    # å°‡å¹³å°åç¨±æ˜ å°„åˆ°Siteæšèˆ‰
                    platform_mapping = {
                        'indeed': 'indeed',
                        'linkedin': 'linkedin', 
                        'seek': 'seek',
                        '104': '104',
                        'ziprecruiter': 'zip_recruiter'
                    }
                    
                    recommended_sites = []
                    for platform in decision_result.recommended_platforms:
                        if platform in platform_mapping:
                            recommended_sites.append(platform_mapping[platform])
                    
                    if recommended_sites and not selected_sites:
                        selected_sites = recommended_sites
                
                # ä½¿ç”¨æ±ºç­–çµæœä¸­çš„æœç´¢åƒæ•¸
                if 'max_results' in decision_result.search_parameters:
                    results_wanted = min(decision_result.search_parameters['max_results'], results_wanted)
            
            # å¦‚æœLLMæˆåŠŸåˆ†æå‡ºçµæ§‹åŒ–æ„åœ–ï¼Œä½¿ç”¨LLMçš„æœç´¢æ¢ä»¶
            if llm_intent_result.llm_used and llm_intent_result.structured_intent:
                structured_intent = llm_intent_result.structured_intent
                
                # ä½¿ç”¨LLMæå–çš„æœç´¢æ¢ä»¶è¦†è“‹åŸå§‹è§£æçµæœ
                if structured_intent.job_titles:
                    # å°‡è·ä½æ¨™é¡Œçµ„åˆç‚ºæœç´¢è©
                    parsed.search_term = ' OR '.join(structured_intent.job_titles)
                
                if structured_intent.location and not location:
                    # å¦‚æœLLMè­˜åˆ¥å‡ºåœ°é»ä¸”ç”¨æˆ¶æœªæ˜ç¢ºæŒ‡å®šåœ°é»ï¼Œä½¿ç”¨LLMçš„åœ°é»
                    derived_location = structured_intent.location
                
                print(f"LLMæ„åœ–åˆ†ææˆåŠŸ: è·ä½={structured_intent.job_titles}, æŠ€èƒ½={structured_intent.skills}, åœ°é»={structured_intent.location}")
                print(f"æ±ºç­–çµæœ: ç­–ç•¥={decision_result.strategy.value if decision_result else 'unknown'}, æ¨è–¦å¹³å°={decision_result.recommended_platforms if decision_result else []}")
            else:
                print(f"ä½¿ç”¨åŸºç¤æ„åœ–åˆ†æ: {parsed.search_term}")
                
        except Exception as e:
            print(f"æ™ºèƒ½æ„åœ–åˆ†æå¤±æ•—: {e}")
            llm_intent_result = None
            decision_result = None
        
        if results_wanted < 1 or results_wanted > 100:
            return jsonify({
                'success': False,
                'error': 'æœå°‹çµæœæ•¸é‡å¿…é ˆåœ¨ 1-100 ä¹‹é–“'
            }), 400
        
        # è™•ç†æ™‚é–“é™åˆ¶
        if hours_old:
            try:
                hours_old = int(hours_old)
                if hours_old < 1:
                    hours_old = None
            except (ValueError, TypeError):
                hours_old = None
        
        # ç”Ÿæˆæœå°‹ ID
        search_id = str(uuid.uuid4())
        
        # åŸ·è¡Œæ™ºèƒ½æœå°‹
        print(f"é–‹å§‹æœå°‹: {parsed.search_term}")
        if site_name:
            print(f"æŒ‡å®šæœå°‹ç¶²ç«™: {site_name}")
        else:
            print(f"é¸æ“‡çš„ç¶²ç«™: {selected_sites if selected_sites else 'æ‰€æœ‰ç¶²ç«™'}")
            
        # ä½¿ç”¨æ–°çš„æ™ºèƒ½è·¯ç”±å™¨
        if site_name:
            # å–®å¹³å°æœå°‹
            result = smart_router.search_jobs(
                query=parsed.search_term,
                location=derived_location if derived_location else None,
                max_results=results_wanted,
                platforms=[site_name]
            )
        else:
            # å¤šå¹³å°æ™ºèƒ½æœå°‹
            result = smart_router.search_jobs(
                query=parsed.search_term,
                location=derived_location if derived_location else None,
                max_results=results_wanted
            )
        
        # è™•ç†æœå°‹çµæœ
        if result.total_jobs == 0:
            return jsonify({
                'success': True,
                'search_id': search_id,
                'total_jobs': 0,
                'message': 'æœªæ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„è·ä½ï¼Œè«‹å˜—è©¦èª¿æ•´æœå°‹æ¢ä»¶',
                'jobs': [],
                'routing_info': {
                    'successful_platforms': result.successful_platforms,
                    'failed_platforms': result.failed_platforms,
                    'execution_time': result.total_execution_time
                },
                'pagination': {
                    'page': page,
                    'per_page': per_page,
                    'total': 0,
                    'total_pages': 0,
                    'has_next': False,
                    'has_prev': False
                }
            })
        
        # è½‰æ›è·ä½æ•¸æ“šç‚ºå­—å…¸æ ¼å¼
        jobs_list = []
        if result.jobs:
            for job in result.jobs:
                job_dict = {
                    'title': str(job.title or ''),
                    'company': str(job.company_name or ''),
                    'location': str(job.location.city if job.location else ''),
                    'description': str(job.description or '')[:500] + ('...' if len(str(job.description or '')) > 500 else ''),
                    'salary_min': None,  # æ–°æ¶æ§‹ä¸­éœ€è¦å¾compensationè§£æ
                    'salary_max': None,  # æ–°æ¶æ§‹ä¸­éœ€è¦å¾compensationè§£æ
                    'salary_currency': '',  # æ–°æ¶æ§‹ä¸­éœ€è¦å¾compensationè§£æ
                    'date_posted': str(job.date_posted or ''),
                    'job_url': str(job.job_url or ''),
                    'job_url_direct': str(job.job_url_direct or ''),
                    'site': str(job.site or ''),
                    'job_type': str(job.job_type or ''),
                    'is_remote': bool(job.is_remote or False)
                }
                jobs_list.append(job_dict)

        # å¯é¸ï¼šåš´æ ¼åœ‹å®¶éæ¿¾ï¼ˆé¿å…ã€Œæ¾³æ´²ã€å‡ºç¾å…¶ä»–åœ‹å®¶ï¼‰
        strict_filter = os.environ.get('STRICT_COUNTRY_FILTER', 'false').lower() == 'true'
        if strict_filter and (derived_country or derived_location):
            country_tokens = set()
            if derived_country:
                country_tokens.add(derived_country.lower())
            # å¸¸è¦‹åŒç¾©è©
            synonyms = {
                'australia': ['australia', 'æ¾³æ´²', 'æ¾³å¤§åˆ©äº', 'æ¾³å¤§åˆ©äºš'],
                'taiwan': ['taiwan', 'å°ç£', 'è‡ºç£'],
                'hong kong': ['hong kong', 'é¦™æ¸¯'],
                'singapore': ['singapore', 'æ–°åŠ å¡'],
                'japan': ['japan', 'æ—¥æœ¬'],
                'usa': ['usa', 'united states', 'america', 'ç¾åœ‹', 'ç¾å›½'],
                'uk': ['uk', 'united kingdom', 'england', 'è‹±åœ‹', 'è‹±å›½'],
                'new zealand': ['new zealand', 'ç´è¥¿è˜­', 'æ–°è¥¿è˜­'],
                'canada': ['canada', 'åŠ æ‹¿å¤§']
            }
            if derived_country and derived_country.lower() in synonyms:
                country_tokens.update(synonyms[derived_country.lower()])
            # ç²—ç•¥éæ¿¾
            jobs_list = [j for j in jobs_list if any(tok in (j.get('location','').lower()) for tok in country_tokens)]

        # å¿«å–æœå°‹çµæœ
        search_results_cache[search_id] = {
            'result': result,
            'timestamp': datetime.now(),
            'query': parsed.search_term,
            'location': derived_location
        }
        
        # ä¼ºæœå™¨ç«¯åˆ†é åˆ‡ç‰‡
        total = len(jobs_list)
        total_pages = (total + per_page - 1) // per_page if per_page else 1
        start = (page - 1) * per_page
        end = start + per_page
        page_jobs = jobs_list[start:end]
        
        # è¿”å›æˆåŠŸéŸ¿æ‡‰ï¼ˆå«åˆ†é è³‡è¨Šï¼‰
        return jsonify({
            'success': True,
            'search_id': search_id,
            'total_jobs': total,
            'jobs': page_jobs,
            'routing_info': {
                'successful_platforms': result.successful_platforms,
                'failed_platforms': result.failed_platforms,
                'execution_time': result.total_execution_time,
                'search_metadata': result.search_metadata
            },
            'search_params': {
                'query': user_query,
                'location': location,
                'results_wanted': results_wanted,
                'hours_old': hours_old
            },
            'pagination': {
                'page': page,
                'per_page': per_page,
                'total': total,
                'total_pages': total_pages,
                'has_next': page < total_pages,
                'has_prev': page > 1
            }
        })
        
    except Exception as e:
        print(f"æœå°‹éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        
        return jsonify({
            'success': False,
            'error': f'æœå°‹éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}'
        }), 500


@app.route('/download/<search_id>/<format>')
def download_results(search_id, format):
    """
    ä¸‹è¼‰æœå°‹çµæœ
    
    Args:
        search_id: æœå°‹ ID
        format: ä¸‹è¼‰æ ¼å¼ (csv, json)
    """
    try:
        # æª¢æŸ¥æœå°‹çµæœæ˜¯å¦å­˜åœ¨
        if search_id not in search_results_cache:
            flash('æœå°‹çµæœä¸å­˜åœ¨æˆ–å·²éæœŸ', 'error')
            return redirect(url_for('index'))
        
        cached_result = search_results_cache[search_id]
        result = cached_result['result']
        
        if result.combined_jobs_data is None or result.total_jobs == 0:
            flash('æ²’æœ‰å¯ä¸‹è¼‰çš„æœå°‹çµæœ', 'warning')
            return redirect(url_for('index'))
        
        # ç”Ÿæˆæª”æ¡ˆåç¨±
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        query_safe = ''.join(c for c in cached_result['query'][:20] if c.isalnum() or c in (' ', '-', '_')).strip()
        
        if format.lower() == 'csv':
            filename = f"jobseeker_{query_safe}_{timestamp}.csv"
            filepath = app.config['UPLOAD_FOLDER'] / filename
            
            # è½‰æ›ç‚ºæ¨™æº–æ ¼å¼
            standardized_data = convert_to_standard_format(result.combined_jobs_data)
            
            # å„²å­˜ CSV æª”æ¡ˆ
            standardized_data.to_csv(filepath, index=False, encoding='utf-8-sig')
            
            return send_file(
                filepath,
                as_attachment=True,
                download_name=filename,
                mimetype='text/csv'
            )
            
        elif format.lower() == 'json':
            filename = f"jobseeker_{query_safe}_{timestamp}.json"
            filepath = app.config['UPLOAD_FOLDER'] / filename
            
            # è½‰æ›ç‚º JSON æ ¼å¼
            jobs_data = result.combined_jobs_data.fillna('').to_dict('records')
            
            export_data = {
                'search_info': {
                    'query': cached_result['query'],
                    'location': cached_result['location'],
                    'timestamp': cached_result['timestamp'].isoformat(),
                    'total_jobs': result.total_jobs
                },
                'routing_info': {
                    'successful_agents': [agent.value for agent in result.successful_agents],
                    'failed_agents': [agent.value for agent in result.failed_agents],
                    'confidence_score': result.routing_decision.confidence_score,
                    'execution_time': result.total_execution_time
                },
                'jobs': jobs_data
            }
            
            # å„²å­˜ JSON æª”æ¡ˆ
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, ensure_ascii=False, indent=2, default=str)
            
            return send_file(
                filepath,
                as_attachment=True,
                download_name=filename,
                mimetype='application/json'
            )
        
        else:
            flash('ä¸æ”¯æ´çš„ä¸‹è¼‰æ ¼å¼', 'error')
            return redirect(url_for('index'))
            
    except Exception as e:
        print(f"ä¸‹è¼‰éŒ¯èª¤: {e}")
        flash(f'ä¸‹è¼‰å¤±æ•—: {str(e)}', 'error')
        return redirect(url_for('index'))


@app.route('/demo')
def demo_results():
    """
    å±•ç¤ºæ¸¬è©¦çµæœé é¢
    """
    # ç¦æ­¢å¿«å–ï¼Œç¢ºä¿é¡¯ç¤ºæœ€æ–°è³‡æ–™
    resp = make_response(render_template('demo_results.html'))
    resp.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, max-age=0'
    resp.headers['Pragma'] = 'no-cache'
    return resp


# ============ Auth Pages ============

@app.route('/login', methods=['GET', 'POST'])
def login():
    if request.method == 'POST':
        email = request.form.get('email', '').strip().lower()
        password = request.form.get('password', '')
        user = User.query.filter_by(email=email).first()
        if user and user.check_password(password):
            login_user(user)
            flash('ç™»å…¥æˆåŠŸ', 'success')
            next_url = request.args.get('next') or url_for('index')
            return redirect(next_url)
        flash('å¸³è™Ÿæˆ–å¯†ç¢¼éŒ¯èª¤', 'error')
    return render_template('login.html')


@app.route('/register', methods=['GET', 'POST'])
def register():
    if request.method == 'POST':
        email = request.form.get('email', '').strip().lower()
        password = request.form.get('password', '')
        if not email or not password:
            flash('è«‹è¼¸å…¥å®Œæ•´è³‡æ–™', 'error')
            return render_template('register.html')
        if User.query.filter_by(email=email).first():
            flash('æ­¤ Email å·²è¢«è¨»å†Š', 'error')
            return render_template('register.html')
        user = User(email=email)
        user.set_password(password)
        db.session.add(user)
        db.session.commit()
        login_user(user)
        flash('è¨»å†ŠæˆåŠŸï¼Œå·²è‡ªå‹•ç™»å…¥', 'success')
        return redirect(url_for('index'))
    return render_template('register.html')


@app.route('/logout')
@login_required
def logout():
    logout_user()
    flash('æ‚¨å·²ç™»å‡º', 'info')
    return redirect(url_for('index'))


@app.route('/favorites')
@login_required
def favorites_page():
    favs = Favorite.query.filter_by(user_id=current_user.id).order_by(Favorite.saved_at.desc()).all()
    return render_template('favorites.html', favorites=favs)


# ============ Admin: Synthetic Test Runner ============

def run_synthetic_tests() -> int:
    """Run a suite of lightweight synthetic tests via Flask test_client.
    Returns run_id.
    """
    run = TestRun()
    db.session.add(run)
    db.session.commit()

    def record(name: str, status: str, start_t: float, message: str = ""):
        case = TestCaseResult(
            run_id=run.id,
            name=name,
            status=status,
            duration_ms=int((time.time() - start_t) * 1000),
            message=message[:2000]
        )
        db.session.add(case)
        db.session.commit()

    total = passed = failed = skipped = 0

    with app.test_client() as client:
        # Health
        total += 1
        t0 = time.time()
        try:
            r = client.get('/health')
            if r.status_code == 200 and r.json.get('status') == 'healthy':
                passed += 1; record('health', 'pass', t0)
            else:
                failed += 1; record('health', 'fail', t0, f"status={r.status_code}")
        except Exception as e:
            failed += 1; record('health', 'fail', t0, str(e))

        # Homepage
        total += 1
        t0 = time.time()
        try:
            r = client.get('/')
            if r.status_code == 200 and 'æ™ºèƒ½è·ä½æœå°‹'.encode('utf-8') in r.data:
                passed += 1; record('homepage', 'pass', t0)
            else:
                failed += 1; record('homepage', 'fail', t0, f"status={r.status_code}")
        except Exception as e:
            failed += 1; record('homepage', 'fail', t0, str(e))

        # Search (may return zero jobs; still pass if success flag)
        total += 1
        t0 = time.time()
        try:
            payload = {"query": "å°åŒ— AI å·¥ç¨‹å¸«", "results_wanted": 5, "hours_old": 168, "page": 1, "per_page": 5}
            r = client.post('/search', json=payload)
            if r.status_code == 200 and r.json.get('success'):
                passed += 1; record('search_basic', 'pass', t0, f"jobs={len(r.json.get('jobs', []))}")
                search_id = r.json.get('search_id')
                # Download JSON if jobs present
                if search_id and r.json.get('total_jobs', 0) > 0:
                    total += 1
                    t1 = time.time()
                    r2 = client.get(f"/download/{search_id}/json")
                    if r2.status_code == 200 and r2.mimetype == 'application/json':
                        passed += 1; record('download_json', 'pass', t1)
                    else:
                        failed += 1; record('download_json', 'fail', t1, f"status={r2.status_code}")
                else:
                    # Skip download if no results
                    total += 1; skipped += 1; record('download_json', 'skip', t0, 'no results')
            else:
                failed += 1; record('search_basic', 'fail', t0, f"status={r.status_code}")
        except Exception as e:
            failed += 1; record('search_basic', 'fail', t0, str(e))

        # Auth flow + favorites
        total += 1
        t0 = time.time()
        try:
            email = f"test+{int(time.time())}@example.com"
            r = client.post('/register', data={'email': email, 'password': 'P@ssw0rd!'}, follow_redirects=True)
            if r.status_code == 200:
                fav_payload = {
                    'title': 'Synthetic Tester', 'company': 'JobSeeker', 'location': 'å°åŒ—',
                    'site': 'linkedin', 'job_url': 'https://example.com', 'job_url_direct': ''
                }
                r2 = client.post('/api/favorites', json=fav_payload)
                if r2.status_code == 200 and r2.json.get('success'):
                    passed += 1; record('auth_favorite', 'pass', t0)
                else:
                    failed += 1; record('auth_favorite', 'fail', t0, f"status={r2.status_code}")
            else:
                failed += 1; record('auth_favorite', 'fail', t0, f"status={r.status_code}")
        except Exception as e:
            failed += 1; record('auth_favorite', 'fail', t0, str(e))

    run.total = total
    run.passed = passed
    run.failed = failed
    run.skipped = skipped
    run.finished_at = datetime.utcnow()
    run.duration_sec = (run.finished_at - run.started_at).total_seconds()
    db.session.commit()
    return run.id


@app.route('/admin/tests')
@login_required
@admin_required
def admin_tests_page():
    runs = TestRun.query.order_by(TestRun.id.desc()).limit(10).all()
    return render_template('admin_tests.html', runs=runs)


@app.route('/api/admin/run-tests', methods=['POST'])
@login_required
@admin_required
def api_admin_run_tests():
    run_id = run_synthetic_tests()
    return jsonify({'success': True, 'run_id': run_id})
@app.route('/api/favorites', methods=['GET', 'POST'])
@login_required
def favorites_api():
    if request.method == 'POST':
        data = request.get_json(force=True)
        fav = Favorite(
            user_id=current_user.id,
            title=data.get('title'),
            company=data.get('company'),
            location=data.get('location'),
            site=data.get('site'),
            job_url=data.get('job_url'),
            job_url_direct=data.get('job_url_direct')
        )
        db.session.add(fav)
        db.session.commit()
        return jsonify({'success': True, 'id': fav.id})
    # GET
    favs = Favorite.query.filter_by(user_id=current_user.id).order_by(Favorite.saved_at.desc()).all()
    return jsonify({'success': True, 'favorites': [
        {
            'id': f.id,
            'title': f.title,
            'company': f.company,
            'location': f.location,
            'site': f.site,
            'job_url': f.job_url,
            'job_url_direct': f.job_url_direct,
            'saved_at': f.saved_at.isoformat()
        } for f in favs
    ]})


@app.route('/api/favorites/<int:fav_id>', methods=['DELETE'])
@login_required
def delete_favorite(fav_id):
    fav = Favorite.query.filter_by(id=fav_id, user_id=current_user.id).first()
    if not fav:
        return jsonify({'success': False, 'error': 'æ‰¾ä¸åˆ°æ”¶è—'}), 404
    db.session.delete(fav)
    db.session.commit()
    return jsonify({'success': True})


@app.route('/api/sites')
def get_supported_sites():
    """
    ç²å–æ”¯æ´çš„æ±‚è·ç¶²ç«™åˆ—è¡¨
    """
    try:
        sites = [{
            'value': site.value,
            'name': site.value.title(),
            'description': get_site_description(site)
        } for site in Site]
        
        return jsonify({
            'success': True,
            'sites': sites
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/search/<search_id>')
def get_search_result(search_id: str):
    """
    å–å¾—æŒ‡å®šæœå°‹ ID çš„çµæœï¼ˆç”¨æ–¼ Demo/çµæœé å‹•æ…‹é¡¯ç¤ºï¼‰
    """
    try:
        if search_id not in search_results_cache:
            return jsonify({'success': False, 'error': 'æœå°‹çµæœä¸å­˜åœ¨æˆ–å·²éæœŸ'}), 404

        cached = search_results_cache[search_id]
        result = cached['result']

        # å¯é¸åˆ†é åƒæ•¸
        try:
            page = int(request.args.get('page', 0))
        except Exception:
            page = 0
        try:
            per_page = int(request.args.get('per_page', 0))
        except Exception:
            per_page = 0

        jobs_list = []
        if result.combined_jobs_data is not None:
            df_clean = result.combined_jobs_data.fillna('')
            for _, row in df_clean.iterrows():
                jobs_list.append({
                    'title': str(row.get('title', '')),
                    'company': str(row.get('company', '')),
                    'location': str(row.get('location', '')),
                    'description': str(row.get('description', ''))[:500] + ('...' if len(str(row.get('description', ''))) > 500 else ''),
                    'salary_min': float(row['salary_min']) if pd.notna(row.get('salary_min')) else None,
                    'salary_max': float(row['salary_max']) if pd.notna(row.get('salary_max')) else None,
                    'salary_currency': str(row.get('salary_currency', '')),
                    'date_posted': str(row.get('date_posted', '')),
                    'job_url': str(row.get('job_url', '')),
                    'job_url_direct': str(row.get('job_url_direct', '')),
                    'site': str(row.get('site', '')),
                    'job_type': str(row.get('job_type', '')),
                    'is_remote': bool(row.get('is_remote', False))
                })

        # åˆ†é åˆ‡ç‰‡ï¼ˆè‹¥æä¾› page/per_pageï¼‰
        total = len(jobs_list)
        if page and per_page:
            if page < 1:
                page = 1
            if per_page < 1:
                per_page = 10
            total_pages = (total + per_page - 1) // per_page
            start = (page - 1) * per_page
            end = start + per_page
            page_jobs = jobs_list[start:end]
        else:
            total_pages = 1
            page_jobs = jobs_list
            page = 1
            per_page = total or 1

        return jsonify({
            'success': True,
            'search_id': search_id,
            'timestamp': cached['timestamp'].isoformat(),
            'query': cached.get('query'),
            'location': cached.get('location'),
            'total_jobs': result.total_jobs,
            'routing_info': {
                'successful_agents': [agent.value for agent in result.successful_agents],
                'failed_agents': [agent.value for agent in result.failed_agents],
                'confidence_score': result.routing_decision.confidence_score,
                'execution_time': result.total_execution_time
            },
            'jobs': page_jobs,
            'pagination': {
                'page': page,
                'per_page': per_page,
                'total': total,
                'total_pages': total_pages,
                'has_next': page < total_pages,
                'has_prev': page > 1
            }
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/search/latest')
def get_latest_search_result():
    """
    å–å¾—æœ€è¿‘ä¸€æ¬¡æœå°‹çµæœæ‘˜è¦
    """
    try:
        if not search_results_cache:
            return jsonify({'success': False, 'error': 'å°šç„¡æœå°‹è¨˜éŒ„'}), 404

        # æ‰¾å‡ºæœ€æ–°çš„æœå°‹
        latest_id = max(search_results_cache.items(), key=lambda kv: kv[1]['timestamp'])[0]
        return get_search_result(latest_id)
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/countries')
def get_supported_countries():
    """
    ç²å–æ”¯æ´çš„åœ‹å®¶åˆ—è¡¨
    """
    try:
        countries = [{
            'value': country.value[0],  # åœ‹å®¶åç¨±
            'code': country.value[1],   # åœ‹å®¶ä»£ç¢¼
            'name': country.name
        } for country in Country]
        
        return jsonify({
            'success': True,
            'countries': countries
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/health')
def health_check():
    """
    å¥åº·æª¢æŸ¥ç«¯é»
    """
    return jsonify({
        'status': 'healthy',
        'timestamp': datetime.now().isoformat(),
        'version': '1.0.0'
    })


def convert_to_standard_format(df: pd.DataFrame) -> pd.DataFrame:
    """
    è½‰æ›è·ä½æ•¸æ“šç‚ºæ¨™æº–æ ¼å¼
    æŒ‰ç…§ç”¨æˆ¶æŒ‡å®šçš„æ ¼å¼ï¼šSITE, TITLE, COMPANY, CITY, STATE, JOB_TYPE, INTERVAL, MIN_AMOUNT, MAX_AMOUNT, JOB_URL, DESCRIPTION
    
    Args:
        df: åŸå§‹è·ä½æ•¸æ“š DataFrame
        
    Returns:
        æ¨™æº–åŒ–çš„ DataFrame
    """
    # å‰µå»ºæ¨™æº–åŒ–çš„ DataFrame
    standardized_df = pd.DataFrame()
    
    # æŒ‰ç…§æ¨™æº–æ ¼å¼æ˜ å°„æ¬„ä½
    standardized_df['SITE'] = df.get('site', '').fillna('')
    standardized_df['TITLE'] = df.get('title', '').fillna('')
    standardized_df['COMPANY'] = df.get('company', '').fillna('')
    
    # è™•ç†åœ°é»è³‡è¨Š - åˆ†é›¢åŸå¸‚å’Œå·/çœ
    location = df.get('location', '').fillna('')
    standardized_df['CITY'] = location.apply(extract_city)
    standardized_df['STATE'] = location.apply(extract_state)
    
    standardized_df['JOB_TYPE'] = df.get('job_type', '').fillna('')
    standardized_df['INTERVAL'] = df.get('interval', '').fillna('')
    standardized_df['MIN_AMOUNT'] = df.get('min_amount', '').fillna('')
    standardized_df['MAX_AMOUNT'] = df.get('max_amount', '').fillna('')
    standardized_df['JOB_URL'] = df.get('job_url', '').fillna('')
    standardized_df['DESCRIPTION'] = df.get('description', '').fillna('')
    
    return standardized_df


def extract_city(location_str):
    """
    å¾åœ°é»å­—ä¸²ä¸­æå–åŸå¸‚åç¨±
    
    Args:
        location_str: åœ°é»å­—ä¸²
        
    Returns:
        åŸå¸‚åç¨±
    """
    if pd.isna(location_str) or location_str == '':
        return ''
    
    # åˆ†å‰²åœ°é»å­—ä¸²ï¼Œé€šå¸¸æ ¼å¼ç‚º "City, State" æˆ– "City"
    parts = str(location_str).split(',')
    return parts[0].strip() if parts else ''


def extract_state(location_str):
    """
    å¾åœ°é»å­—ä¸²ä¸­æå–å·/çœåç¨±
    
    Args:
        location_str: åœ°é»å­—ä¸²
        
    Returns:
        å·/çœåç¨±
    """
    if pd.isna(location_str) or location_str == '':
        return ''
    
    # åˆ†å‰²åœ°é»å­—ä¸²ï¼Œé€šå¸¸æ ¼å¼ç‚º "City, State" æˆ– "City"
    parts = str(location_str).split(',')
    return parts[1].strip() if len(parts) > 1 else ''


def get_site_description(site: Site) -> str:
    """
    ç²å–æ±‚è·ç¶²ç«™æè¿°
    
    Args:
        site: Site æšèˆ‰å€¼
        
    Returns:
        ç¶²ç«™æè¿°å­—ä¸²
    """
    descriptions = {
        'indeed': 'å…¨çƒæœ€å¤§çš„æ±‚è·ç¶²ç«™ï¼Œæ¶µè“‹å„è¡Œå„æ¥­',
        'linkedin': 'å°ˆæ¥­äººè„ˆç¶²ç«™ï¼Œé©åˆç™½é ˜å’Œç®¡ç†è·ä½',
        'glassdoor': 'æä¾›å…¬å¸è©•åƒ¹å’Œè–ªè³‡è³‡è¨Š',
        'seek': 'æ¾³æ´²å’Œç´è¥¿è˜­æœ€å¤§çš„æ±‚è·ç¶²ç«™',
        'zip_recruiter': 'ç¾åœ‹çŸ¥åæ±‚è·ç¶²ç«™ï¼ŒAI æ™ºèƒ½åŒ¹é…',
        'google': 'Google è·ä½æœå°‹ï¼Œæ•´åˆå¤šå€‹å¹³å°',
        'naukri': 'å°åº¦æœ€å¤§çš„æ±‚è·ç¶²ç«™',
        'bayt': 'ä¸­æ±åœ°å€é ˜å…ˆçš„æ±‚è·å¹³å°',
        'bdjobs': 'å­ŸåŠ æ‹‰åœ‹æœ¬åœ°æ±‚è·ç¶²ç«™',
        '104': 'å°ç£ 104 äººåŠ›éŠ€è¡Œï¼Œæœ¬åœ°åœ¨åœ°å¹³å°',
        '1111': 'å°ç£ 1111 äººåŠ›éŠ€è¡Œï¼Œæœ¬åœ°åœ¨åœ°å¹³å°'
    }
    
    return descriptions.get(site.value, f'{site.value.title()} æ±‚è·ç¶²ç«™')


@app.route('/docs')
def docs_page():
    """
    æ–‡æª”é é¢
    é¡¯ç¤º jobseeker çš„ä½¿ç”¨æ–‡æª”å’Œ API èªªæ˜
    """
    return render_template('docs.html')


@app.route('/downloads')
def downloads_page():
    """
    ä¸‹è¼‰é é¢
    æä¾›å„ç¨®å·¥å…·å’Œè³‡æºçš„ä¸‹è¼‰
    """
    return render_template('downloads.html')


@app.route('/donate')
def donate_page():
    """
    æè´ˆé é¢
    æ”¯æŒå°ˆæ¡ˆç™¼å±•çš„æè´ˆè³‡è¨Š
    """
    return render_template('donate.html')


@app.route('/search-results')
def search_results():
    """
    å±•ç¤ºæœå°‹çµæœé é¢ - åªé¡¯ç¤ºç”¨æˆ¶æœå°‹çµæœ
    """
    # ç¦æ­¢å¿«å–ï¼Œç¢ºä¿é¡¯ç¤ºæœ€æ–°è³‡æ–™
    resp = make_response(render_template('search_results.html'))
    resp.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, max-age=0'
    resp.headers['Pragma'] = 'no-cache'
    return resp


# è¨»å†Šå¢å¼·ç‰ˆ API Blueprint
try:
    from .enhanced_api import enhanced_api_bp
    app.register_blueprint(enhanced_api_bp)
    print("âœ… å¢å¼·ç‰ˆ API (v2) å·²è¨»å†Š")
except ImportError as e:
    print(f"âš ï¸ ç„¡æ³•è¨»å†Šå¢å¼·ç‰ˆ API: {e}")

if __name__ == '__main__':
    # å¾ç’°å¢ƒè®Šæ•¸ç²å–ä¸»æ©Ÿåœ°å€ï¼Œé è¨­ç‚º 0.0.0.0 ä»¥æ”¯æ´å¤–éƒ¨è¨ªå•
    host = os.environ.get('HOST', '0.0.0.0')
    port = int(os.environ.get('PORT', 5000))
    
    print("ğŸš€ jobseeker ç¶²é æ‡‰ç”¨å•Ÿå‹•ä¸­...")
    print(f"ğŸ“± æœ¬åœ°è¨ªå•: http://localhost:{port}")
    print(f"ğŸ“± ç¶²è·¯è¨ªå•: http://192.168.1.181:{port}")
    print(f"ğŸ“Š API æ–‡æª”: http://localhost:{port}/api/sites")
    print(f"ğŸ”§ ç›£è½åœ°å€: {host}:{port}")
    
    app.run(
        host=host,
        port=port,
        debug=app.config['DEBUG']
    )
