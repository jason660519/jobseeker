#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
jobseeker ç¶²é æ‡‰ç”¨
æä¾›ç°¡å–®æ˜“ç”¨çš„ç¶²é ç•Œé¢ï¼Œè®“ä¸€èˆ¬æ°‘çœ¾ç„¡éœ€ç¨‹å¼è¨­è¨ˆçŸ¥è­˜å³å¯ä½¿ç”¨è·ä½æœå°‹åŠŸèƒ½

åŠŸèƒ½:
1. ç¶²é ç•Œé¢ - ç°¡æ½”çš„æœå°‹è¡¨å–®
2. API ç«¯é» - RESTful API æ”¯æ´
3. å³æ™‚æœå°‹ - AJAX æ”¯æ´çš„å‹•æ…‹æœå°‹
4. çµæœå±•ç¤º - ç¾è§€çš„è·ä½åˆ—è¡¨å’Œè©³ç´°è³‡è¨Š
5. ä¸‹è¼‰åŠŸèƒ½ - CSV å’Œ JSON æ ¼å¼ä¸‹è¼‰

Author: jobseeker Team
Date: 2025-01-27
"""

import os
import sys
import json
import uuid
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
# æ”¯æ´æœ¬åœ°é–‹ç™¼å’Œ Railway éƒ¨ç½²ç’°å¢ƒ
project_root = Path(__file__).parent.parent
if project_root.name == 'web_app':  # Railway éƒ¨ç½²æ™‚çš„æƒ…æ³
    project_root = project_root.parent
sys.path.insert(0, str(project_root))

from flask import Flask, render_template, request, jsonify, send_file, flash, redirect, url_for, make_response
from flask_sqlalchemy import SQLAlchemy
from flask_login import LoginManager, login_user, logout_user, login_required, current_user, UserMixin
from werkzeug.security import generate_password_hash, check_password_hash
import time
from flask_cors import CORS
import pandas as pd

# å°å…¥ jobseeker æ ¸å¿ƒåŠŸèƒ½
try:
    from jobseeker.smart_router import smart_router
    from jobseeker.model import Site, Country
    from jobseeker.query_parser import parse_user_query_smart
    from jobseeker.intent_analyzer import analyze_user_intent, is_job_related
    from jobseeker.llm_intent_analyzer import LLMIntentAnalyzer
    from jobseeker.llm_config import LLMConfig, LLMProvider
    from jobseeker.intelligent_decision_engine import DecisionResult, ProcessingStrategy, PlatformSelectionMode
    from jobseeker.test_case_generator import TestCaseGenerator
except ImportError as e:
    print(f"è­¦å‘Š: ç„¡æ³•å°å…¥ jobseeker æ¨¡çµ„: {e}")
    print("è«‹ç¢ºä¿å·²æ­£ç¢ºå®‰è£ jobseeker å¥—ä»¶")
    sys.exit(1)

# å‰µå»º Flask æ‡‰ç”¨
app = Flask(__name__)
app.secret_key = os.environ.get('SECRET_KEY', 'jobseeker-web-app-secret-key-2025')

# å•Ÿç”¨ CORS æ”¯æ´
CORS(app)

# é…ç½®
app.config.update(
    MAX_CONTENT_LENGTH=16 * 1024 * 1024,  # 16MB æœ€å¤§ä¸Šå‚³å¤§å°
    UPLOAD_FOLDER=project_root / 'web_app' / 'downloads',
    TEMPLATES_AUTO_RELOAD=True,
    DEBUG=os.environ.get('FLASK_DEBUG', 'False').lower() == 'true',
    SQLALCHEMY_DATABASE_URI=f"sqlite:///{project_root / 'web_app' / 'db' / 'app.db'}",
    SQLALCHEMY_TRACK_MODIFICATIONS=False
)

# ç¢ºä¿ä¸‹è¼‰ç›®éŒ„å­˜åœ¨
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)
os.makedirs(project_root / 'web_app' / 'db', exist_ok=True)

# å…¨åŸŸè®Šæ•¸å„²å­˜æœå°‹çµæœ
search_results_cache = {}

# åˆå§‹åŒ–LLMæ„åœ–åˆ†æå™¨ - æ”¯æŒå¤šå€‹æä¾›å•†
try:
    if LLMProvider and LLMConfig:
        openai_api_key = os.getenv('OPENAI_API_KEY')
        anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')
        
        llm_config = None
        
        # å„ªå…ˆä½¿ç”¨Anthropicï¼ˆæ›´ç©©å®šï¼‰
        if anthropic_api_key:
            print("ğŸ¤– æ­£åœ¨åˆå§‹åŒ–LLMæ„åœ–åˆ†æå™¨ (Anthropicæ¨¡å¼)...")
            try:
                from jobseeker.llm_intent_analyzer import LLMProvider as IntentLLMProvider
                llm_intent_analyzer = LLMIntentAnalyzer(
                    provider=IntentLLMProvider.ANTHROPIC_CLAUDE,
                    api_key=anthropic_api_key,
                    fallback_to_basic=True
                )
                print("âœ… LLMæ„åœ–åˆ†æå™¨åˆå§‹åŒ–æˆåŠŸ (Anthropicæ¨¡å¼)")
                llm_config = True  # æ¨™è¨˜æˆåŠŸ
            except Exception as e:
                print(f"âš ï¸  Anthropic LLMåˆå§‹åŒ–å¤±æ•—: {e}")
                llm_config = None
        
        # å‚™ç”¨OpenAI
        if not llm_config and openai_api_key:
            print("ğŸ¤– æ­£åœ¨åˆå§‹åŒ–LLMæ„åœ–åˆ†æå™¨ (OpenAIæ¨¡å¼)...")
            try:
                from jobseeker.llm_intent_analyzer import LLMProvider as IntentLLMProvider
                llm_intent_analyzer = LLMIntentAnalyzer(
                    provider=IntentLLMProvider.OPENAI_GPT35,
                    api_key=openai_api_key,
                    fallback_to_basic=True
                )
                print("âœ… LLMæ„åœ–åˆ†æå™¨åˆå§‹åŒ–æˆåŠŸ (OpenAIæ¨¡å¼)")
                llm_config = True  # æ¨™è¨˜æˆåŠŸ
            except Exception as e:
                print(f"âš ï¸  OpenAI LLMåˆå§‹åŒ–å¤±æ•—: {e}")
                llm_config = None
        
        # å¦‚æœæ²’æœ‰å¯ç”¨çš„APIå¯†é‘°ï¼Œä½¿ç”¨æ¨¡æ“¬æ¨¡å¼
        if not llm_config:
            print("âš ï¸  æœªæª¢æ¸¬åˆ°å¯ç”¨çš„APIå¯†é‘°ï¼Œä½¿ç”¨æ¨¡æ“¬æ¨¡å¼")
            print("ğŸ’¡ æç¤º: è¨­ç½®OPENAI_API_KEYæˆ–ANTHROPIC_API_KEYç’°å¢ƒè®Šé‡ä»¥å•Ÿç”¨çœŸå¯¦LLMåˆ†æ")
            llm_intent_analyzer = LLMIntentAnalyzer()
    else:
        print("âš ï¸  LLMé…ç½®é¡æœªå¯ç”¨ï¼Œä½¿ç”¨åŸºæœ¬æ„åœ–åˆ†æå™¨")
        llm_intent_analyzer = LLMIntentAnalyzer()
except ImportError as e:
    print(f"âš ï¸  LLMæ„åœ–åˆ†æå™¨å°å…¥å¤±æ•—: {e}")
    print("ä½¿ç”¨åŸºæœ¬æ„åœ–åˆ†æå™¨")
    # ç§»é™¤æ¨¡æ“¬LLMç›¸é—œé‚è¼¯ï¼Œç•¶LLMæœå‹™ä¸å¯ç”¨æ™‚å°‡åœ¨æœç´¢æ™‚æç¤ºç”¨æˆ¶
llm_intent_analyzer = None

db = SQLAlchemy(app)
login_manager = LoginManager(app)
login_manager.login_view = 'login'


class User(db.Model, UserMixin):
    id = db.Column(db.Integer, primary_key=True)
    email = db.Column(db.String(255), unique=True, nullable=False)
    password_hash = db.Column(db.String(255), nullable=False)
    created_at = db.Column(db.DateTime, default=datetime.utcnow)

    def set_password(self, password: str):
        self.password_hash = generate_password_hash(password)

    def check_password(self, password: str) -> bool:
        return check_password_hash(self.password_hash, password)


class Favorite(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    user_id = db.Column(db.Integer, db.ForeignKey('user.id'), nullable=False)
    title = db.Column(db.String(512))
    company = db.Column(db.String(512))
    location = db.Column(db.String(512))
    site = db.Column(db.String(64))
    job_url = db.Column(db.String(1024))
    job_url_direct = db.Column(db.String(1024))
    saved_at = db.Column(db.DateTime, default=datetime.utcnow)

    user = db.relationship('User', backref=db.backref('favorites', lazy=True))


class TestRun(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    started_at = db.Column(db.DateTime, default=datetime.utcnow)
    finished_at = db.Column(db.DateTime, nullable=True)
    total = db.Column(db.Integer, default=0)
    passed = db.Column(db.Integer, default=0)
    failed = db.Column(db.Integer, default=0)
    skipped = db.Column(db.Integer, default=0)
    duration_sec = db.Column(db.Float, default=0.0)


class TestCaseResult(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    run_id = db.Column(db.Integer, db.ForeignKey('test_run.id'), nullable=False)
    name = db.Column(db.String(255), nullable=False)
    status = db.Column(db.String(16), nullable=False)  # pass/fail/skip
    duration_ms = db.Column(db.Integer, default=0)
    message = db.Column(db.Text, nullable=True)
    created_at = db.Column(db.DateTime, default=datetime.utcnow)
    run = db.relationship('TestRun', backref=db.backref('cases', lazy=True))


@login_manager.user_loader
def load_user(user_id):
    return User.query.get(int(user_id))


@login_manager.unauthorized_handler
def unauthorized():
    # API è«‹æ±‚è¿”å› 401 JSONï¼Œå…¶é¤˜å°å‘ç™»å…¥é 
    if request.path.startswith('/api/'):
        return jsonify({'success': False, 'error': 'æœªç™»å…¥'}), 401
    flash('è«‹å…ˆç™»å…¥', 'warning')
    return redirect(url_for('login', next=request.url))


def is_admin_user() -> bool:
    if not current_user.is_authenticated:
        return False
    admin_emails = os.environ.get('ADMIN_EMAILS', '')
    allow = [e.strip().lower() for e in admin_emails.split(',') if e.strip()]
    if not allow:
        # Default: no admins unless explicitly configured
        return False
    return current_user.email.lower() in allow


def admin_required(fn):
    from functools import wraps
    @wraps(fn)
    def wrapper(*args, **kwargs):
        if not current_user.is_authenticated:
            return unauthorized()
        if not is_admin_user():
            flash('éœ€è¦ç®¡ç†å“¡æ¬Šé™', 'error')
            return redirect(url_for('index'))
        return fn(*args, **kwargs)
    return wrapper

# åˆå§‹åŒ–è³‡æ–™åº«
with app.app_context():
    db.create_all()

@app.context_processor
def inject_global_flags():
    return {'is_admin': is_admin_user()}

@app.route('/')
def index():
    """
    é¦–é  - é¡¯ç¤ºæœå°‹è¡¨å–®
    """
    return render_template('index.html')


@app.route('/debug')
def debug_test():
    """
    èª¿è©¦æ¸¬è©¦é é¢
    """
    return render_template('debug_test.html')


@app.route('/search', methods=['POST'])
def search_jobs():
    """
    åŸ·è¡Œè·ä½æœå°‹ (æ”¯æ´åˆ†é )
    
    æ¥å— JSON æˆ–è¡¨å–®æ•¸æ“š
    è¿”å›æœå°‹çµæœçš„ JSON éŸ¿æ‡‰ï¼ŒåŒ…å«åˆ†é è³‡è¨Š
    """
    try:
        # ç²å–è«‹æ±‚æ•¸æ“š
        if request.is_json:
            data = request.get_json()
        else:
            data = request.form.to_dict()
        
        # æå–æœå°‹åƒæ•¸ï¼ˆå–®æ¬„è¼¸å…¥ï¼Œåœ°é»å¯ç”±è§£æå¾—å‡ºï¼‰
        user_query = data.get('query', '').strip()
        location = data.get('location', '').strip() if data.get('location') is not None else ''
        results_wanted = int(data.get('results_wanted', 20))
        hours_old = data.get('hours_old')
        selected_sites = data.get('selected_sites', '')
        
        # æ–°å¢åˆ†é åƒæ•¸
        page = int(data.get('page', 1))
        per_page = int(data.get('per_page', 20))
        
        # é©—è­‰åˆ†é åƒæ•¸
        if page < 1:
            page = 1
        if per_page < 1 or per_page > 100:
            per_page = 20
        
        # è§£æå–®æ¬„æŸ¥è©¢ï¼ˆLLM-ready è¦å‰‡å¼è§£æï¼‰
        parsed = parse_user_query_smart(user_query)

        # è‹¥æœªé¡¯å¼æä¾›åœ°é»ï¼Œä½¿ç”¨è§£æåˆ°çš„åœ°é»
        derived_location = location if location else (parsed.location or '')

        # å˜—è©¦æ¨æ–·åœ‹å®¶ï¼ˆä¾› Indeed/Glassdoor ç­‰åŸŸåé¸æ“‡ï¼‰
        derived_country = None
        try:
            if parsed.location:
                # Country.from_string æ”¯æ´è‹±æ–‡é—œéµè©ï¼Œå¦‚ 'australia','uk','usa','taiwan'
                derived_country = Country.from_string(parsed.location).value[0]
        except Exception:
            derived_country = None

        # è™•ç†é¸æ“‡çš„ç¶²ç«™
        site_name = None
        if selected_sites:
            # å¦‚æœselected_sitesæ˜¯å­—ç¬¦ä¸²ï¼Œè½‰æ›ç‚ºåˆ—è¡¨
            if isinstance(selected_sites, str):
                sites_list = [site.strip() for site in selected_sites.split(',') if site.strip()]
            else:
                # å¦‚æœå·²ç¶“æ˜¯åˆ—è¡¨ï¼Œç›´æ¥ä½¿ç”¨
                sites_list = [site.strip() for site in selected_sites if site.strip()]
            
            if len(sites_list) == 1:
                # å¦‚æœåªé¸æ“‡äº†ä¸€å€‹ç¶²ç«™ï¼Œä½¿ç”¨è©²ç¶²ç«™
                site_name = sites_list[0]
            elif len(sites_list) > 1:
                # å¦‚æœé¸æ“‡äº†å¤šå€‹ç¶²ç«™ï¼Œä½¿ç”¨æ™ºèƒ½è·¯ç”±ä½†é™åˆ¶åœ¨é¸æ“‡çš„ç¶²ç«™å…§
                print(f"å¤šå¹³å°æœå°‹: {sites_list}")
                # ä¿æŒ site_name ç‚º Noneï¼Œè®“æ™ºèƒ½è·¯ç”±è™•ç†ï¼Œä½†æœƒé€šé selected_sites é™åˆ¶
            # å¦‚æœé¸æ“‡äº†å¤šå€‹ç¶²ç«™ï¼Œä¿æŒ site_name ç‚º Noneï¼ˆæœå°‹æ‰€æœ‰ç¶²ç«™ï¼‰
        elif parsed.site_hints and len(parsed.site_hints) == 1:
            # ä½¿ç”¨æŸ¥è©¢ä¸­çš„å–®ä¸€ç«™é»æç¤º
            site_name = parsed.site_hints[0]
        
        # é©—è­‰è¼¸å…¥
        if not user_query:
            return jsonify({
                'success': False,
                'error': 'è«‹è¼¸å…¥æœå°‹é—œéµå­—'
            }), 400
        
        # æª¢æŸ¥LLMæ„åœ–åˆ†æå™¨æ˜¯å¦å¯ç”¨
        if llm_intent_analyzer is None:
            return jsonify({
                'success': False,
                'error': 'ç›®å‰LLMæœå‹™æš«æ™‚ä¸å¯ç”¨ï¼Œè«‹ä½¿ç”¨ä¸»é çš„æ™ºèƒ½è·ä½æœå°‹åŠŸèƒ½ï¼Œé€™å°‡å¹«åŠ©æ‚¨æ›´ç²¾æº–åœ°æ‰¾åˆ°ç†æƒ³å·¥ä½œã€‚',
                'suggestion': 'è«‹å˜—è©¦ä½¿ç”¨ä¸»é çš„è·ä½æœå°‹åŠŸèƒ½'
            }), 503
        
        # ä½¿ç”¨LLMæ™ºèƒ½æ„åœ–åˆ†æå™¨é€²è¡Œåˆ†æå’Œæ±ºç­–
        try:
            llm_intent_result, decision_result = llm_intent_analyzer.analyze_intent_with_decision(user_query)
            
            # æª¢æŸ¥æ˜¯å¦ç‚ºæ±‚è·ç›¸é—œæŸ¥è©¢
            if not llm_intent_result.is_job_related:
                return jsonify({
                    'success': False,
                    'error': llm_intent_result.rejection_message or 'æŠ±æ­‰ï¼Œæˆ‘æ˜¯AIåŠ©æ‰‹ï¼Œåƒ…èƒ½å”åŠ©æ‚¨è™•ç†æ±‚è·ç›¸é—œå•é¡Œï¼Œç„¡æ³•é€²è¡Œä¸€èˆ¬èŠå¤©ã€‚',
                    'intent_analysis': {
                        'intent_type': llm_intent_result.intent_type.value if llm_intent_result.intent_type else 'unclear',
                        'confidence': llm_intent_result.confidence,
                        'analysis_method': 'llm' if llm_intent_result.llm_used else 'basic'
                    },
                    'decision_analysis': {
                        'strategy': decision_result.strategy.value if decision_result else 'unknown',
                        'confidence': decision_result.confidence if decision_result else 0.0,
                        'reasoning': decision_result.reasoning if decision_result else ''
                    }
                }), 400
            
            # æ ¹æ“šæ±ºç­–çµæœèª¿æ•´æœç´¢åƒæ•¸
            if decision_result and decision_result.strategy != ProcessingStrategy.REJECT_QUERY:
                # ä½¿ç”¨æ±ºç­–å¼•æ“æ¨è–¦çš„å¹³å°
                if decision_result.recommended_platforms:
                    # å°‡å¹³å°åç¨±æ˜ å°„åˆ°Siteæšèˆ‰
                    platform_mapping = {
                        'indeed': 'indeed',
                        'linkedin': 'linkedin', 
                        'seek': 'seek',
                        '104': '104',
                        'ziprecruiter': 'zip_recruiter'
                    }
                    
                    recommended_sites = []
                    for platform in decision_result.recommended_platforms:
                        if platform in platform_mapping:
                            recommended_sites.append(platform_mapping[platform])
                    
                    if recommended_sites and not selected_sites:
                        selected_sites = recommended_sites
                
                # ä½¿ç”¨æ±ºç­–çµæœä¸­çš„æœç´¢åƒæ•¸
                if 'max_results' in decision_result.search_parameters:
                    results_wanted = min(decision_result.search_parameters['max_results'], results_wanted)
            
            # å¦‚æœLLMæˆåŠŸåˆ†æå‡ºçµæ§‹åŒ–æ„åœ–ï¼Œä½¿ç”¨LLMçš„æœç´¢æ¢ä»¶
            if llm_intent_result.llm_used and llm_intent_result.structured_intent:
                structured_intent = llm_intent_result.structured_intent
                
                # ä½¿ç”¨LLMæå–çš„æœç´¢æ¢ä»¶è¦†è“‹åŸå§‹è§£æçµæœ
                if structured_intent.job_titles:
                    # å°‡è·ä½æ¨™é¡Œçµ„åˆç‚ºæœç´¢è©
                    parsed.search_term = ' OR '.join(structured_intent.job_titles)
                
                if structured_intent.location and not location:
                    # å¦‚æœLLMè­˜åˆ¥å‡ºåœ°é»ä¸”ç”¨æˆ¶æœªæ˜ç¢ºæŒ‡å®šåœ°é»ï¼Œä½¿ç”¨LLMçš„åœ°é»
                    derived_location = structured_intent.location
                
                print(f"LLMæ„åœ–åˆ†ææˆåŠŸ: è·ä½={structured_intent.job_titles}, æŠ€èƒ½={structured_intent.skills}, åœ°é»={structured_intent.location}")
                print(f"æ±ºç­–çµæœ: ç­–ç•¥={decision_result.strategy.value if decision_result else 'unknown'}, æ¨è–¦å¹³å°={decision_result.recommended_platforms if decision_result else []}")
            else:
                print(f"ä½¿ç”¨åŸºç¤æ„åœ–åˆ†æ: {parsed.search_term}")
                
        except Exception as e:
            print(f"æ™ºèƒ½æ„åœ–åˆ†æå¤±æ•—: {e}")
            llm_intent_result = None
            decision_result = None
        
        if results_wanted < 1 or results_wanted > 100:
            return jsonify({
                'success': False,
                'error': 'æœå°‹çµæœæ•¸é‡å¿…é ˆåœ¨ 1-100 ä¹‹é–“'
            }), 400
        
        # è™•ç†æ™‚é–“é™åˆ¶
        if hours_old:
            try:
                hours_old = int(hours_old)
                if hours_old < 1:
                    hours_old = None
            except (ValueError, TypeError):
                hours_old = None
        
        # ç”Ÿæˆæœå°‹ ID
        search_id = str(uuid.uuid4())
        
        # åŸ·è¡Œæ™ºèƒ½æœå°‹
        print(f"é–‹å§‹æœå°‹: {parsed.search_term}")
        if site_name:
            print(f"æŒ‡å®šæœå°‹ç¶²ç«™: {site_name}")
        else:
            print(f"é¸æ“‡çš„ç¶²ç«™: {selected_sites if selected_sites else 'æ‰€æœ‰ç¶²ç«™'}")
            
        # ä½¿ç”¨æ–°çš„æ™ºèƒ½è·¯ç”±å™¨
        if site_name:
            # å–®å¹³å°æœå°‹
            result = smart_router.search_jobs(
                query=parsed.search_term,
                location=derived_location if derived_location else None,
                max_results=results_wanted,
                platforms=[site_name]
            )
        else:
            # å¤šå¹³å°æ™ºèƒ½æœå°‹
            result = smart_router.search_jobs(
                query=parsed.search_term,
                location=derived_location if derived_location else None,
                max_results=results_wanted
            )
        
        # è™•ç†æœå°‹çµæœ
        if result.total_jobs == 0:
            return jsonify({
                'success': True,
                'search_id': search_id,
                'total_jobs': 0,
                'message': 'æœªæ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„è·ä½ï¼Œè«‹å˜—è©¦èª¿æ•´æœå°‹æ¢ä»¶',
                'jobs': [],
                'routing_info': {
                    'successful_platforms': result.successful_platforms,
                    'failed_platforms': result.failed_platforms,
                    'execution_time': result.total_execution_time
                },
                'pagination': {
                    'page': page,
                    'per_page': per_page,
                    'total': 0,
                    'total_pages': 0,
                    'has_next': False,
                    'has_prev': False
                }
            })
        
        # è½‰æ›è·ä½æ•¸æ“šç‚ºå­—å…¸æ ¼å¼
        jobs_list = []
        if result.jobs:
            for job in result.jobs:
                job_dict = {
                    'title': str(job.title or ''),
                    'company': str(job.company_name or ''),
                    'location': str(job.location.city if job.location else ''),
                    'description': str(job.description or '')[:500] + ('...' if len(str(job.description or '')) > 500 else ''),
                    'salary_min': None,  # æ–°æ¶æ§‹ä¸­éœ€è¦å¾compensationè§£æ
                    'salary_max': None,  # æ–°æ¶æ§‹ä¸­éœ€è¦å¾compensationè§£æ
                    'salary_currency': '',  # æ–°æ¶æ§‹ä¸­éœ€è¦å¾compensationè§£æ
                    'date_posted': str(job.date_posted or ''),
                    'job_url': str(job.job_url or ''),
                    'job_url_direct': str(job.job_url_direct or ''),
                    'site': str(job.site or ''),
                    'job_type': str(job.job_type or ''),
                    'is_remote': bool(job.is_remote or False)
                }
                jobs_list.append(job_dict)

        # å¯é¸ï¼šåš´æ ¼åœ‹å®¶éæ¿¾ï¼ˆé¿å…ã€Œæ¾³æ´²ã€å‡ºç¾å…¶ä»–åœ‹å®¶ï¼‰
        strict_filter = os.environ.get('STRICT_COUNTRY_FILTER', 'false').lower() == 'true'
        if strict_filter and (derived_country or derived_location):
            country_tokens = set()
            if derived_country:
                country_tokens.add(derived_country.lower())
            # å¸¸è¦‹åŒç¾©è©
            synonyms = {
                'australia': ['australia', 'æ¾³æ´²', 'æ¾³å¤§åˆ©äº', 'æ¾³å¤§åˆ©äºš'],
                'taiwan': ['taiwan', 'å°ç£', 'è‡ºç£'],
                'hong kong': ['hong kong', 'é¦™æ¸¯'],
                'singapore': ['singapore', 'æ–°åŠ å¡'],
                'japan': ['japan', 'æ—¥æœ¬'],
                'usa': ['usa', 'united states', 'america', 'ç¾åœ‹', 'ç¾å›½'],
                'uk': ['uk', 'united kingdom', 'england', 'è‹±åœ‹', 'è‹±å›½'],
                'new zealand': ['new zealand', 'ç´è¥¿è˜­', 'æ–°è¥¿è˜­'],
                'canada': ['canada', 'åŠ æ‹¿å¤§']
            }
            if derived_country and derived_country.lower() in synonyms:
                country_tokens.update(synonyms[derived_country.lower()])
            # ç²—ç•¥éæ¿¾
            jobs_list = [j for j in jobs_list if any(tok in (j.get('location','').lower()) for tok in country_tokens)]

        # å¿«å–æœå°‹çµæœ
        search_results_cache[search_id] = {
            'result': result,
            'timestamp': datetime.now(),
            'query': parsed.search_term,
            'location': derived_location
        }
        
        # ä¼ºæœå™¨ç«¯åˆ†é åˆ‡ç‰‡
        total = len(jobs_list)
        total_pages = (total + per_page - 1) // per_page if per_page else 1
        start = (page - 1) * per_page
        end = start + per_page
        page_jobs = jobs_list[start:end]
        
        # è¿”å›æˆåŠŸéŸ¿æ‡‰ï¼ˆå«åˆ†é è³‡è¨Šï¼‰
        return jsonify({
            'success': True,
            'search_id': search_id,
            'total_jobs': total,
            'jobs': page_jobs,
            'routing_info': {
                'successful_platforms': result.successful_platforms,
                'failed_platforms': result.failed_platforms,
                'execution_time': result.total_execution_time,
                'search_metadata': result.search_metadata
            },
            'search_params': {
                'query': user_query,
                'location': location,
                'results_wanted': results_wanted,
                'hours_old': hours_old
            },
            'pagination': {
                'page': page,
                'per_page': per_page,
                'total': total,
                'total_pages': total_pages,
                'has_next': page < total_pages,
                'has_prev': page > 1
            }
        })
        
    except Exception as e:
        print(f"æœå°‹éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        
        return jsonify({
            'success': False,
            'error': f'æœå°‹éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}'
        }), 500


@app.route('/download/<search_id>/<format>')
def download_results(search_id, format):
    """
    ä¸‹è¼‰æœå°‹çµæœ
    
    Args:
        search_id: æœå°‹ ID
        format: ä¸‹è¼‰æ ¼å¼ (csv, json)
    """
    try:
        # æª¢æŸ¥æœå°‹çµæœæ˜¯å¦å­˜åœ¨
        if search_id not in search_results_cache:
            flash('æœå°‹çµæœä¸å­˜åœ¨æˆ–å·²éæœŸ', 'error')
            return redirect(url_for('index'))
        
        cached_result = search_results_cache[search_id]
        result = cached_result['result']
        
        if result.combined_jobs_data is None or result.total_jobs == 0:
            flash('æ²’æœ‰å¯ä¸‹è¼‰çš„æœå°‹çµæœ', 'warning')
            return redirect(url_for('index'))
        
        # ç”Ÿæˆæª”æ¡ˆåç¨±
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        query_safe = ''.join(c for c in cached_result['query'][:20] if c.isalnum() or c in (' ', '-', '_')).strip()
        
        if format.lower() == 'csv':
            filename = f"jobseeker_{query_safe}_{timestamp}.csv"
            filepath = app.config['UPLOAD_FOLDER'] / filename
            
            # è½‰æ›ç‚ºæ¨™æº–æ ¼å¼
            standardized_data = convert_to_standard_format(result.combined_jobs_data)
            
            # å„²å­˜ CSV æª”æ¡ˆ
            standardized_data.to_csv(filepath, index=False, encoding='utf-8-sig')
            
            return send_file(
                filepath,
                as_attachment=True,
                download_name=filename,
                mimetype='text/csv'
            )
            
        elif format.lower() == 'json':
            filename = f"jobseeker_{query_safe}_{timestamp}.json"
            filepath = app.config['UPLOAD_FOLDER'] / filename
            
            # è½‰æ›ç‚º JSON æ ¼å¼
            jobs_data = result.combined_jobs_data.fillna('').to_dict('records')
            
            export_data = {
                'search_info': {
                    'query': cached_result['query'],
                    'location': cached_result['location'],
                    'timestamp': cached_result['timestamp'].isoformat(),
                    'total_jobs': result.total_jobs
                },
                'routing_info': {
                    'successful_agents': [agent.value for agent in result.successful_agents],
                    'failed_agents': [agent.value for agent in result.failed_agents],
                    'confidence_score': result.routing_decision.confidence_score,
                    'execution_time': result.total_execution_time
                },
                'jobs': jobs_data
            }
            
            # å„²å­˜ JSON æª”æ¡ˆ
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, ensure_ascii=False, indent=2, default=str)
            
            return send_file(
                filepath,
                as_attachment=True,
                download_name=filename,
                mimetype='application/json'
            )
        
        else:
            flash('ä¸æ”¯æ´çš„ä¸‹è¼‰æ ¼å¼', 'error')
            return redirect(url_for('index'))
            
    except Exception as e:
        print(f"ä¸‹è¼‰éŒ¯èª¤: {e}")
        flash(f'ä¸‹è¼‰å¤±æ•—: {str(e)}', 'error')
        return redirect(url_for('index'))


@app.route('/demo')
def demo_results():
    """
    å±•ç¤ºæ¸¬è©¦çµæœé é¢
    """
    # ç¦æ­¢å¿«å–ï¼Œç¢ºä¿é¡¯ç¤ºæœ€æ–°è³‡æ–™
    resp = make_response(render_template('demo_results.html'))
    resp.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, max-age=0'
    resp.headers['Pragma'] = 'no-cache'
    return resp


# ============ Auth Pages ============

@app.route('/login', methods=['GET', 'POST'])
def login():
    if request.method == 'POST':
        email = request.form.get('email', '').strip().lower()
        password = request.form.get('password', '')
        user = User.query.filter_by(email=email).first()
        if user and user.check_password(password):
            login_user(user)
            flash('ç™»å…¥æˆåŠŸ', 'success')
            next_url = request.args.get('next') or url_for('index')
            return redirect(next_url)
        flash('å¸³è™Ÿæˆ–å¯†ç¢¼éŒ¯èª¤', 'error')
    return render_template('login.html')


@app.route('/register', methods=['GET', 'POST'])
def register():
    if request.method == 'POST':
        email = request.form.get('email', '').strip().lower()
        password = request.form.get('password', '')
        if not email or not password:
            flash('è«‹è¼¸å…¥å®Œæ•´è³‡æ–™', 'error')
            return render_template('register.html')
        if User.query.filter_by(email=email).first():
            flash('æ­¤ Email å·²è¢«è¨»å†Š', 'error')
            return render_template('register.html')
        user = User(email=email)
        user.set_password(password)
        db.session.add(user)
        db.session.commit()
        login_user(user)
        flash('è¨»å†ŠæˆåŠŸï¼Œå·²è‡ªå‹•ç™»å…¥', 'success')
        return redirect(url_for('index'))
    return render_template('register.html')


@app.route('/logout')
@login_required
def logout():
    logout_user()
    flash('æ‚¨å·²ç™»å‡º', 'info')
    return redirect(url_for('index'))


@app.route('/favorites')
@login_required
def favorites_page():
    favs = Favorite.query.filter_by(user_id=current_user.id).order_by(Favorite.saved_at.desc()).all()
    return render_template('favorites.html', favorites=favs)


# ============ Admin: Synthetic Test Runner ============

def run_synthetic_tests() -> int:
    """Run a suite of lightweight synthetic tests via Flask test_client.
    Returns run_id.
    """
    run = TestRun()
    db.session.add(run)
    db.session.commit()

    def record(name: str, status: str, start_t: float, message: str = ""):
        case = TestCaseResult(
            run_id=run.id,
            name=name,
            status=status,
            duration_ms=int((time.time() - start_t) * 1000),
            message=message[:2000]
        )
        db.session.add(case)
        db.session.commit()

    total = passed = failed = skipped = 0

    with app.test_client() as client:
        # Health
        total += 1
        t0 = time.time()
        try:
            r = client.get('/health')
            if r.status_code == 200 and r.json.get('status') == 'healthy':
                passed += 1; record('health', 'pass', t0)
            else:
                failed += 1; record('health', 'fail', t0, f"status={r.status_code}")
        except Exception as e:
            failed += 1; record('health', 'fail', t0, str(e))

        # Homepage
        total += 1
        t0 = time.time()
        try:
            r = client.get('/')
            if r.status_code == 200 and 'æ™ºèƒ½è·ä½æœå°‹'.encode('utf-8') in r.data:
                passed += 1; record('homepage', 'pass', t0)
            else:
                failed += 1; record('homepage', 'fail', t0, f"status={r.status_code}")
        except Exception as e:
            failed += 1; record('homepage', 'fail', t0, str(e))

        # Search (may return zero jobs; still pass if success flag)
        total += 1
        t0 = time.time()
        try:
            payload = {"query": "å°åŒ— AI å·¥ç¨‹å¸«", "results_wanted": 5, "hours_old": 168, "page": 1, "per_page": 5}
            r = client.post('/search', json=payload)
            if r.status_code == 200 and r.json.get('success'):
                passed += 1; record('search_basic', 'pass', t0, f"jobs={len(r.json.get('jobs', []))}")
                search_id = r.json.get('search_id')
                # Download JSON if jobs present
                if search_id and r.json.get('total_jobs', 0) > 0:
                    total += 1
                    t1 = time.time()
                    r2 = client.get(f"/download/{search_id}/json")
                    if r2.status_code == 200 and r2.mimetype == 'application/json':
                        passed += 1; record('download_json', 'pass', t1)
                    else:
                        failed += 1; record('download_json', 'fail', t1, f"status={r2.status_code}")
                else:
                    # Skip download if no results
                    total += 1; skipped += 1; record('download_json', 'skip', t0, 'no results')
            else:
                failed += 1; record('search_basic', 'fail', t0, f"status={r.status_code}")
        except Exception as e:
            failed += 1; record('search_basic', 'fail', t0, str(e))

        # Auth flow + favorites
        total += 1
        t0 = time.time()
        try:
            email = f"test+{int(time.time())}@example.com"
            r = client.post('/register', data={'email': email, 'password': 'P@ssw0rd!'}, follow_redirects=True)
            if r.status_code == 200:
                fav_payload = {
                    'title': 'Synthetic Tester', 'company': 'JobSeeker', 'location': 'å°åŒ—',
                    'site': 'linkedin', 'job_url': 'https://example.com', 'job_url_direct': ''
                }
                r2 = client.post('/api/favorites', json=fav_payload)
                if r2.status_code == 200 and r2.json.get('success'):
                    passed += 1; record('auth_favorite', 'pass', t0)
                else:
                    failed += 1; record('auth_favorite', 'fail', t0, f"status={r2.status_code}")
            else:
                failed += 1; record('auth_favorite', 'fail', t0, f"status={r.status_code}")
        except Exception as e:
            failed += 1; record('auth_favorite', 'fail', t0, str(e))

    run.total = total
    run.passed = passed
    run.failed = failed
    run.skipped = skipped
    run.finished_at = datetime.utcnow()
    run.duration_sec = (run.finished_at - run.started_at).total_seconds()
    db.session.commit()
    return run.id


@app.route('/admin/tests')
@login_required
@admin_required
def admin_tests_page():
    runs = TestRun.query.order_by(TestRun.id.desc()).limit(10).all()
    return render_template('admin_tests.html', runs=runs)


@app.route('/api/admin/run-tests', methods=['POST'])
@login_required
@admin_required
def api_admin_run_tests():
    run_id = run_synthetic_tests()
    return jsonify({'success': True, 'run_id': run_id})
@app.route('/api/favorites', methods=['GET', 'POST'])
@login_required
def favorites_api():
    if request.method == 'POST':
        data = request.get_json(force=True)
        fav = Favorite(
            user_id=current_user.id,
            title=data.get('title'),
            company=data.get('company'),
            location=data.get('location'),
            site=data.get('site'),
            job_url=data.get('job_url'),
            job_url_direct=data.get('job_url_direct')
        )
        db.session.add(fav)
        db.session.commit()
        return jsonify({'success': True, 'id': fav.id})
    # GET
    favs = Favorite.query.filter_by(user_id=current_user.id).order_by(Favorite.saved_at.desc()).all()
    return jsonify({'success': True, 'favorites': [
        {
            'id': f.id,
            'title': f.title,
            'company': f.company,
            'location': f.location,
            'site': f.site,
            'job_url': f.job_url,
            'job_url_direct': f.job_url_direct,
            'saved_at': f.saved_at.isoformat()
        } for f in favs
    ]})


@app.route('/api/favorites/<int:fav_id>', methods=['DELETE'])
@login_required
def delete_favorite(fav_id):
    fav = Favorite.query.filter_by(id=fav_id, user_id=current_user.id).first()
    if not fav:
        return jsonify({'success': False, 'error': 'æ‰¾ä¸åˆ°æ”¶è—'}), 404
    db.session.delete(fav)
    db.session.commit()
    return jsonify({'success': True})


@app.route('/api/sites')
def get_supported_sites():
    """
    ç²å–æ”¯æ´çš„æ±‚è·ç¶²ç«™åˆ—è¡¨
    """
    try:
        sites = [{
            'value': site.value,
            'name': site.value.title(),
            'description': get_site_description(site)
        } for site in Site]
        
        return jsonify({
            'success': True,
            'sites': sites
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/search/<search_id>')
def get_search_result(search_id: str):
    """
    å–å¾—æŒ‡å®šæœå°‹ ID çš„çµæœï¼ˆç”¨æ–¼ Demo/çµæœé å‹•æ…‹é¡¯ç¤ºï¼‰
    """
    try:
        if search_id not in search_results_cache:
            return jsonify({'success': False, 'error': 'æœå°‹çµæœä¸å­˜åœ¨æˆ–å·²éæœŸ'}), 404

        cached = search_results_cache[search_id]
        result = cached['result']

        # å¯é¸åˆ†é åƒæ•¸
        try:
            page = int(request.args.get('page', 0))
        except Exception:
            page = 0
        try:
            per_page = int(request.args.get('per_page', 0))
        except Exception:
            per_page = 0

        jobs_list = []
        if result.combined_jobs_data is not None:
            df_clean = result.combined_jobs_data.fillna('')
            for _, row in df_clean.iterrows():
                jobs_list.append({
                    'title': str(row.get('title', '')),
                    'company': str(row.get('company', '')),
                    'location': str(row.get('location', '')),
                    'description': str(row.get('description', ''))[:500] + ('...' if len(str(row.get('description', ''))) > 500 else ''),
                    'salary_min': float(row['salary_min']) if pd.notna(row.get('salary_min')) else None,
                    'salary_max': float(row['salary_max']) if pd.notna(row.get('salary_max')) else None,
                    'salary_currency': str(row.get('salary_currency', '')),
                    'date_posted': str(row.get('date_posted', '')),
                    'job_url': str(row.get('job_url', '')),
                    'job_url_direct': str(row.get('job_url_direct', '')),
                    'site': str(row.get('site', '')),
                    'job_type': str(row.get('job_type', '')),
                    'is_remote': bool(row.get('is_remote', False))
                })

        # åˆ†é åˆ‡ç‰‡ï¼ˆè‹¥æä¾› page/per_pageï¼‰
        total = len(jobs_list)
        if page and per_page:
            if page < 1:
                page = 1
            if per_page < 1:
                per_page = 10
            total_pages = (total + per_page - 1) // per_page
            start = (page - 1) * per_page
            end = start + per_page
            page_jobs = jobs_list[start:end]
        else:
            total_pages = 1
            page_jobs = jobs_list
            page = 1
            per_page = total or 1

        return jsonify({
            'success': True,
            'search_id': search_id,
            'timestamp': cached['timestamp'].isoformat(),
            'query': cached.get('query'),
            'location': cached.get('location'),
            'total_jobs': result.total_jobs,
            'routing_info': {
                'successful_agents': [agent.value for agent in result.successful_agents],
                'failed_agents': [agent.value for agent in result.failed_agents],
                'confidence_score': result.routing_decision.confidence_score,
                'execution_time': result.total_execution_time
            },
            'jobs': page_jobs,
            'pagination': {
                'page': page,
                'per_page': per_page,
                'total': total,
                'total_pages': total_pages,
                'has_next': page < total_pages,
                'has_prev': page > 1
            }
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/search/latest')
def get_latest_search_result():
    """
    å–å¾—æœ€è¿‘ä¸€æ¬¡æœå°‹çµæœæ‘˜è¦
    """
    try:
        if not search_results_cache:
            return jsonify({'success': False, 'error': 'å°šç„¡æœå°‹è¨˜éŒ„'}), 404

        # æ‰¾å‡ºæœ€æ–°çš„æœå°‹
        latest_id = max(search_results_cache.items(), key=lambda kv: kv[1]['timestamp'])[0]
        return get_search_result(latest_id)
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/countries')
def get_supported_countries():
    """
    ç²å–æ”¯æ´çš„åœ‹å®¶åˆ—è¡¨
    """
    try:
        countries = [{
            'value': country.value[0],  # åœ‹å®¶åç¨±
            'code': country.value[1],   # åœ‹å®¶ä»£ç¢¼
            'name': country.name
        } for country in Country]
        
        return jsonify({
            'success': True,
            'countries': countries
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/health')
def health_check():
    """
    å¥åº·æª¢æŸ¥ç«¯é»
    """
    return jsonify({
        'status': 'healthy',
        'timestamp': datetime.now().isoformat(),
        'version': '1.0.0'
    })


def convert_to_standard_format(df: pd.DataFrame) -> pd.DataFrame:
    """
    è½‰æ›è·ä½æ•¸æ“šç‚ºæ¨™æº–æ ¼å¼
    æŒ‰ç…§ç”¨æˆ¶æŒ‡å®šçš„æ ¼å¼ï¼šSITE, TITLE, COMPANY, CITY, STATE, JOB_TYPE, INTERVAL, MIN_AMOUNT, MAX_AMOUNT, JOB_URL, DESCRIPTION
    
    Args:
        df: åŸå§‹è·ä½æ•¸æ“š DataFrame
        
    Returns:
        æ¨™æº–åŒ–çš„ DataFrame
    """
    # å‰µå»ºæ¨™æº–åŒ–çš„ DataFrame
    standardized_df = pd.DataFrame()
    
    # æŒ‰ç…§æ¨™æº–æ ¼å¼æ˜ å°„æ¬„ä½
    standardized_df['SITE'] = df.get('site', '').fillna('')
    standardized_df['TITLE'] = df.get('title', '').fillna('')
    standardized_df['COMPANY'] = df.get('company', '').fillna('')
    
    # è™•ç†åœ°é»è³‡è¨Š - åˆ†é›¢åŸå¸‚å’Œå·/çœ
    location = df.get('location', '').fillna('')
    standardized_df['CITY'] = location.apply(extract_city)
    standardized_df['STATE'] = location.apply(extract_state)
    
    standardized_df['JOB_TYPE'] = df.get('job_type', '').fillna('')
    standardized_df['INTERVAL'] = df.get('interval', '').fillna('')
    standardized_df['MIN_AMOUNT'] = df.get('min_amount', '').fillna('')
    standardized_df['MAX_AMOUNT'] = df.get('max_amount', '').fillna('')
    standardized_df['JOB_URL'] = df.get('job_url', '').fillna('')
    standardized_df['DESCRIPTION'] = df.get('description', '').fillna('')
    
    return standardized_df


def extract_city(location_str):
    """
    å¾åœ°é»å­—ä¸²ä¸­æå–åŸå¸‚åç¨±
    
    Args:
        location_str: åœ°é»å­—ä¸²
        
    Returns:
        åŸå¸‚åç¨±
    """
    if pd.isna(location_str) or location_str == '':
        return ''
    
    # åˆ†å‰²åœ°é»å­—ä¸²ï¼Œé€šå¸¸æ ¼å¼ç‚º "City, State" æˆ– "City"
    parts = str(location_str).split(',')
    return parts[0].strip() if parts else ''


def extract_state(location_str):
    """
    å¾åœ°é»å­—ä¸²ä¸­æå–å·/çœåç¨±
    
    Args:
        location_str: åœ°é»å­—ä¸²
        
    Returns:
        å·/çœåç¨±
    """
    if pd.isna(location_str) or location_str == '':
        return ''
    
    # åˆ†å‰²åœ°é»å­—ä¸²ï¼Œé€šå¸¸æ ¼å¼ç‚º "City, State" æˆ– "City"
    parts = str(location_str).split(',')
    return parts[1].strip() if len(parts) > 1 else ''


def get_site_description(site: Site) -> str:
    """
    ç²å–æ±‚è·ç¶²ç«™æè¿°
    
    Args:
        site: Site æšèˆ‰å€¼
        
    Returns:
        ç¶²ç«™æè¿°å­—ä¸²
    """
    descriptions = {
        'indeed': 'å…¨çƒæœ€å¤§çš„æ±‚è·ç¶²ç«™ï¼Œæ¶µè“‹å„è¡Œå„æ¥­',
        'linkedin': 'å°ˆæ¥­äººè„ˆç¶²ç«™ï¼Œé©åˆç™½é ˜å’Œç®¡ç†è·ä½',
        'glassdoor': 'æä¾›å…¬å¸è©•åƒ¹å’Œè–ªè³‡è³‡è¨Š',
        'seek': 'æ¾³æ´²å’Œç´è¥¿è˜­æœ€å¤§çš„æ±‚è·ç¶²ç«™',
        'zip_recruiter': 'ç¾åœ‹çŸ¥åæ±‚è·ç¶²ç«™ï¼ŒAI æ™ºèƒ½åŒ¹é…',
        'google': 'Google è·ä½æœå°‹ï¼Œæ•´åˆå¤šå€‹å¹³å°',
        'naukri': 'å°åº¦æœ€å¤§çš„æ±‚è·ç¶²ç«™',
        'bayt': 'ä¸­æ±åœ°å€é ˜å…ˆçš„æ±‚è·å¹³å°',
        'bdjobs': 'å­ŸåŠ æ‹‰åœ‹æœ¬åœ°æ±‚è·ç¶²ç«™',
        '104': 'å°ç£ 104 äººåŠ›éŠ€è¡Œï¼Œæœ¬åœ°åœ¨åœ°å¹³å°',
        '1111': 'å°ç£ 1111 äººåŠ›éŠ€è¡Œï¼Œæœ¬åœ°åœ¨åœ°å¹³å°'
    }
    
    return descriptions.get(site.value, f'{site.value.title()} æ±‚è·ç¶²ç«™')


@app.route('/docs')
def docs_page():
    """
    æ–‡æª”é é¢
    é¡¯ç¤º jobseeker çš„ä½¿ç”¨æ–‡æª”å’Œ API èªªæ˜
    """
    return render_template('docs.html')


@app.route('/downloads')
def downloads_page():
    """
    ä¸‹è¼‰é é¢
    æä¾›å„ç¨®å·¥å…·å’Œè³‡æºçš„ä¸‹è¼‰
    """
    return render_template('downloads.html')


@app.route('/donate')
def donate_page():
    """
    æè´ˆé é¢
    æ”¯æŒå°ˆæ¡ˆç™¼å±•çš„æè´ˆè³‡è¨Š
    """
    return render_template('donate.html')


@app.route('/search-results')
def search_results():
    """
    å±•ç¤ºæœå°‹çµæœé é¢ - åªé¡¯ç¤ºç”¨æˆ¶æœå°‹çµæœ
    """
    # ç¦æ­¢å¿«å–ï¼Œç¢ºä¿é¡¯ç¤ºæœ€æ–°è³‡æ–™
    resp = make_response(render_template('search_results.html'))
    resp.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, max-age=0'
    resp.headers['Pragma'] = 'no-cache'
    return resp


@app.route('/test-case-generator')
def test_case_generator():
    """
    æ¸¬è©¦æ¡ˆä¾‹ç”Ÿæˆå™¨é é¢
    æä¾›å¿«é€Ÿç”Ÿæˆå¤šæ¨£åŒ–LLMæ¸¬è©¦æ¡ˆä¾‹çš„åŠŸèƒ½
    """
    return render_template('test_case_generator.html')


@app.route('/api/generate-test-cases', methods=['POST'])
def api_generate_test_cases():
    """
    APIç«¯é»ï¼šç”Ÿæˆæ¸¬è©¦æ¡ˆä¾‹
    """
    try:
        data = request.get_json()
        
        # ç²å–åƒæ•¸ - æ”¯æ´è¤‡é¸æ¨¡å¼
        generation_modes = data.get('generation_modes', ['balanced'])  # æ”¹ç‚ºè¤‡æ•¸å½¢å¼
        if isinstance(generation_modes, str):  # å‘å¾Œå…¼å®¹å–®é¸
            generation_modes = [generation_modes]
        
        num_cases = data.get('num_cases', 50)
        languages = data.get('languages', ['zh-TW'])
        complexity_distribution = data.get('complexity_distribution', {
            'simple': 0.3,
            'medium': 0.5,
            'complex': 0.2
        })
        
        # å‰µå»ºæ¸¬è©¦æ¡ˆä¾‹ç”Ÿæˆå™¨
        from jobseeker.test_case_generator import TestCaseGenerator, GenerationConfig
        generator = TestCaseGenerator()
        
        # æ ¹æ“šé¸ä¸­çš„æ¨¡å¼å‰µå»ºé…ç½®
        config = GenerationConfig(
            total_cases=num_cases,
            complexity_distribution=complexity_distribution
        )
        
        # æ ¹æ“šé¸ä¸­çš„æ¨¡å¼èª¿æ•´é¡åˆ¥æ¬Šé‡
        category_weights = {}
        
        if 'balanced' in generation_modes:
            category_weights.update({
                "job_search": 0.25,
                "skill_query": 0.15,
                "location_based": 0.15,
                "salary_inquiry": 0.1,
                "career_advice": 0.1,
                "company_info": 0.1,
                "edge_cases": 0.05,
                "multilingual": 0.05,
                "ambiguous": 0.03,
                "complex_query": 0.02
            })
        
        if 'job_focused' in generation_modes:
            category_weights.update({
                "job_search": category_weights.get("job_search", 0) + 0.4,
                "skill_query": category_weights.get("skill_query", 0) + 0.2,
                "location_based": category_weights.get("location_based", 0) + 0.15,
                "salary_inquiry": category_weights.get("salary_inquiry", 0) + 0.15,
                "career_advice": category_weights.get("career_advice", 0) + 0.1
            })
        
        if 'skill_focused' in generation_modes:
            category_weights.update({
                "skill_query": category_weights.get("skill_query", 0) + 0.4,
                "job_search": category_weights.get("job_search", 0) + 0.3,
                "career_advice": category_weights.get("career_advice", 0) + 0.2,
                "company_info": category_weights.get("company_info", 0) + 0.1
            })
        
        if 'multilingual' in generation_modes:
            category_weights.update({
                "multilingual": category_weights.get("multilingual", 0) + 0.4,
                "job_search": category_weights.get("job_search", 0) + 0.3,
                "skill_query": category_weights.get("skill_query", 0) + 0.3
            })
        
        if 'edge_cases' in generation_modes:
            category_weights.update({
                "edge_cases": category_weights.get("edge_cases", 0) + 0.4,
                "ambiguous": category_weights.get("ambiguous", 0) + 0.3,
                "complex_query": category_weights.get("complex_query", 0) + 0.3
            })
        
        # æ­£è¦åŒ–æ¬Šé‡
        total_weight = sum(category_weights.values())
        if total_weight > 0:
            category_weights = {k: v / total_weight for k, v in category_weights.items()}
            config.category_weights = category_weights
        
        # è¨­ç½®èªè¨€åˆ†ä½ˆ
        if languages:
            language_dist = {}
            weight_per_lang = 1.0 / len(languages)
            for lang in languages:
                language_dist[lang.lower().replace('-', '_')] = weight_per_lang
            config.language_distribution = language_dist
        
        # ç”Ÿæˆæ¸¬è©¦æ¡ˆä¾‹
        test_cases = generator.generate_test_cases(config)
        
        # è½‰æ›ç‚ºå¯åºåˆ—åŒ–çš„æ ¼å¼
        cases_data = []
        for case in test_cases:
            cases_data.append({
                'id': case.id,
                'query': case.query,
                'category': case.category,
                'complexity': case.complexity,
                'language': case.language,
                'expected_intent': case.expected_intent,
                'expected_entities': case.expected_entities,
                'metadata': case.metadata
            })
        
        # ç”Ÿæˆçµ±è¨ˆè³‡è¨Š
        stats = {
            'total_generated': len(test_cases),
            'category_distribution': {},
            'complexity_distribution': {},
            'language_distribution': {}
        }
        
        # è¨ˆç®—åˆ†ä½ˆçµ±è¨ˆ
        for case in test_cases:
            # é¡åˆ¥åˆ†ä½ˆ
            category = case.category
            stats['category_distribution'][category] = stats['category_distribution'].get(category, 0) + 1
            
            # è¤‡é›œåº¦åˆ†ä½ˆ
            complexity = case.complexity
            stats['complexity_distribution'][complexity] = stats['complexity_distribution'].get(complexity, 0) + 1
            
            # èªè¨€åˆ†ä½ˆ
            language = case.language
            stats['language_distribution'][language] = stats['language_distribution'].get(language, 0) + 1
        
        return jsonify({
            'success': True,
            'test_cases': cases_data,
            'statistics': stats
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/export-test-cases', methods=['POST'])
def api_export_test_cases():
    """
    APIç«¯é»ï¼šå°å‡ºæ¸¬è©¦æ¡ˆä¾‹
    """
    try:
        data = request.get_json()
        test_cases_data = data.get('test_cases', [])
        export_format = data.get('format', 'json')
        
        if not test_cases_data:
            return jsonify({
                'success': False,
                'error': 'æ²’æœ‰æ¸¬è©¦æ¡ˆä¾‹å¯å°å‡º'
            }), 400
        
        # å‰µå»ºè‡¨æ™‚æ–‡ä»¶
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        if export_format == 'json':
            filename = f'test_cases_{timestamp}.json'
            filepath = app.config['UPLOAD_FOLDER'] / filename
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(test_cases_data, f, ensure_ascii=False, indent=2)
                
        elif export_format == 'csv':
            filename = f'test_cases_{timestamp}.csv'
            filepath = app.config['UPLOAD_FOLDER'] / filename
            
            # è½‰æ›ç‚ºDataFrameä¸¦å°å‡ºCSV
            df_data = []
            for case in test_cases_data:
                df_data.append({
                    'ID': case['id'],
                    'æŸ¥è©¢': case['query'],
                    'é¡åˆ¥': case['category'],
                    'è¤‡é›œåº¦': case['complexity'],
                    'èªè¨€': case['language'],
                    'é æœŸæ„åœ–': case['expected_intent'],
                    'é æœŸå¯¦é«”': json.dumps(case['expected_entities'], ensure_ascii=False),
                    'å…ƒæ•¸æ“š': json.dumps(case['metadata'], ensure_ascii=False)
                })
            
            df = pd.DataFrame(df_data)
            df.to_csv(filepath, index=False, encoding='utf-8-sig')
        
        else:
            return jsonify({
                'success': False,
                'error': 'ä¸æ”¯æ´çš„å°å‡ºæ ¼å¼'
            }), 400
        
        return jsonify({
            'success': True,
            'download_url': f'/download-test-cases/{filename}'
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/download-test-cases/<filename>')
def download_test_cases(filename):
    """
    ä¸‹è¼‰æ¸¬è©¦æ¡ˆä¾‹æ–‡ä»¶
    """
    try:
        filepath = app.config['UPLOAD_FOLDER'] / filename
        if not filepath.exists():
            return jsonify({'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}), 404
            
        return send_file(
            filepath,
            as_attachment=True,
            download_name=filename
        )
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/export-pure-english', methods=['POST'])
def api_export_pure_english():
    """
    APIç«¯é»ï¼šä½¿ç”¨LLMç”Ÿæˆç´”è‹±æ–‡æ¸¬è©¦æ¡ˆä¾‹
    """
    try:
        from jobseeker.llm_intent_analyzer import LLMIntentAnalyzer, LLMProvider
        from etl_pipeline.etl_manager import ETLManager
        from etl_pipeline.etl_config import ETLConfig
        import os
        
        data = request.get_json()
        test_cases_data = data.get('test_cases', [])
        
        if not test_cases_data:
            return jsonify({
                'success': False,
                'error': 'æ²’æœ‰æ¸¬è©¦æ¡ˆä¾‹å¯å°å‡º'
            }), 400
        
        # åˆå§‹åŒ–LLMåˆ†æå™¨
        openai_key = os.getenv('OPENAI_API_KEY')
        anthropic_key = os.getenv('ANTHROPIC_API_KEY')
        
        if openai_key:
            analyzer = LLMIntentAnalyzer(provider=LLMProvider.OPENAI_GPT35, api_key=openai_key)
        elif anthropic_key:
            analyzer = LLMIntentAnalyzer(provider=LLMProvider.ANTHROPIC_CLAUDE, api_key=anthropic_key)
        else:
            return jsonify({
                'success': False,
                'error': 'éœ€è¦è¨­ç½® OPENAI_API_KEY æˆ– ANTHROPIC_API_KEY ç’°å¢ƒè®Šé‡'
            }), 400
        
        # ä½¿ç”¨LLMç”Ÿæˆç´”è‹±æ–‡æ¸¬è©¦æ¡ˆä¾‹
        english_test_cases = []
        
        for case in test_cases_data:
            try:
                # æ§‹å»ºLLMæç¤ºè©
                prompt = f"""
Please convert the following job search query to pure English while maintaining the same intent and meaning:

Original Query: {case['query']}
Category: {case['category']}
Complexity: {case['complexity']}

Requirements:
1. Generate a natural, fluent English query that expresses the same job search intent
2. Maintain the same level of complexity
3. Use professional job search terminology
4. Ensure the query sounds like something a real job seeker would ask
5. Do not translate literally - create a natural English equivalent

Respond with only the English query, no explanations or additional text.
"""
                
                # èª¿ç”¨LLM API
                response = analyzer._call_llm_api(prompt)
                
                if response.get('success'):
                    english_query = response.get('content', '').strip()
                    
                    # å‰µå»ºè‹±æ–‡ç‰ˆæœ¬çš„æ¸¬è©¦æ¡ˆä¾‹
                    english_case = {
                        'id': case['id'] + '_en',
                        'query': english_query,
                        'category': case['category'],
                        'complexity': case['complexity'],
                        'language': 'en-US',
                        'expected_intent': case['expected_intent'],
                        'expected_entities': case['expected_entities'],
                        'metadata': {
                            **case.get('metadata', {}),
                            'original_query': case['query'],
                            'translation_method': 'llm_generated',
                            'llm_provider': analyzer.provider.value
                        }
                    }
                    english_test_cases.append(english_case)
                else:
                    print(f"LLMè½‰æ›å¤±æ•—: {case['query']}")
                    
            except Exception as e:
                print(f"è™•ç†æ¡ˆä¾‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                continue
        
        if not english_test_cases:
            return jsonify({
                'success': False,
                'error': 'LLMè½‰æ›å¤±æ•—ï¼Œç„¡æ³•ç”Ÿæˆè‹±æ–‡æ¸¬è©¦æ¡ˆä¾‹'
            }), 500
        
        # å‰µå»ºè‡¨æ™‚æ–‡ä»¶
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f'test_cases_llm_english_{timestamp}.csv'
        filepath = app.config['UPLOAD_FOLDER'] / filename
        
        # è½‰æ›ç‚ºDataFrameä¸¦å°å‡ºCSV
        df_data = []
        for case in english_test_cases:
            df_data.append({
                'ID': case['id'],
                'Query': case['query'],
                'Category': case['category'],
                'Complexity': case['complexity'],
                'Language': case['language'],
                'Expected_Intent': case['expected_intent'],
                'Expected_Entities': json.dumps(case['expected_entities'], ensure_ascii=False),
                'Metadata': json.dumps(case['metadata'], ensure_ascii=False),
                'Original_Query': case['metadata'].get('original_query', '')
            })
        
        df = pd.DataFrame(df_data)
        df.to_csv(filepath, index=False, encoding='utf-8-sig')
        
        return jsonify({
            'success': True,
            'download_url': f'/download-test-cases/{filename}',
            'translated_count': len(english_test_cases),
            'method': 'llm_generated',
            'llm_provider': analyzer.provider.value
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


def _is_pure_english(text: str) -> bool:
    """
    æª¢æŸ¥æ–‡æœ¬æ˜¯å¦ç‚ºç´”è‹±æ–‡ï¼ˆåªåŒ…å«è‹±æ–‡å­—æ¯ã€æ•¸å­—ã€æ¨™é»ç¬¦è™Ÿå’Œç©ºæ ¼ï¼‰
    """
    import re
    # å…è¨±è‹±æ–‡å­—æ¯ã€æ•¸å­—ã€å¸¸è¦‹æ¨™é»ç¬¦è™Ÿå’Œç©ºæ ¼
    english_pattern = re.compile(r'^[a-zA-Z0-9\s\.,;:!?\-\'"()\[\]{}/@#$%^&*+=<>|~`]*$')
    return bool(english_pattern.match(text))

@app.route('/api/generate-english-test-cases', methods=['POST'])
def api_generate_english_test_cases():
    """
    APIç«¯é»ï¼šä½¿ç”¨LLMç›´æ¥ç”Ÿæˆç´”è‹±æ–‡æ¸¬è©¦æ¡ˆä¾‹
    """
    try:
        from jobseeker.llm_intent_analyzer import LLMIntentAnalyzer, LLMProvider
        import os
        
        data = request.get_json()
        num_cases = data.get('num_cases', 20)
        categories = data.get('categories', ['job_search', 'skill_query', 'location_based', 'salary_inquiry'])
        complexity_levels = data.get('complexity_levels', ['simple', 'medium', 'complex'])
        
        # åˆå§‹åŒ–LLMåˆ†æå™¨
        openai_key = os.getenv('OPENAI_API_KEY')
        anthropic_key = os.getenv('ANTHROPIC_API_KEY')
        
        if openai_key:
            analyzer = LLMIntentAnalyzer(provider=LLMProvider.OPENAI_GPT35, api_key=openai_key)
        elif anthropic_key:
            analyzer = LLMIntentAnalyzer(provider=LLMProvider.ANTHROPIC_CLAUDE, api_key=anthropic_key)
        else:
            return jsonify({
                'success': False,
                'error': 'éœ€è¦è¨­ç½® OPENAI_API_KEY æˆ– ANTHROPIC_API_KEY ç’°å¢ƒè®Šé‡'
            }), 400
        
        # ç”Ÿæˆç´”è‹±æ–‡æ¸¬è©¦æ¡ˆä¾‹
        english_test_cases = []
        
        for i in range(num_cases):
            category = random.choice(categories)
            complexity = random.choice(complexity_levels)
            
            # æ§‹å»ºLLMæç¤ºè©
            prompt = f"""
Generate a realistic job search query in PURE ENGLISH ONLY for the following specifications:

Category: {category}
Complexity: {complexity}

**CRITICAL REQUIREMENTS - ENGLISH ONLY:**
- Output MUST contain ONLY English words and characters
- ABSOLUTELY NO Chinese, Japanese, Korean, or any non-English characters
- ALL job titles must be in English (e.g., "Software Engineer", "Data Scientist", "Marketing Manager")
- ALL locations must be in English (e.g., "New York", "London", "Taipei", "Tokyo")
- ALL skills and technologies must be in English (e.g., "Python", "Machine Learning", "Project Management")
- ALL company types must be in English (e.g., "startup", "tech company", "consulting firm")

**CONTENT GUIDELINES:**
1. Create a natural, fluent English query that a real job seeker would ask
2. Match the complexity level:
   - Simple: Basic job title searches ("software engineer jobs")
   - Medium: Queries with 1-2 filters ("remote software engineer jobs in tech")
   - Complex: Detailed queries with multiple criteria ("senior full-stack developer positions at startups with equity compensation")
3. Use professional job search terminology
4. Make it sound conversational and natural
5. Ensure it clearly fits the specified category

**EXAMPLES OF CORRECT OUTPUT:**
- "Software engineer jobs in San Francisco"
- "Remote data scientist positions with machine learning focus"
- "Senior marketing manager roles at tech startups with growth opportunities"

**FORBIDDEN - DO NOT USE:**
- Any Chinese characters (è»Ÿé«”å·¥ç¨‹å¸«, è³‡æ–™ç§‘å­¸å®¶, etc.)
- Any Japanese characters (ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢, etc.)
- Any Korean characters (ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´, etc.)
- Any non-Latin script characters

Respond with ONLY the English query, no explanations or additional text. The output must be 100% English.
"""
            
            try:
                # ç›´æ¥èª¿ç”¨LLMå®¢æˆ¶ç«¯ï¼Œä¸ä½¿ç”¨JSONæ ¼å¼
                messages = [
                    {
                        "role": "system",
                        "content": "You are a professional job search query generator. Generate only pure English job search queries as requested. Do not include any explanations, formatting, or additional text."
                    },
                    {
                        "role": "user", 
                        "content": prompt
                    }
                ]
                
                # èª¿ç”¨LLM APIï¼ˆä¸ä½¿ç”¨JSONæ ¼å¼ï¼‰
                response = analyzer.llm_client.call(
                    messages=messages,
                    temperature=0.1,
                    max_tokens=200
                )
                
                if response.success:
                    english_query = response.content.strip()
                    
                    # é©—è­‰è¼¸å‡ºæ˜¯å¦ç‚ºç´”è‹±æ–‡
                     if _is_pure_english(english_query):
                        # å‰µå»ºæ¸¬è©¦æ¡ˆä¾‹
                        test_case = {
                            'id': f'llm_en_{category}_{complexity}_{i+1}',
                            'query': english_query,
                            'category': category,
                            'complexity': complexity,
                            'language': 'en-US',
                            'expected_intent': 'job_search' if category in ['job_search', 'skill_query', 'location_based', 'salary_inquiry'] else category,
                            'expected_entities': [],
                            'metadata': {
                                'generation_method': 'llm_native',
                                'llm_provider': analyzer.provider.value,
                                'generated_at': datetime.now().isoformat()
                            }
                        }
                        english_test_cases.append(test_case)
                    else:
                        print(f"ç”Ÿæˆçš„æŸ¥è©¢åŒ…å«éè‹±æ–‡å­—ç¬¦ï¼Œè·³é: {english_query}")
                    
            except Exception as e:
                print(f"ç”Ÿæˆæ¡ˆä¾‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                continue
        
        if not english_test_cases:
            return jsonify({
                'success': False,
                'error': 'LLMç”Ÿæˆå¤±æ•—ï¼Œç„¡æ³•å‰µå»ºè‹±æ–‡æ¸¬è©¦æ¡ˆä¾‹'
            }), 500
        
        # ç”Ÿæˆçµ±è¨ˆè³‡è¨Š
        stats = {
            'total_generated': len(english_test_cases),
            'category_distribution': {},
            'complexity_distribution': {},
            'language_distribution': {'en-US': len(english_test_cases)}
        }
        
        # è¨ˆç®—åˆ†ä½ˆçµ±è¨ˆ
        for case in english_test_cases:
            category = case['category']
            stats['category_distribution'][category] = stats['category_distribution'].get(category, 0) + 1
            
            complexity = case['complexity']
            stats['complexity_distribution'][complexity] = stats['complexity_distribution'].get(complexity, 0) + 1
        
        return jsonify({
            'success': True,
            'test_cases': english_test_cases,
            'statistics': stats,
            'method': 'llm_native_generation',
            'llm_provider': analyzer.provider.value
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/run-etl-pipeline', methods=['POST'])
def run_etl_pipeline():
    """
    é‹è¡Œå®Œæ•´çš„ETLæµç¨‹
    å°‡Webä¸Šå‚³çš„æ¸¬è©¦æ¡ˆä¾‹è½‰æ›ç‚ºç´”è‹±æ–‡ä¸¦è¼‰å…¥åˆ°ETLç³»çµ±
    """
    try:
        # åˆå§‹åŒ–ETLç®¡ç†å™¨
        etl_config = ETLConfig()
        etl_manager = ETLManager(etl_config)
        
        # é‹è¡Œå®Œæ•´çš„ETLæµç¨‹
        result = etl_manager.run_full_pipeline()
        
        if result['success']:
            return jsonify({
                'success': True,
                'message': result['message'],
                'stats': result['stats'],
                'duration_seconds': result['duration_seconds'],
                'timestamp': result['timestamp']
            })
        else:
            return jsonify({
                'success': False,
                'message': result['message'],
                'stats': result['stats']
            }), 400
            
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'ETLæµç¨‹åŸ·è¡Œå¤±æ•—: {str(e)}'
        }), 500


@app.route('/api/etl-status', methods=['GET'])
def get_etl_status():
    """
    ç²å–ETLæµç¨‹ç‹€æ…‹ä¿¡æ¯
    """
    try:
        etl_config = ETLConfig()
        etl_manager = ETLManager(etl_config)
        
        status = etl_manager.get_pipeline_status()
        
        return jsonify({
            'success': True,
            'status': status
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'ç²å–ETLç‹€æ…‹å¤±æ•—: {str(e)}'
        }), 500


# è¨»å†Šå¢å¼·ç‰ˆ API Blueprint
try:
    from .enhanced_api import enhanced_api_bp
    app.register_blueprint(enhanced_api_bp)
    print("âœ… å¢å¼·ç‰ˆ API (v2) å·²è¨»å†Š")
except ImportError as e:
    print(f"âš ï¸ ç„¡æ³•è¨»å†Šå¢å¼·ç‰ˆ API: {e}")

if __name__ == '__main__':
    # å¾ç’°å¢ƒè®Šæ•¸ç²å–ä¸»æ©Ÿåœ°å€ï¼Œé è¨­ç‚º 0.0.0.0 ä»¥æ”¯æ´å¤–éƒ¨è¨ªå•
    host = os.environ.get('HOST', '0.0.0.0')
    port = int(os.environ.get('PORT', 5000))
    
    print("ğŸš€ jobseeker ç¶²é æ‡‰ç”¨å•Ÿå‹•ä¸­...")
    print(f"ğŸ“± æœ¬åœ°è¨ªå•: http://localhost:{port}")
    print(f"ğŸ“± ç¶²è·¯è¨ªå•: http://192.168.1.181:{port}")
    print(f"ğŸ“Š API æ–‡æª”: http://localhost:{port}/api/sites")
    print(f"ğŸ”§ ç›£è½åœ°å€: {host}:{port}")
    
    app.run(
        host=host,
        port=port,
        debug=app.config['DEBUG']
    )
