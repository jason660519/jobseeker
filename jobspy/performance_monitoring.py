"""æ•ˆèƒ½ç›£æ§æ¨¡çµ„

æä¾›çˆ¬èŸ²æ•ˆèƒ½ç›£æ§ã€æŒ‡æ¨™æ”¶é›†å’Œåˆ†æåŠŸèƒ½ã€‚
"""

import time
import threading
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass, field
from enum import Enum
from collections import defaultdict, deque
import json
import statistics
from functools import wraps
import asyncio


class MetricType(Enum):
    """æŒ‡æ¨™é¡å‹æšèˆ‰"""
    REQUEST_COUNT = "request_count"
    SUCCESS_COUNT = "success_count"
    ERROR_COUNT = "error_count"
    RESPONSE_TIME = "response_time"
    RATE_LIMIT_HIT = "rate_limit_hit"
    RETRY_COUNT = "retry_count"
    DATA_QUALITY_SCORE = "data_quality_score"
    CACHE_HIT = "cache_hit"
    CACHE_MISS = "cache_miss"


class AlertLevel(Enum):
    """è­¦å ±ç´šåˆ¥æšèˆ‰"""
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"


@dataclass
class MetricEntry:
    """æŒ‡æ¨™æ¢ç›®"""
    timestamp: datetime
    metric_type: MetricType
    value: float
    source: str  # çˆ¬èŸ²ä¾†æº (linkedin, indeed, etc.)
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class PerformanceAlert:
    """æ•ˆèƒ½è­¦å ±"""
    timestamp: datetime
    level: AlertLevel
    message: str
    metric_type: MetricType
    current_value: float
    threshold: float
    source: str


@dataclass
class PerformanceStats:
    """æ•ˆèƒ½çµ±è¨ˆ"""
    total_requests: int = 0
    successful_requests: int = 0
    failed_requests: int = 0
    avg_response_time: float = 0.0
    min_response_time: float = float('inf')
    max_response_time: float = 0.0
    success_rate: float = 0.0
    error_rate: float = 0.0
    cache_hit_rate: float = 0.0
    avg_data_quality_score: float = 0.0
    total_retries: int = 0
    rate_limit_hits: int = 0

    def calculate_rates(self):
        """è¨ˆç®—å„ç¨®æ¯”ç‡"""
        if self.total_requests > 0:
            self.success_rate = self.successful_requests / self.total_requests
            self.error_rate = self.failed_requests / self.total_requests


class MetricsCollector:
    """æŒ‡æ¨™æ”¶é›†å™¨"""
    
    def __init__(self, max_entries: int = 10000):
        self.max_entries = max_entries
        self.metrics: deque = deque(maxlen=max_entries)
        self.alerts: List[PerformanceAlert] = []
        self.thresholds: Dict[MetricType, Dict[str, float]] = {
            MetricType.RESPONSE_TIME: {"warning": 5.0, "error": 10.0},
            MetricType.ERROR_COUNT: {"warning": 10, "error": 20},
            MetricType.SUCCESS_COUNT: {"warning": 0.8, "error": 0.6},  # æˆåŠŸç‡é–¾å€¼
        }
        self._lock = threading.Lock()
    
    def add_metric(self, metric_type: MetricType, value: float, source: str, 
                   metadata: Optional[Dict[str, Any]] = None):
        """æ·»åŠ æŒ‡æ¨™"""
        with self._lock:
            entry = MetricEntry(
                timestamp=datetime.now(),
                metric_type=metric_type,
                value=value,
                source=source,
                metadata=metadata or {}
            )
            self.metrics.append(entry)
            self._check_thresholds(entry)
    
    def _check_thresholds(self, entry: MetricEntry):
        """æª¢æŸ¥é–¾å€¼ä¸¦ç”Ÿæˆè­¦å ±"""
        if entry.metric_type not in self.thresholds:
            return
        
        thresholds = self.thresholds[entry.metric_type]
        
        if entry.value >= thresholds.get("error", float('inf')):
            level = AlertLevel.ERROR
            threshold = thresholds["error"]
        elif entry.value >= thresholds.get("warning", float('inf')):
            level = AlertLevel.WARNING
            threshold = thresholds["warning"]
        else:
            return
        
        alert = PerformanceAlert(
            timestamp=entry.timestamp,
            level=level,
            message=f"{entry.metric_type.value} è¶…éé–¾å€¼: {entry.value} >= {threshold}",
            metric_type=entry.metric_type,
            current_value=entry.value,
            threshold=threshold,
            source=entry.source
        )
        self.alerts.append(alert)
    
    def get_stats(self, source: Optional[str] = None, 
                  time_window: Optional[timedelta] = None) -> PerformanceStats:
        """ç²å–æ•ˆèƒ½çµ±è¨ˆ"""
        with self._lock:
            filtered_metrics = self._filter_metrics(source, time_window)
            return self._calculate_stats(filtered_metrics)
    
    def _filter_metrics(self, source: Optional[str], 
                       time_window: Optional[timedelta]) -> List[MetricEntry]:
        """éæ¿¾æŒ‡æ¨™"""
        filtered = list(self.metrics)
        
        if source:
            filtered = [m for m in filtered if m.source == source]
        
        if time_window:
            cutoff = datetime.now() - time_window
            filtered = [m for m in filtered if m.timestamp >= cutoff]
        
        return filtered
    
    def _calculate_stats(self, metrics: List[MetricEntry]) -> PerformanceStats:
        """è¨ˆç®—çµ±è¨ˆæ•¸æ“š"""
        stats = PerformanceStats()
        
        if not metrics:
            return stats
        
        # æŒ‰é¡å‹åˆ†çµ„æŒ‡æ¨™
        by_type = defaultdict(list)
        for metric in metrics:
            by_type[metric.metric_type].append(metric.value)
        
        # è¨ˆç®—åŸºæœ¬çµ±è¨ˆ
        stats.total_requests = len(by_type.get(MetricType.REQUEST_COUNT, []))
        stats.successful_requests = len(by_type.get(MetricType.SUCCESS_COUNT, []))
        stats.failed_requests = len(by_type.get(MetricType.ERROR_COUNT, []))
        stats.total_retries = len(by_type.get(MetricType.RETRY_COUNT, []))
        stats.rate_limit_hits = len(by_type.get(MetricType.RATE_LIMIT_HIT, []))
        
        # è¨ˆç®—éŸ¿æ‡‰æ™‚é–“çµ±è¨ˆ
        response_times = by_type.get(MetricType.RESPONSE_TIME, [])
        if response_times:
            stats.avg_response_time = statistics.mean(response_times)
            stats.min_response_time = min(response_times)
            stats.max_response_time = max(response_times)
        
        # è¨ˆç®—è³‡æ–™å“è³ªåˆ†æ•¸
        quality_scores = by_type.get(MetricType.DATA_QUALITY_SCORE, [])
        if quality_scores:
            stats.avg_data_quality_score = statistics.mean(quality_scores)
        
        # è¨ˆç®—å¿«å–å‘½ä¸­ç‡
        cache_hits = len(by_type.get(MetricType.CACHE_HIT, []))
        cache_misses = len(by_type.get(MetricType.CACHE_MISS, []))
        total_cache_requests = cache_hits + cache_misses
        if total_cache_requests > 0:
            stats.cache_hit_rate = cache_hits / total_cache_requests
        
        # è¨ˆç®—æ¯”ç‡
        stats.calculate_rates()
        
        return stats
    
    def get_recent_alerts(self, count: int = 10) -> List[PerformanceAlert]:
        """ç²å–æœ€è¿‘çš„è­¦å ±"""
        return sorted(self.alerts, key=lambda x: x.timestamp, reverse=True)[:count]
    
    def export_metrics(self, filepath: str, source: Optional[str] = None,
                      time_window: Optional[timedelta] = None):
        """å°å‡ºæŒ‡æ¨™åˆ°æ–‡ä»¶"""
        with self._lock:
            filtered_metrics = self._filter_metrics(source, time_window)
            
            data = {
                "export_time": datetime.now().isoformat(),
                "source_filter": source,
                "time_window_hours": time_window.total_seconds() / 3600 if time_window else None,
                "metrics": [
                    {
                        "timestamp": m.timestamp.isoformat(),
                        "type": m.metric_type.value,
                        "value": m.value,
                        "source": m.source,
                        "metadata": m.metadata
                    }
                    for m in filtered_metrics
                ],
                "stats": self._stats_to_dict(self._calculate_stats(filtered_metrics))
            }
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
    
    def _stats_to_dict(self, stats: PerformanceStats) -> Dict[str, Any]:
        """å°‡çµ±è¨ˆå°è±¡è½‰æ›ç‚ºå­—å…¸"""
        return {
            "total_requests": stats.total_requests,
            "successful_requests": stats.successful_requests,
            "failed_requests": stats.failed_requests,
            "avg_response_time": stats.avg_response_time,
            "min_response_time": stats.min_response_time if stats.min_response_time != float('inf') else 0,
            "max_response_time": stats.max_response_time,
            "success_rate": stats.success_rate,
            "error_rate": stats.error_rate,
            "cache_hit_rate": stats.cache_hit_rate,
            "avg_data_quality_score": stats.avg_data_quality_score,
            "total_retries": stats.total_retries,
            "rate_limit_hits": stats.rate_limit_hits
        }


class ScrapingMetrics:
    """çˆ¬èŸ²æŒ‡æ¨™ç®¡ç†å™¨"""
    
    _instance = None
    _lock = threading.Lock()
    
    def __new__(cls):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        if not hasattr(self, 'initialized'):
            self.collector = MetricsCollector()
            self.initialized = True
    
    def record_request(self, source: str, metadata: Optional[Dict[str, Any]] = None):
        """è¨˜éŒ„è«‹æ±‚"""
        self.collector.add_metric(MetricType.REQUEST_COUNT, 1, source, metadata)
    
    def record_success(self, source: str, response_time: float, 
                      metadata: Optional[Dict[str, Any]] = None):
        """è¨˜éŒ„æˆåŠŸè«‹æ±‚"""
        self.collector.add_metric(MetricType.SUCCESS_COUNT, 1, source, metadata)
        self.collector.add_metric(MetricType.RESPONSE_TIME, response_time, source, metadata)
    
    def record_error(self, source: str, error_type: str, 
                    metadata: Optional[Dict[str, Any]] = None):
        """è¨˜éŒ„éŒ¯èª¤"""
        metadata = metadata or {}
        metadata['error_type'] = error_type
        self.collector.add_metric(MetricType.ERROR_COUNT, 1, source, metadata)
    
    def record_retry(self, source: str, attempt: int, 
                    metadata: Optional[Dict[str, Any]] = None):
        """è¨˜éŒ„é‡è©¦"""
        metadata = metadata or {}
        metadata['attempt'] = attempt
        self.collector.add_metric(MetricType.RETRY_COUNT, 1, source, metadata)
    
    def record_rate_limit(self, source: str, metadata: Optional[Dict[str, Any]] = None):
        """è¨˜éŒ„é€Ÿç‡é™åˆ¶"""
        self.collector.add_metric(MetricType.RATE_LIMIT_HIT, 1, source, metadata)
    
    def record_cache_hit(self, source: str, metadata: Optional[Dict[str, Any]] = None):
        """è¨˜éŒ„å¿«å–å‘½ä¸­"""
        self.collector.add_metric(MetricType.CACHE_HIT, 1, source, metadata)
    
    def record_cache_miss(self, source: str, metadata: Optional[Dict[str, Any]] = None):
        """è¨˜éŒ„å¿«å–æœªå‘½ä¸­"""
        self.collector.add_metric(MetricType.CACHE_MISS, 1, source, metadata)
    
    def record_data_quality(self, source: str, score: float, 
                           metadata: Optional[Dict[str, Any]] = None):
        """è¨˜éŒ„è³‡æ–™å“è³ªåˆ†æ•¸"""
        self.collector.add_metric(MetricType.DATA_QUALITY_SCORE, score, source, metadata)
    
    def get_stats(self, source: Optional[str] = None, 
                  hours: Optional[int] = None) -> PerformanceStats:
        """ç²å–çµ±è¨ˆæ•¸æ“š"""
        time_window = timedelta(hours=hours) if hours else None
        return self.collector.get_stats(source, time_window)
    
    def get_alerts(self, count: int = 10) -> List[PerformanceAlert]:
        """ç²å–è­¦å ±"""
        return self.collector.get_recent_alerts(count)
    
    def export_report(self, filepath: str, source: Optional[str] = None, 
                     hours: Optional[int] = None):
        """å°å‡ºæ•ˆèƒ½å ±å‘Š"""
        time_window = timedelta(hours=hours) if hours else None
        self.collector.export_metrics(filepath, source, time_window)


def performance_monitor(source: str):
    """æ•ˆèƒ½ç›£æ§è£é£¾å™¨"""
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs):
            metrics = ScrapingMetrics()
            start_time = time.time()
            
            try:
                metrics.record_request(source)
                result = func(*args, **kwargs)
                
                response_time = time.time() - start_time
                metrics.record_success(source, response_time)
                
                return result
            except Exception as e:
                metrics.record_error(source, type(e).__name__)
                raise
        
        return wrapper
    return decorator


def async_performance_monitor(source: str):
    """éåŒæ­¥æ•ˆèƒ½ç›£æ§è£é£¾å™¨"""
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(*args, **kwargs):
            metrics = ScrapingMetrics()
            start_time = time.time()
            
            try:
                metrics.record_request(source)
                result = await func(*args, **kwargs)
                
                response_time = time.time() - start_time
                metrics.record_success(source, response_time)
                
                return result
            except Exception as e:
                metrics.record_error(source, type(e).__name__)
                raise
        
        return wrapper
    return decorator


class PerformanceDashboard:
    """æ•ˆèƒ½å„€è¡¨æ¿"""
    
    def __init__(self, metrics: ScrapingMetrics):
        self.metrics = metrics
    
    def print_summary(self, source: Optional[str] = None, hours: Optional[int] = 24):
        """æ‰“å°æ•ˆèƒ½æ‘˜è¦"""
        stats = self.metrics.get_stats(source, hours)
        alerts = self.metrics.get_alerts(5)
        
        print("\n=== çˆ¬èŸ²æ•ˆèƒ½æ‘˜è¦ ===")
        if source:
            print(f"ä¾†æº: {source}")
        if hours:
            print(f"æ™‚é–“ç¯„åœ: æœ€è¿‘ {hours} å°æ™‚")
        
        print(f"\nğŸ“Š åŸºæœ¬çµ±è¨ˆ:")
        print(f"  ç¸½è«‹æ±‚æ•¸: {stats.total_requests}")
        print(f"  æˆåŠŸè«‹æ±‚: {stats.successful_requests}")
        print(f"  å¤±æ•—è«‹æ±‚: {stats.failed_requests}")
        print(f"  æˆåŠŸç‡: {stats.success_rate:.2%}")
        print(f"  éŒ¯èª¤ç‡: {stats.error_rate:.2%}")
        
        print(f"\nâ±ï¸ éŸ¿æ‡‰æ™‚é–“:")
        print(f"  å¹³å‡: {stats.avg_response_time:.2f}s")
        print(f"  æœ€å°: {stats.min_response_time:.2f}s")
        print(f"  æœ€å¤§: {stats.max_response_time:.2f}s")
        
        print(f"\nğŸ”„ å…¶ä»–æŒ‡æ¨™:")
        print(f"  é‡è©¦æ¬¡æ•¸: {stats.total_retries}")
        print(f"  é€Ÿç‡é™åˆ¶: {stats.rate_limit_hits}")
        print(f"  å¿«å–å‘½ä¸­ç‡: {stats.cache_hit_rate:.2%}")
        print(f"  å¹³å‡è³‡æ–™å“è³ª: {stats.avg_data_quality_score:.2f}")
        
        if alerts:
            print(f"\nğŸš¨ æœ€è¿‘è­¦å ±:")
            for alert in alerts:
                emoji = {"warning": "âš ï¸", "error": "âŒ", "critical": "ğŸ”¥"}.get(alert.level.value, "â„¹ï¸")
                print(f"  {emoji} [{alert.timestamp.strftime('%H:%M:%S')}] {alert.message}")
        
        print("\n" + "="*50)


# å…¨åŸŸæŒ‡æ¨™å¯¦ä¾‹
metrics = ScrapingMetrics()


# ä¾¿åˆ©å‡½æ•¸
def get_performance_stats(source: Optional[str] = None, hours: Optional[int] = None) -> PerformanceStats:
    """ç²å–æ•ˆèƒ½çµ±è¨ˆçš„ä¾¿åˆ©å‡½æ•¸"""
    return metrics.get_stats(source, hours)


def show_performance_dashboard(source: Optional[str] = None, hours: Optional[int] = 24):
    """é¡¯ç¤ºæ•ˆèƒ½å„€è¡¨æ¿çš„ä¾¿åˆ©å‡½æ•¸"""
    dashboard = PerformanceDashboard(metrics)
    dashboard.print_summary(source, hours)


def export_performance_report(filepath: str, source: Optional[str] = None, hours: Optional[int] = None):
    """å°å‡ºæ•ˆèƒ½å ±å‘Šçš„ä¾¿åˆ©å‡½æ•¸"""
    metrics.export_report(filepath, source, hours)