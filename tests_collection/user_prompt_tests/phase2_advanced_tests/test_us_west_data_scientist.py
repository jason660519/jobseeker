#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¾åœ‹è¥¿éƒ¨ Data Scientist è·ä½æœå°‹æ¸¬è©¦
æ¸¬è©¦ç›®æ¨™ï¼šæœå°‹èˆŠé‡‘å±±å’Œè¥¿é›…åœ–çš„ Data Scientist è·ä½
æ¸¬è©¦é¡å‹ï¼šåœ°é»ç¯©é¸ + è–ªè³‡åˆ†æ
"""

import sys
import os
import json
import pandas as pd
from datetime import datetime
from pathlib import Path

# æ·»åŠ  jobseeker æ¨¡çµ„è·¯å¾‘
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..', '..'))

from jobseeker import scrape_jobs
from jobseeker.model import Site, Country

def convert_types(obj):
    """
    å°‡ numpy/pandas æ•¸æ“šé¡å‹è½‰æ›ç‚º Python åŸç”Ÿé¡å‹ï¼Œä»¥ä¾¿ JSON åºåˆ—åŒ–
    """
    import numpy as np
    
    if pd.isna(obj):
        return None
    elif hasattr(obj, 'item'):  # numpy types
        return obj.item()
    elif isinstance(obj, (pd.Timestamp, pd.Timedelta)):
        return str(obj)
    elif isinstance(obj, (np.integer, np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.floating, np.float64, np.float32)):
        return float(obj)
    elif isinstance(obj, np.bool_):
        return bool(obj)
    else:
        return obj

def test_us_west_data_scientist():
    """
    æ¸¬è©¦ç¾åœ‹è¥¿éƒ¨åœ°å€ Data Scientist è·ä½æœå°‹åŠŸèƒ½
    """
    print("=== ç¾åœ‹è¥¿éƒ¨ Data Scientist è·ä½æœå°‹æ¸¬è©¦ ===")
    
    # æ¸¬è©¦åƒæ•¸
    test_params = {
        'san_francisco': {
            'site_name': [Site.INDEED, Site.LINKEDIN, Site.ZIP_RECRUITER],
            'search_term': 'Data Scientist',
            'location': 'San Francisco, CA',
            'country': Country.USA,
            'results_wanted': 75,
            'hours_old': 168,  # ä¸€é€±å…§
            'job_type': 'fulltime'
        },
        'seattle': {
            'site_name': [Site.INDEED, Site.LINKEDIN, Site.ZIP_RECRUITER],
            'search_term': 'Data Scientist',
            'location': 'Seattle, WA',
            'country': Country.USA,
            'results_wanted': 75,
            'hours_old': 168,  # ä¸€é€±å…§
            'job_type': 'fulltime'
        }
    }
    
    all_jobs = []
    test_results = {}
    
    # ç‚ºæ¯å€‹åŸå¸‚åŸ·è¡Œæœå°‹
    for city, params in test_params.items():
        print(f"\nğŸ” æœå°‹ {city.replace('_', ' ').title()} çš„ Data Scientist è·ä½...")
        
        try:
            jobs = scrape_jobs(**params)
            
            if jobs is not None and not jobs.empty:
                print(f"âœ… {city.replace('_', ' ').title()} æ‰¾åˆ° {len(jobs)} å€‹è·ä½")
                
                # æ·»åŠ åŸå¸‚æ¨™è¨˜
                jobs['search_city'] = city.replace('_', ' ').title()
                all_jobs.append(jobs)
                
                # æ”¶é›†æ¸¬è©¦çµæœ
                test_results[city] = {
                    'job_count': len(jobs),
                    'sites': jobs['site'].value_counts().to_dict() if 'site' in jobs.columns else {},
                    'companies': jobs['company'].value_counts().head(5).to_dict() if 'company' in jobs.columns else {},
                    'avg_salary': jobs['salary_avg'].mean() if 'salary_avg' in jobs.columns else None
                }
                
                # é¡¯ç¤ºåŸºæœ¬çµ±è¨ˆ
                print(f"   ç¶²ç«™åˆ†å¸ƒ: {dict(jobs['site'].value_counts()) if 'site' in jobs.columns else 'N/A'}")
                if 'salary_avg' in jobs.columns and jobs['salary_avg'].notna().any():
                    avg_salary = jobs['salary_avg'].mean()
                    print(f"   å¹³å‡è–ªè³‡: ${avg_salary:,.0f}")
                    
            else:
                print(f"âŒ {city.replace('_', ' ').title()} æœªæ‰¾åˆ°è·ä½")
                test_results[city] = {'job_count': 0, 'error': 'No jobs found'}
                
        except Exception as e:
            print(f"âŒ {city.replace('_', ' ').title()} æœå°‹å¤±æ•—: {str(e)}")
            test_results[city] = {'job_count': 0, 'error': str(e)}
    
    # åˆä½µæ‰€æœ‰çµæœ
    if all_jobs:
        combined_jobs = pd.concat(all_jobs, ignore_index=True)
        total_jobs = len(combined_jobs)
        print(f"\nğŸ“Š ç¸½è¨ˆæ‰¾åˆ° {total_jobs} å€‹ Data Scientist è·ä½")
        
        # å‰µå»ºçµæœç›®éŒ„
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        result_dir = Path(f"tests_collection/user_prompt_tests/phase2_advanced_tests/us_west_data_scientist_{timestamp}")
        result_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜è©³ç´°çµæœ
        combined_jobs.to_csv(result_dir / "us_west_data_scientist_jobs.csv", index=False, encoding='utf-8')
        
        # è–ªè³‡åˆ†æ
        salary_analysis = {}
        if 'salary_avg' in combined_jobs.columns:
            salary_data = combined_jobs['salary_avg'].dropna()
            if not salary_data.empty:
                salary_analysis = {
                    'overall_avg': convert_types(salary_data.mean()),
                    'median': convert_types(salary_data.median()),
                    'min': convert_types(salary_data.min()),
                    'max': convert_types(salary_data.max()),
                    'std': convert_types(salary_data.std())
                }
        
        # ç”Ÿæˆåˆ†æå ±å‘Š
        analysis = {
            'test_info': {
                'test_name': 'US West Data Scientist Search',
                'test_date': datetime.now().isoformat(),
                'total_jobs': total_jobs,
                'cities_tested': list(test_params.keys())
            },
            'salary_analysis': salary_analysis,
            'city_results': {}
        }
        
        for city in test_params.keys():
            city_data = combined_jobs[combined_jobs['search_city'] == city.replace('_', ' ').title()]
            if not city_data.empty:
                city_salary_analysis = {}
                if 'salary_avg' in city_data.columns:
                    city_salary_data = city_data['salary_avg'].dropna()
                    if not city_salary_data.empty:
                        city_salary_analysis = {
                            'avg': convert_types(city_salary_data.mean()),
                            'median': convert_types(city_salary_data.median()),
                            'min': convert_types(city_salary_data.min()),
                            'max': convert_types(city_salary_data.max())
                        }
                
                analysis['city_results'][city] = {
                    'job_count': len(city_data),
                    'site_distribution': {k: convert_types(v) for k, v in city_data['site'].value_counts().to_dict().items()} if 'site' in city_data.columns else {},
                    'top_companies': {k: convert_types(v) for k, v in city_data['company'].value_counts().head(5).to_dict().items()} if 'company' in city_data.columns else {},
                    'salary_analysis': city_salary_analysis
                }
        
        # ä¿å­˜åˆ†æçµæœ
        with open(result_dir / "analysis_report.json", 'w', encoding='utf-8') as f:
            json.dump(analysis, f, indent=2, ensure_ascii=False)
        
        # ç”Ÿæˆæ¸¬è©¦å ±å‘Š
        report_content = f"""# ç¾åœ‹è¥¿éƒ¨ Data Scientist è·ä½æœå°‹æ¸¬è©¦å ±å‘Š

## æ¸¬è©¦æ¦‚è¦
- **æ¸¬è©¦æ—¥æœŸ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **æ¸¬è©¦åŸå¸‚**: San Francisco, Seattle
- **æœå°‹è·ä½**: Data Scientist
- **ç¸½è·ä½æ•¸**: {total_jobs}

## è–ªè³‡åˆ†æ
{f"- **æ•´é«”å¹³å‡è–ªè³‡**: ${salary_analysis.get('overall_avg', 0):,.0f}" if salary_analysis.get('overall_avg') else "- è–ªè³‡è³‡è¨Šä¸è¶³"}
{f"- **è–ªè³‡ä¸­ä½æ•¸**: ${salary_analysis.get('median', 0):,.0f}" if salary_analysis.get('median') else ""}
{f"- **è–ªè³‡ç¯„åœ**: ${salary_analysis.get('min', 0):,.0f} - ${salary_analysis.get('max', 0):,.0f}" if salary_analysis.get('min') and salary_analysis.get('max') else ""}

## åŸå¸‚åˆ†æ

### San Francisco
- è·ä½æ•¸é‡: {test_results.get('san_francisco', {}).get('job_count', 0)}
- ç¶²ç«™åˆ†å¸ƒ: {test_results.get('san_francisco', {}).get('sites', {})}
{f"- å¹³å‡è–ªè³‡: ${test_results.get('san_francisco', {}).get('avg_salary', 0):,.0f}" if test_results.get('san_francisco', {}).get('avg_salary') else ""}

### Seattle
- è·ä½æ•¸é‡: {test_results.get('seattle', {}).get('job_count', 0)}
- ç¶²ç«™åˆ†å¸ƒ: {test_results.get('seattle', {}).get('sites', {})}
{f"- å¹³å‡è–ªè³‡: ${test_results.get('seattle', {}).get('avg_salary', 0):,.0f}" if test_results.get('seattle', {}).get('avg_salary') else ""}

## æ¸¬è©¦çµè«–
âœ… ç¾åœ‹è¥¿éƒ¨ Data Scientist è·ä½æœå°‹æ¸¬è©¦å®Œæˆ
ğŸ“ çµæœå·²ä¿å­˜è‡³: {result_dir}
"""
        
        with open(result_dir / "test_report.md", 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"\nğŸ“ æ¸¬è©¦çµæœå·²ä¿å­˜è‡³: {result_dir}")
        return True
        
    else:
        print("\nâŒ æ‰€æœ‰åŸå¸‚éƒ½æœªæ‰¾åˆ°è·ä½")
        return False

if __name__ == "__main__":
    success = test_us_west_data_scientist()
    if success:
        print("\nğŸ‰ ç¾åœ‹è¥¿éƒ¨ Data Scientist æ¸¬è©¦æˆåŠŸå®Œæˆï¼")
    else:
        print("\nğŸ’¥ ç¾åœ‹è¥¿éƒ¨ Data Scientist æ¸¬è©¦å¤±æ•—")
        sys.exit(1)