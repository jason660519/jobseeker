#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–°åŠ å¡å’Œé¦™æ¸¯Machine Learning Engineerè·ä½æœå°‹æ¸¬è©¦

æ¸¬è©¦ç”¨æˆ¶æç¤º: "å°‹æ‰¾æ–°åŠ å¡å’Œé¦™æ¸¯çš„Machine Learning Engineerè·ä½ï¼Œè–ªè³‡ç¯„åœ80k-150k USD"

Author: JobSpy Team
Date: 2025-01-09
"""

import os
import sys
import pandas as pd
from datetime import datetime
from pathlib import Path

# æ·»åŠ jobseekeræ¨¡çµ„åˆ°è·¯å¾‘
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..', '..'))

from jobseeker import scrape_jobs
from jobseeker.model import Site


def test_singapore_ml_engineer():
    """
    åŸ·è¡Œæ–°åŠ å¡å’Œé¦™æ¸¯Machine Learning Engineerè·ä½æœå°‹æ¸¬è©¦
    
    æ¸¬è©¦åƒæ•¸:
    - è·ä½: Machine Learning Engineer
    - åœ°é»: Singapore, Hong Kong
    - ç¶²ç«™: Indeed, LinkedIn, Glassdoor
    - è–ªè³‡ç¯„åœ: 80k-150k USD
    
    Returns:
        dict: æ¸¬è©¦çµæœ
    """
    print("ğŸš€ é–‹å§‹åŸ·è¡Œæ–°åŠ å¡å’Œé¦™æ¸¯Machine Learning Engineerè·ä½æœå°‹æ¸¬è©¦")
    print("ğŸ“ ç”¨æˆ¶æç¤º: å°‹æ‰¾æ–°åŠ å¡å’Œé¦™æ¸¯çš„Machine Learning Engineerè·ä½ï¼Œè–ªè³‡ç¯„åœ80k-150k USD")
    
    # æ¸¬è©¦é…ç½®
    test_config = {
        'job_title': 'Machine Learning Engineer',
        'locations': [
            {'name': 'Singapore', 'country': 'Singapore'},
            {'name': 'Hong Kong', 'country': 'Hong Kong'}
        ],
        'sites': [Site.INDEED, Site.LINKEDIN, Site.GLASSDOOR],
        'results_wanted': 75,
        'salary_range': {'min': 80000, 'max': 150000, 'currency': 'USD'}
    }
    
    # å‰µå»ºçµæœç›®éŒ„
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_dir = Path(__file__).parent / f"singapore_ml_engineer_{timestamp}"
    results_dir.mkdir(exist_ok=True)
    
    all_jobs = []
    test_results = {
        'test_name': 'singapore_ml_engineer',
        'user_prompt': 'å°‹æ‰¾æ–°åŠ å¡å’Œé¦™æ¸¯çš„Machine Learning Engineerè·ä½ï¼Œè–ªè³‡ç¯„åœ80k-150k USD',
        'start_time': datetime.now(),
        'locations_tested': [],
        'total_jobs': 0,
        'jobs_by_location': {},
        'jobs_by_site': {},
        'salary_analysis': {},
        'status': 'running'
    }
    
    try:
        # ç‚ºæ¯å€‹åœ°é»åŸ·è¡Œæœå°‹
        for location_info in test_config['locations']:
            location = location_info['name']
            country = location_info['country']
            print(f"\nğŸ” æœå°‹åœ°é»: {location}")
            print(f"ğŸŒ åœ‹å®¶è¨­å®š: {country}")
            print(f"ğŸ’° ç›®æ¨™è–ªè³‡: {test_config['salary_range']['min']:,}-{test_config['salary_range']['max']:,} {test_config['salary_range']['currency']}")
            
            try:
                # åŸ·è¡ŒJobSpyæœå°‹
                jobs_df = scrape_jobs(
                    site_name=test_config['sites'],
                    search_term=test_config['job_title'],
                    location=location,
                    results_wanted=test_config['results_wanted'],
                    country_indeed=country
                )
                
                if jobs_df is not None and not jobs_df.empty:
                    all_jobs.append(jobs_df)
                    job_count = len(jobs_df)
                    test_results['jobs_by_location'][location] = job_count
                    test_results['locations_tested'].append(location)
                    print(f"âœ… {location}: æ‰¾åˆ° {job_count} å€‹è·ä½")
                    
                    # åˆ†æè–ªè³‡è³‡è¨Š
                    salary_info = analyze_salary_data(jobs_df, test_config['salary_range'])
                    if salary_info['jobs_with_salary'] > 0:
                        print(f"ğŸ’° æœ‰è–ªè³‡è³‡è¨Š: {salary_info['jobs_with_salary']} å€‹è·ä½")
                        print(f"ğŸ’° ç¬¦åˆè–ªè³‡ç¯„åœ: {salary_info['jobs_in_range']} å€‹è·ä½")
                    
                    # å„²å­˜å–®ä¸€åœ°é»çµæœ
                    location_file = results_dir / f"{location.replace(' ', '_').lower()}_jobs.csv"
                    jobs_df.to_csv(location_file, index=False, encoding='utf-8-sig')
                    
                else:
                    print(f"âš ï¸  {location}: æ²’æœ‰æ‰¾åˆ°è·ä½")
                    test_results['jobs_by_location'][location] = 0
                    
            except Exception as e:
                print(f"âŒ {location} æœå°‹å¤±æ•—: {str(e)}")
                test_results['jobs_by_location'][location] = 0
        
        # åˆä½µæ‰€æœ‰çµæœ
        if all_jobs:
            combined_df = pd.concat(all_jobs, ignore_index=True)
            
            # ç§»é™¤é‡è¤‡è·ä½ (åŸºæ–¼job_url)
            original_count = len(combined_df)
            combined_df = combined_df.drop_duplicates(subset=['job_url'], keep='first')
            final_count = len(combined_df)
            
            print(f"\nğŸ“Š åˆä½µçµæœ: {original_count} â†’ {final_count} (ç§»é™¤ {original_count - final_count} å€‹é‡è¤‡è·ä½)")
            
            # çµ±è¨ˆç¶²ç«™åˆ†å¸ƒ
            if 'site' in combined_df.columns:
                site_counts = combined_df['site'].value_counts()
                test_results['jobs_by_site'] = site_counts.to_dict()
                print("\nğŸŒ ç¶²ç«™åˆ†å¸ƒ:")
                for site, count in site_counts.items():
                    print(f"   {site}: {count} å€‹è·ä½")
            
            # è©³ç´°è–ªè³‡åˆ†æ
            salary_analysis = analyze_salary_data(combined_df, test_config['salary_range'])
            test_results['salary_analysis'] = salary_analysis
            
            print(f"\nğŸ’° è–ªè³‡åˆ†æ:")
            print(f"   æœ‰è–ªè³‡è³‡è¨Š: {salary_analysis['jobs_with_salary']} å€‹è·ä½")
            print(f"   ç¬¦åˆç¯„åœ: {salary_analysis['jobs_in_range']} å€‹è·ä½")
            if salary_analysis['avg_min_salary'] > 0:
                print(f"   å¹³å‡æœ€ä½è–ªè³‡: {salary_analysis['avg_min_salary']:,.0f}")
                print(f"   å¹³å‡æœ€é«˜è–ªè³‡: {salary_analysis['avg_max_salary']:,.0f}")
            
            # å„²å­˜åˆä½µçµæœ
            combined_file = results_dir / "singapore_ml_engineer_combined.csv"
            combined_df.to_csv(combined_file, index=False, encoding='utf-8-sig')
            
            # å„²å­˜åŸå§‹JSONè³‡æ–™
            json_file = results_dir / "singapore_ml_engineer_raw_data.json"
            combined_df.to_json(json_file, orient='records', indent=2, force_ascii=False)
            
            # æ›´æ–°æ¸¬è©¦çµæœ
            test_results['total_jobs'] = final_count
            test_results['status'] = 'success'
            test_results['csv_file'] = str(combined_file)
            test_results['json_file'] = str(json_file)
            
            # ç”ŸæˆåŸºæœ¬çµ±è¨ˆ
            stats = {
                'unique_companies': combined_df['company'].nunique() if 'company' in combined_df.columns else 0,
                'unique_locations': combined_df['location'].nunique() if 'location' in combined_df.columns else 0,
                'remote_jobs': len(combined_df[combined_df['is_remote'] == True]) if 'is_remote' in combined_df.columns else 0,
                'senior_positions': count_senior_positions(combined_df)
            }
            test_results['statistics'] = stats
            
            print(f"\nğŸ“ˆ çµ±è¨ˆè³‡è¨Š:")
            print(f"   ğŸ’¼ ç¸½è·ä½æ•¸: {final_count}")
            print(f"   ğŸ¢ å…¬å¸æ•¸: {stats['unique_companies']}")
            print(f"   ğŸ“ åœ°é»æ•¸: {stats['unique_locations']}")
            print(f"   ğŸ  é ç¨‹å·¥ä½œ: {stats['remote_jobs']}")
            print(f"   ğŸ‘” é«˜ç´šè·ä½: {stats['senior_positions']}")
            
            # åˆ†ææŠ€èƒ½è¦æ±‚
            skill_analysis = analyze_ml_skills(combined_df)
            if skill_analysis:
                test_results['skill_analysis'] = skill_analysis
                print(f"\nğŸ”§ æŠ€èƒ½åˆ†æ:")
                for skill, count in skill_analysis.items():
                    print(f"   {skill}: {count} å€‹è·ä½")
            
        else:
            test_results['status'] = 'no_results'
            test_results['total_jobs'] = 0
            print("âŒ æ‰€æœ‰åœ°é»éƒ½æ²’æœ‰æ‰¾åˆ°è·ä½")
    
    except Exception as e:
        test_results['status'] = 'error'
        test_results['error'] = str(e)
        print(f"âŒ æ¸¬è©¦åŸ·è¡Œå‡ºéŒ¯: {str(e)}")
    
    finally:
        test_results['end_time'] = datetime.now()
        test_results['execution_time'] = (test_results['end_time'] - test_results['start_time']).total_seconds()
        
        # å„²å­˜æ¸¬è©¦çµæœ
        import json
        results_file = results_dir / "test_results.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            # è½‰æ›datetimeç‚ºå­—ä¸²ä»¥ä¾¿JSONåºåˆ—åŒ–
            results_copy = test_results.copy()
            results_copy['start_time'] = test_results['start_time'].isoformat()
            results_copy['end_time'] = test_results['end_time'].isoformat()
            
            # è½‰æ›numpy/pandasæ•¸æ“šé¡å‹ç‚ºPythonåŸç”Ÿé¡å‹
            def convert_types(obj):
                if hasattr(obj, 'item'):
                    return obj.item()
                elif isinstance(obj, dict):
                    return {k: convert_types(v) for k, v in obj.items()}
                elif isinstance(obj, list):
                    return [convert_types(v) for v in obj]
                return obj
            
            results_copy = convert_types(results_copy)
            json.dump(results_copy, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“ æ¸¬è©¦çµæœå·²å„²å­˜è‡³: {results_dir}")
        print(f"â±ï¸  åŸ·è¡Œæ™‚é–“: {test_results['execution_time']:.2f} ç§’")
    
    return test_results


def analyze_salary_data(df: pd.DataFrame, target_range: dict) -> dict:
    """
    åˆ†æè–ªè³‡è³‡æ–™
    
    Args:
        df: è·ä½è³‡æ–™DataFrame
        target_range: ç›®æ¨™è–ªè³‡ç¯„åœ
        
    Returns:
        dict: è–ªè³‡åˆ†æçµæœ
    """
    analysis = {
        'jobs_with_salary': 0,
        'jobs_in_range': 0,
        'avg_min_salary': 0,
        'avg_max_salary': 0,
        'salary_currencies': {}
    }
    
    if 'min_amount' in df.columns and 'max_amount' in df.columns:
        # æœ‰è–ªè³‡è³‡è¨Šçš„è·ä½
        salary_jobs = df.dropna(subset=['min_amount'])
        analysis['jobs_with_salary'] = len(salary_jobs)
        
        if len(salary_jobs) > 0:
            # è¨ˆç®—å¹³å‡è–ªè³‡
            analysis['avg_min_salary'] = salary_jobs['min_amount'].mean()
            analysis['avg_max_salary'] = salary_jobs['max_amount'].mean()
            
            # çµ±è¨ˆè²¨å¹£é¡å‹
            if 'currency' in salary_jobs.columns:
                currency_counts = salary_jobs['currency'].value_counts()
                analysis['salary_currencies'] = currency_counts.to_dict()
            
            # æª¢æŸ¥ç¬¦åˆè–ªè³‡ç¯„åœçš„è·ä½
            target_min = target_range['min']
            target_max = target_range['max']
            
            # å‡è¨­è–ªè³‡åœ¨ç›®æ¨™ç¯„åœå…§çš„æ¢ä»¶ï¼šæœ€ä½è–ªè³‡ >= target_min æˆ– æœ€é«˜è–ªè³‡ <= target_max
            in_range = salary_jobs[
                (salary_jobs['min_amount'] >= target_min) | 
                (salary_jobs['max_amount'] <= target_max)
            ]
            analysis['jobs_in_range'] = len(in_range)
    
    return analysis


def count_senior_positions(df: pd.DataFrame) -> int:
    """
    çµ±è¨ˆé«˜ç´šè·ä½æ•¸é‡
    
    Args:
        df: è·ä½è³‡æ–™DataFrame
        
    Returns:
        int: é«˜ç´šè·ä½æ•¸é‡
    """
    if 'title' not in df.columns:
        return 0
    
    senior_keywords = ['Senior', 'Lead', 'Principal', 'Staff', 'Director', 'Manager', 'Head']
    senior_count = 0
    
    for keyword in senior_keywords:
        senior_count += df['title'].str.contains(keyword, case=False, na=False).sum()
    
    return senior_count


def analyze_ml_skills(df: pd.DataFrame) -> dict:
    """
    åˆ†ææ©Ÿå™¨å­¸ç¿’ç›¸é—œæŠ€èƒ½è¦æ±‚
    
    Args:
        df: è·ä½è³‡æ–™DataFrame
        
    Returns:
        dict: æŠ€èƒ½åˆ†æçµæœ
    """
    if 'description' not in df.columns:
        return {}
    
    ml_skills = {
        'Python': 0,
        'TensorFlow': 0,
        'PyTorch': 0,
        'Scikit-learn': 0,
        'Keras': 0,
        'AWS': 0,
        'Azure': 0,
        'GCP': 0,
        'Docker': 0,
        'Kubernetes': 0,
        'SQL': 0,
        'Spark': 0,
        'Hadoop': 0
    }
    
    # åˆä½µæ‰€æœ‰æè¿°æ–‡å­—
    all_descriptions = df['description'].dropna().str.lower()
    
    for skill in ml_skills.keys():
        skill_count = all_descriptions.str.contains(skill.lower(), na=False).sum()
        ml_skills[skill] = skill_count
    
    # åªè¿”å›æœ‰å‡ºç¾çš„æŠ€èƒ½
    return {skill: count for skill, count in ml_skills.items() if count > 0}


def generate_test_report(test_results: dict, results_dir: Path):
    """
    ç”Ÿæˆæ¸¬è©¦å ±å‘Š
    
    Args:
        test_results: æ¸¬è©¦çµæœå­—å…¸
        results_dir: çµæœç›®éŒ„è·¯å¾‘
    """
    report_content = f"""# æ–°åŠ å¡å’Œé¦™æ¸¯Machine Learning Engineerè·ä½æœå°‹æ¸¬è©¦å ±å‘Š

## ğŸ“‹ æ¸¬è©¦æ¦‚è¦

- **æ¸¬è©¦åç¨±**: {test_results['test_name']}
- **ç”¨æˆ¶æç¤º**: "{test_results['user_prompt']}"
- **åŸ·è¡Œæ™‚é–“**: {test_results['start_time'].strftime('%Y-%m-%d %H:%M:%S')}
- **æ¸¬è©¦ç‹€æ…‹**: {test_results['status']}
- **åŸ·è¡Œæ™‚é•·**: {test_results['execution_time']:.2f} ç§’

## ğŸ¯ æ¸¬è©¦çµæœ

### ç¸½é«”çµ±è¨ˆ
- **ç¸½è·ä½æ•¸**: {test_results['total_jobs']}
- **æ¸¬è©¦åœ°é»æ•¸**: {len(test_results['locations_tested'])}

### åœ°é»åˆ†å¸ƒ
"""
    
    for location, count in test_results.get('jobs_by_location', {}).items():
        report_content += f"- **{location}**: {count} å€‹è·ä½\n"
    
    if test_results.get('jobs_by_site'):
        report_content += "\n### ç¶²ç«™åˆ†å¸ƒ\n"
        for site, count in test_results['jobs_by_site'].items():
            report_content += f"- **{site}**: {count} å€‹è·ä½\n"
    
    # è–ªè³‡åˆ†æ
    if test_results.get('salary_analysis'):
        salary = test_results['salary_analysis']
        report_content += f"\n### ğŸ’° è–ªè³‡åˆ†æ\n"
        report_content += f"- **æœ‰è–ªè³‡è³‡è¨Šçš„è·ä½**: {salary['jobs_with_salary']}\n"
        report_content += f"- **ç¬¦åˆè–ªè³‡ç¯„åœçš„è·ä½**: {salary['jobs_in_range']}\n"
        if salary['avg_min_salary'] > 0:
            report_content += f"- **å¹³å‡æœ€ä½è–ªè³‡**: {salary['avg_min_salary']:,.0f}\n"
            report_content += f"- **å¹³å‡æœ€é«˜è–ªè³‡**: {salary['avg_max_salary']:,.0f}\n"
        
        if salary.get('salary_currencies'):
            report_content += "\n#### è–ªè³‡è²¨å¹£åˆ†å¸ƒ\n"
            for currency, count in salary['salary_currencies'].items():
                report_content += f"- **{currency}**: {count} å€‹è·ä½\n"
    
    if test_results.get('statistics'):
        stats = test_results['statistics']
        report_content += f"\n### ğŸ“Š è©³ç´°çµ±è¨ˆ\n"
        report_content += f"- **å…¬å¸æ•¸é‡**: {stats['unique_companies']}\n"
        report_content += f"- **åœ°é»æ•¸é‡**: {stats['unique_locations']}\n"
        report_content += f"- **é ç¨‹å·¥ä½œ**: {stats['remote_jobs']}\n"
        report_content += f"- **é«˜ç´šè·ä½**: {stats['senior_positions']}\n"
    
    if test_results.get('skill_analysis'):
        report_content += "\n### ğŸ”§ æŠ€èƒ½è¦æ±‚åˆ†æ\n"
        for skill, count in test_results['skill_analysis'].items():
            report_content += f"- **{skill}**: {count} å€‹è·ä½\n"
    
    # æ¸¬è©¦çµè«–
    report_content += "\n## ğŸ¯ æ¸¬è©¦çµè«–\n\n"
    if test_results['status'] == 'success':
        if test_results['total_jobs'] >= 10:
            report_content += "âœ… **æ¸¬è©¦é€šé**: æˆåŠŸæ‰¾åˆ°è¶³å¤ æ•¸é‡çš„Machine Learning Engineerè·ä½\n"
        else:
            report_content += "âš ï¸ **éƒ¨åˆ†æˆåŠŸ**: æ‰¾åˆ°è·ä½ä½†æ•¸é‡è¼ƒå°‘\n"
        
        salary_analysis = test_results.get('salary_analysis', {})
        if salary_analysis.get('jobs_with_salary', 0) > 0:
            report_content += "âœ… **è–ªè³‡è³‡è¨Š**: éƒ¨åˆ†è·ä½åŒ…å«è–ªè³‡è³‡è¨Š\n"
            if salary_analysis.get('jobs_in_range', 0) > 0:
                report_content += "âœ… **è–ªè³‡ç¯„åœ**: æ‰¾åˆ°ç¬¦åˆç›®æ¨™è–ªè³‡ç¯„åœçš„è·ä½\n"
            else:
                report_content += "âš ï¸ **è–ªè³‡ç¯„åœ**: æ²’æœ‰è·ä½å®Œå…¨ç¬¦åˆç›®æ¨™è–ªè³‡ç¯„åœ\n"
        else:
            report_content += "âš ï¸ **è–ªè³‡è³‡è¨Š**: å¤§éƒ¨åˆ†è·ä½ç¼ºå°‘è–ªè³‡è³‡è¨Š\n"
            
    elif test_results['status'] == 'no_results':
        report_content += "âŒ **æ¸¬è©¦å¤±æ•—**: æ²’æœ‰æ‰¾åˆ°ä»»ä½•è·ä½\n"
    else:
        report_content += f"âŒ **æ¸¬è©¦éŒ¯èª¤**: {test_results.get('error', 'æœªçŸ¥éŒ¯èª¤')}\n"
    
    report_content += "\n### å»ºè­°\n"
    report_content += "- æ–°åŠ å¡å’Œé¦™æ¸¯æ˜¯äºæ´²MLå·¥ç¨‹å¸«è·ä½çš„é‡è¦å¸‚å ´\n"
    report_content += "- è–ªè³‡è³‡è¨Šå¯èƒ½å› ç‚ºéš±ç§æ”¿ç­–è€Œè¼ƒå°‘å…¬é–‹\n"
    report_content += "- å¯ä»¥è€ƒæ…®æ“´å¤§æœå°‹åˆ°å…¶ä»–ç›¸é—œè·ä½å¦‚Data Scientist\n"
    
    report_content += f"\n---\n\n*å ±å‘Šç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*"
    
    # å„²å­˜å ±å‘Š
    report_file = results_dir / "test_report.md"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report_content)
    
    print(f"ğŸ“„ æ¸¬è©¦å ±å‘Šå·²ç”Ÿæˆ: {report_file}")


if __name__ == "__main__":
    # åŸ·è¡Œæ¸¬è©¦
    results = test_singapore_ml_engineer()
    
    # ç”Ÿæˆå ±å‘Š
    if 'csv_file' in results:
        results_dir = Path(results['csv_file']).parent
        generate_test_report(results, results_dir)
    
    # é¡¯ç¤ºæœ€çµ‚ç‹€æ…‹
    if results['status'] == 'success':
        print(f"\nğŸ‰ æ¸¬è©¦æˆåŠŸå®Œæˆ! æ‰¾åˆ° {results['total_jobs']} å€‹Machine Learning Engineerè·ä½")
        salary_info = results.get('salary_analysis', {})
        if salary_info.get('jobs_with_salary', 0) > 0:
            print(f"ğŸ’° å…¶ä¸­ {salary_info['jobs_with_salary']} å€‹è·ä½æœ‰è–ªè³‡è³‡è¨Š")
    else:
        print(f"\nâš ï¸ æ¸¬è©¦ç‹€æ…‹: {results['status']}")