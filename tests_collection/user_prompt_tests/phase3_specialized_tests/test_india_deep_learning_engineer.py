#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°åº¦ Deep Learning Engineer è·ä½æœå°‹æ¸¬è©¦
æ¸¬è©¦ç›®æ¨™ï¼šæœå°‹ç­åŠ ç¾…çˆ¾å’Œæµ·å¾·æ‹‰å·´çš„ Deep Learning Engineer è·ä½
æ¸¬è©¦é¡å‹ï¼šå°ˆæ¥­æŠ€è¡“è·ä½ + å°åº¦ç§‘æŠ€ä¸­å¿ƒæ¸¬è©¦
"""

import sys
import os
import json
import pandas as pd
from datetime import datetime
from pathlib import Path

# æ·»åŠ  jobseeker æ¨¡çµ„è·¯å¾‘
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..', '..'))

from jobseeker import scrape_jobs
from jobseeker.model import Site, Country

def convert_types(obj):
    """
    å°‡ numpy/pandas æ•¸æ“šé¡å‹è½‰æ›ç‚º Python åŸç”Ÿé¡å‹ï¼Œä»¥ä¾¿ JSON åºåˆ—åŒ–
    """
    import numpy as np
    
    if pd.isna(obj):
        return None
    elif hasattr(obj, 'item'):  # numpy types
        return obj.item()
    elif isinstance(obj, (pd.Timestamp, pd.Timedelta)):
        return str(obj)
    elif isinstance(obj, (np.integer, np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.floating, np.float64, np.float32)):
        return float(obj)
    elif isinstance(obj, np.bool_):
        return bool(obj)
    else:
        return obj

def test_india_deep_learning_engineer():
    """
    æ¸¬è©¦å°åº¦åœ°å€ Deep Learning Engineer è·ä½æœå°‹åŠŸèƒ½
    """
    print("=== å°åº¦ Deep Learning Engineer è·ä½æœå°‹æ¸¬è©¦ ===")
    
    # æ¸¬è©¦åƒæ•¸
    test_params = {
        'bangalore': {
            'site_name': [Site.INDEED, Site.LINKEDIN, Site.NAUKRI],
            'search_term': 'Deep Learning Engineer',
            'location': 'Bangalore, India',
            'country': Country.INDIA,
            'results_wanted': 75,
            'hours_old': 168,  # ä¸€é€±å…§
            'job_type': 'fulltime'
        },
        'hyderabad': {
            'site_name': [Site.INDEED, Site.LINKEDIN, Site.NAUKRI],
            'search_term': 'Deep Learning Engineer',
            'location': 'Hyderabad, India',
            'country': Country.INDIA,
            'results_wanted': 75,
            'hours_old': 168,  # ä¸€é€±å…§
            'job_type': 'fulltime'
        }
    }
    
    all_jobs = []
    test_results = {}
    
    # ç‚ºæ¯å€‹åŸå¸‚åŸ·è¡Œæœå°‹
    for city, params in test_params.items():
        print(f"\nğŸ” æœå°‹ {city.title()} çš„ Deep Learning Engineer è·ä½...")
        
        try:
            jobs = scrape_jobs(**params)
            
            if jobs is not None and not jobs.empty:
                print(f"âœ… {city.title()} æ‰¾åˆ° {len(jobs)} å€‹è·ä½")
                
                # æ·»åŠ åŸå¸‚æ¨™è¨˜
                jobs['search_city'] = city.title()
                all_jobs.append(jobs)
                
                # æ”¶é›†æ¸¬è©¦çµæœ
                test_results[city] = {
                    'job_count': len(jobs),
                    'sites': jobs['site'].value_counts().to_dict() if 'site' in jobs.columns else {},
                    'companies': jobs['company'].value_counts().head(5).to_dict() if 'company' in jobs.columns else {},
                    'avg_salary': jobs['salary_avg'].mean() if 'salary_avg' in jobs.columns else None
                }
                
                # é¡¯ç¤ºåŸºæœ¬çµ±è¨ˆ
                print(f"   ç¶²ç«™åˆ†å¸ƒ: {dict(jobs['site'].value_counts()) if 'site' in jobs.columns else 'N/A'}")
                if 'salary_avg' in jobs.columns and jobs['salary_avg'].notna().any():
                    avg_salary = jobs['salary_avg'].mean()
                    print(f"   å¹³å‡è–ªè³‡: â‚¹{avg_salary:,.0f}")
                    
                # åˆ†æå…¬å¸é¡å‹
                if 'company' in jobs.columns:
                    companies = jobs['company'].value_counts().head(10)
                    print(f"   ä¸»è¦é›‡ä¸»: {list(companies.index[:3])}")
                    
            else:
                print(f"âŒ {city.title()} æœªæ‰¾åˆ°è·ä½")
                test_results[city] = {'job_count': 0, 'error': 'No jobs found'}
                
        except Exception as e:
            print(f"âŒ {city.title()} æœå°‹å¤±æ•—: {str(e)}")
            test_results[city] = {'job_count': 0, 'error': str(e)}
    
    # åˆä½µæ‰€æœ‰çµæœ
    if all_jobs:
        combined_jobs = pd.concat(all_jobs, ignore_index=True)
        total_jobs = len(combined_jobs)
        print(f"\nğŸ“Š ç¸½è¨ˆæ‰¾åˆ° {total_jobs} å€‹ Deep Learning Engineer è·ä½")
        
        # å‰µå»ºçµæœç›®éŒ„
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        result_dir = Path(f"tests_collection/user_prompt_tests/phase3_specialized_tests/india_deep_learning_engineer_{timestamp}")
        result_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜è©³ç´°çµæœ
        combined_jobs.to_csv(result_dir / "india_deep_learning_engineer_jobs.csv", index=False, encoding='utf-8')
        
        # æ·±åº¦å­¸ç¿’æŠ€èƒ½åˆ†æ
        skill_analysis = {}
        if 'description' in combined_jobs.columns:
            all_descriptions = ' '.join(combined_jobs['description'].fillna('').astype(str))
            dl_keywords = {
                'tensorflow': ['tensorflow', 'tf'],
                'pytorch': ['pytorch', 'torch'],
                'keras': ['keras'],
                'python': ['python'],
                'cnn': ['cnn', 'convolutional neural network'],
                'rnn': ['rnn', 'recurrent neural network', 'lstm', 'gru'],
                'transformer': ['transformer', 'bert', 'gpt'],
                'computer_vision': ['computer vision', 'cv', 'image processing'],
                'nlp': ['nlp', 'natural language processing'],
                'gpu': ['gpu', 'cuda', 'nvidia'],
                'docker': ['docker', 'kubernetes'],
                'cloud': ['aws', 'azure', 'gcp', 'cloud']
            }
            
            for skill, keywords in dl_keywords.items():
                count = sum(all_descriptions.lower().count(keyword) for keyword in keywords)
                skill_analysis[skill] = count
        
        # å…¬å¸é¡å‹åˆ†æ
        company_analysis = {}
        if 'company' in combined_jobs.columns:
            companies = combined_jobs['company'].value_counts()
            # åˆ†é¡å…¬å¸é¡å‹ï¼ˆåŸºæ–¼å¸¸è¦‹çš„å°åº¦ç§‘æŠ€å…¬å¸ï¼‰
            tech_giants = ['Google', 'Microsoft', 'Amazon', 'Facebook', 'Apple', 'IBM']
            indian_it = ['TCS', 'Infosys', 'Wipro', 'HCL', 'Tech Mahindra', 'Cognizant']
            startups = ['Flipkart', 'Ola', 'Paytm', 'Zomato', 'Swiggy', 'BYJU\'S']
            
            company_analysis = {
                'tech_giants': sum(companies.get(company, 0) for company in tech_giants),
                'indian_it_services': sum(companies.get(company, 0) for company in indian_it),
                'startups': sum(companies.get(company, 0) for company in startups),
                'others': len(combined_jobs) - sum(companies.get(company, 0) for company in tech_giants + indian_it + startups)
            }
        
        # ç”Ÿæˆåˆ†æå ±å‘Š
        analysis = {
            'test_info': {
                'test_name': 'India Deep Learning Engineer Search',
                'test_date': datetime.now().isoformat(),
                'total_jobs': convert_types(total_jobs),
                'cities_tested': list(test_params.keys())
            },
            'skill_analysis': {k: convert_types(v) for k, v in skill_analysis.items()},
            'company_analysis': {k: convert_types(v) for k, v in company_analysis.items()},
            'city_results': {}
        }
        
        for city in test_params.keys():
            city_data = combined_jobs[combined_jobs['search_city'] == city.title()]
            if not city_data.empty:
                analysis['city_results'][city] = {
                    'job_count': len(city_data),
                    'site_distribution': {k: convert_types(v) for k, v in city_data['site'].value_counts().to_dict().items()} if 'site' in city_data.columns else {},
                    'top_companies': {k: convert_types(v) for k, v in city_data['company'].value_counts().head(5).to_dict().items()} if 'company' in city_data.columns else {},
                    'salary_info': {
                        'avg_salary': convert_types(city_data['salary_avg'].mean()) if 'salary_avg' in city_data.columns else None,
                        'min_salary': convert_types(city_data['salary_min'].min()) if 'salary_min' in city_data.columns else None,
                        'max_salary': convert_types(city_data['salary_max'].max()) if 'salary_max' in city_data.columns else None
                    }
                }
        
        # ä¿å­˜åˆ†æçµæœ
        with open(result_dir / "analysis_report.json", 'w', encoding='utf-8') as f:
            json.dump(analysis, f, indent=2, ensure_ascii=False)
        
        # ç”Ÿæˆæ¸¬è©¦å ±å‘Š
        top_skills = sorted(skill_analysis.items(), key=lambda x: x[1], reverse=True)[:5] if skill_analysis else []
        
        report_content = f"""# å°åº¦ Deep Learning Engineer è·ä½æœå°‹æ¸¬è©¦å ±å‘Š

## æ¸¬è©¦æ¦‚è¦
- **æ¸¬è©¦æ—¥æœŸ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **æ¸¬è©¦åŸå¸‚**: Bangalore, Hyderabad
- **æœå°‹è·ä½**: Deep Learning Engineer
- **ç¸½è·ä½æ•¸**: {total_jobs}

## æ·±åº¦å­¸ç¿’æŠ€èƒ½éœ€æ±‚åˆ†æ
{chr(10).join([f"- **{skill.replace('_', ' ').title()}**: {count} æ¬¡æåŠ" for skill, count in top_skills]) if top_skills else "- æŠ€èƒ½åˆ†æè³‡æ–™ä¸è¶³"}

## å…¬å¸é¡å‹åˆ†å¸ƒ
{f"- **è·¨åœ‹ç§‘æŠ€å·¨é ­**: {company_analysis.get('tech_giants', 0)} å€‹è·ä½" if company_analysis else ""}
{f"- **å°åº¦ITæœå‹™å…¬å¸**: {company_analysis.get('indian_it_services', 0)} å€‹è·ä½" if company_analysis else ""}
{f"- **æ–°å‰µå…¬å¸**: {company_analysis.get('startups', 0)} å€‹è·ä½" if company_analysis else ""}
{f"- **å…¶ä»–å…¬å¸**: {company_analysis.get('others', 0)} å€‹è·ä½" if company_analysis else ""}

## åŸå¸‚åˆ†æ

### Bangalore
- è·ä½æ•¸é‡: {test_results.get('bangalore', {}).get('job_count', 0)}
- ç¶²ç«™åˆ†å¸ƒ: {test_results.get('bangalore', {}).get('sites', {})}
{f"- å¹³å‡è–ªè³‡: â‚¹{test_results.get('bangalore', {}).get('avg_salary', 0):,.0f}" if test_results.get('bangalore', {}).get('avg_salary') else ""}

### Hyderabad
- è·ä½æ•¸é‡: {test_results.get('hyderabad', {}).get('job_count', 0)}
- ç¶²ç«™åˆ†å¸ƒ: {test_results.get('hyderabad', {}).get('sites', {})}
{f"- å¹³å‡è–ªè³‡: â‚¹{test_results.get('hyderabad', {}).get('avg_salary', 0):,.0f}" if test_results.get('hyderabad', {}).get('avg_salary') else ""}

## å¸‚å ´æ´å¯Ÿ
- å°åº¦æ˜¯å…¨çƒæ·±åº¦å­¸ç¿’äººæ‰çš„é‡è¦ä¾›æ‡‰åœ°
- Bangalore ä½œç‚º"å°åº¦çŸ½è°·"æ“æœ‰æœ€å¤šAIè·ä½
- Hyderabad æ­£å¿«é€Ÿç™¼å±•ç‚ºAIç ”ç™¼ä¸­å¿ƒ
- è–ªè³‡æ°´å¹³ç›¸å°è¼ƒä½ä½†äººæ‰ç´ è³ªé«˜

## æ¸¬è©¦çµè«–
âœ… å°åº¦ Deep Learning Engineer è·ä½æœå°‹æ¸¬è©¦å®Œæˆ
ğŸ“ çµæœå·²ä¿å­˜è‡³: {result_dir}
"""
        
        with open(result_dir / "test_report.md", 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"\nğŸ“ æ¸¬è©¦çµæœå·²ä¿å­˜è‡³: {result_dir}")
        return True
        
    else:
        print("\nâŒ æ‰€æœ‰åŸå¸‚éƒ½æœªæ‰¾åˆ°è·ä½")
        return False

if __name__ == "__main__":
    success = test_india_deep_learning_engineer()
    if success:
        print("\nğŸ‰ å°åº¦ Deep Learning Engineer æ¸¬è©¦æˆåŠŸå®Œæˆï¼")
    else:
        print("\nğŸ’¥ å°åº¦ Deep Learning Engineer æ¸¬è©¦å¤±æ•—")
        sys.exit(1)