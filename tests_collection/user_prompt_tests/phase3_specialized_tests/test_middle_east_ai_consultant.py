#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸­æ±åœ°å€ AI Consultant è·ä½æœå°‹æ¸¬è©¦
æ¸¬è©¦ç›®æ¨™ï¼šæœå°‹æœæ‹œå’Œé˜¿å¸ƒé”æ¯”çš„ AI Consultant è·ä½
æ¸¬è©¦é¡å‹ï¼šå°ˆæ¥­è«®è©¢è·ä½ + ä¸­æ±å¸‚å ´æ¸¬è©¦
"""

import sys
import os
import json
import pandas as pd
from datetime import datetime
from pathlib import Path

# æ·»åŠ  jobseeker æ¨¡çµ„è·¯å¾‘
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..', '..'))

from jobseeker import scrape_jobs
from jobseeker.model import Site, Country

def convert_types(obj):
    """
    å°‡ numpy/pandas æ•¸æ“šé¡å‹è½‰æ›ç‚º Python åŸç”Ÿé¡å‹ï¼Œä»¥ä¾¿ JSON åºåˆ—åŒ–
    """
    if pd.isna(obj):
        return None
    elif hasattr(obj, 'item'):  # numpy types
        return obj.item()
    elif isinstance(obj, (pd.Timestamp, pd.Timedelta)):
        return str(obj)
    else:
        return obj

def test_middle_east_ai_consultant():
    """
    æ¸¬è©¦ä¸­æ±åœ°å€ AI Consultant è·ä½æœå°‹åŠŸèƒ½
    """
    print("=== ä¸­æ±åœ°å€ AI Consultant è·ä½æœå°‹æ¸¬è©¦ ===")
    
    # æ¸¬è©¦åƒæ•¸
    test_params = {
        'dubai': {
            'site_name': [Site.INDEED, Site.LINKEDIN],
            'search_term': 'AI Consultant',
            'location': 'Dubai, UAE',
            'country': Country.UNITEDARABEMIRATES,
            'results_wanted': 50,
            'hours_old': 168,  # ä¸€é€±å…§
            'job_type': 'fulltime'
        },
        'abu_dhabi': {
            'site_name': [Site.INDEED, Site.LINKEDIN],
            'search_term': 'AI Consultant',
            'location': 'Abu Dhabi, UAE',
            'country': Country.UNITEDARABEMIRATES,
            'results_wanted': 50,
            'hours_old': 168,  # ä¸€é€±å…§
            'job_type': 'fulltime'
        }
    }
    
    all_jobs = []
    test_results = {}
    
    # ç‚ºæ¯å€‹åŸå¸‚åŸ·è¡Œæœå°‹
    for city, params in test_params.items():
        print(f"\nğŸ” æœå°‹ {city.replace('_', ' ').title()} çš„ AI Consultant è·ä½...")
        
        try:
            jobs = scrape_jobs(**params)
            
            if jobs is not None and not jobs.empty:
                print(f"âœ… {city.replace('_', ' ').title()} æ‰¾åˆ° {len(jobs)} å€‹è·ä½")
                
                # æ·»åŠ åŸå¸‚æ¨™è¨˜
                jobs['search_city'] = city.replace('_', ' ').title()
                all_jobs.append(jobs)
                
                # æ”¶é›†æ¸¬è©¦çµæœ
                test_results[city] = {
                    'job_count': len(jobs),
                    'sites': jobs['site'].value_counts().to_dict() if 'site' in jobs.columns else {},
                    'companies': jobs['company'].value_counts().head(5).to_dict() if 'company' in jobs.columns else {},
                    'avg_salary': jobs['salary_avg'].mean() if 'salary_avg' in jobs.columns else None
                }
                
                # é¡¯ç¤ºåŸºæœ¬çµ±è¨ˆ
                print(f"   ç¶²ç«™åˆ†å¸ƒ: {dict(jobs['site'].value_counts()) if 'site' in jobs.columns else 'N/A'}")
                if 'salary_avg' in jobs.columns and jobs['salary_avg'].notna().any():
                    avg_salary = jobs['salary_avg'].mean()
                    print(f"   å¹³å‡è–ªè³‡: {avg_salary:,.0f} AED")
                    
                # åˆ†æè·ä½æè¿°ä¸­çš„é—œéµæŠ€èƒ½
                if 'description' in jobs.columns:
                    descriptions = ' '.join(jobs['description'].fillna('').astype(str))
                    ai_keywords = ['machine learning', 'deep learning', 'neural network', 'tensorflow', 'pytorch', 'python', 'data science', 'nlp', 'computer vision']
                    keyword_counts = {keyword: descriptions.lower().count(keyword) for keyword in ai_keywords}
                    top_skills = sorted(keyword_counts.items(), key=lambda x: x[1], reverse=True)[:5]
                    print(f"   ç†±é–€æŠ€èƒ½: {dict(top_skills)}")
                    
            else:
                print(f"âŒ {city.replace('_', ' ').title()} æœªæ‰¾åˆ°è·ä½")
                test_results[city] = {'job_count': 0, 'error': 'No jobs found'}
                
        except Exception as e:
            print(f"âŒ {city.replace('_', ' ').title()} æœå°‹å¤±æ•—: {str(e)}")
            test_results[city] = {'job_count': 0, 'error': str(e)}
    
    # åˆä½µæ‰€æœ‰çµæœ
    if all_jobs:
        combined_jobs = pd.concat(all_jobs, ignore_index=True)
        total_jobs = len(combined_jobs)
        print(f"\nğŸ“Š ç¸½è¨ˆæ‰¾åˆ° {total_jobs} å€‹ AI Consultant è·ä½")
        
        # å‰µå»ºçµæœç›®éŒ„
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        result_dir = Path(f"tests_collection/user_prompt_tests/phase3_specialized_tests/middle_east_ai_consultant_{timestamp}")
        result_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜è©³ç´°çµæœ
        combined_jobs.to_csv(result_dir / "middle_east_ai_consultant_jobs.csv", index=False, encoding='utf-8')
        
        # æŠ€èƒ½åˆ†æ
        skill_analysis = {}
        if 'description' in combined_jobs.columns:
            all_descriptions = ' '.join(combined_jobs['description'].fillna('').astype(str))
            ai_keywords = {
                'machine_learning': ['machine learning', 'ml'],
                'deep_learning': ['deep learning', 'neural network'],
                'python': ['python'],
                'tensorflow': ['tensorflow'],
                'pytorch': ['pytorch'],
                'data_science': ['data science', 'data analytics'],
                'nlp': ['nlp', 'natural language processing'],
                'computer_vision': ['computer vision', 'cv'],
                'cloud': ['aws', 'azure', 'gcp', 'cloud'],
                'consulting': ['consulting', 'advisory', 'strategy']
            }
            
            for skill, keywords in ai_keywords.items():
                count = sum(all_descriptions.lower().count(keyword) for keyword in keywords)
                skill_analysis[skill] = count
        
        # ç”Ÿæˆåˆ†æå ±å‘Š
        analysis = {
            'test_info': {
                'test_name': 'Middle East AI Consultant Search',
                'test_date': datetime.now().isoformat(),
                'total_jobs': total_jobs,
                'cities_tested': list(test_params.keys())
            },
            'skill_analysis': skill_analysis,
            'city_results': {}
        }
        
        for city in test_params.keys():
            city_data = combined_jobs[combined_jobs['search_city'] == city.replace('_', ' ').title()]
            if not city_data.empty:
                analysis['city_results'][city] = {
                    'job_count': len(city_data),
                    'site_distribution': {k: convert_types(v) for k, v in city_data['site'].value_counts().to_dict().items()} if 'site' in city_data.columns else {},
                    'top_companies': {k: convert_types(v) for k, v in city_data['company'].value_counts().head(5).to_dict().items()} if 'company' in city_data.columns else {},
                    'salary_info': {
                        'avg_salary': convert_types(city_data['salary_avg'].mean()) if 'salary_avg' in city_data.columns else None,
                        'min_salary': convert_types(city_data['salary_min'].min()) if 'salary_min' in city_data.columns else None,
                        'max_salary': convert_types(city_data['salary_max'].max()) if 'salary_max' in city_data.columns else None
                    }
                }
        
        # ä¿å­˜åˆ†æçµæœ
        with open(result_dir / "analysis_report.json", 'w', encoding='utf-8') as f:
            json.dump(analysis, f, indent=2, ensure_ascii=False)
        
        # ç”Ÿæˆæ¸¬è©¦å ±å‘Š
        top_skills = sorted(skill_analysis.items(), key=lambda x: x[1], reverse=True)[:5] if skill_analysis else []
        
        report_content = f"""# ä¸­æ±åœ°å€ AI Consultant è·ä½æœå°‹æ¸¬è©¦å ±å‘Š

## æ¸¬è©¦æ¦‚è¦
- **æ¸¬è©¦æ—¥æœŸ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **æ¸¬è©¦åŸå¸‚**: Dubai, Abu Dhabi
- **æœå°‹è·ä½**: AI Consultant
- **ç¸½è·ä½æ•¸**: {total_jobs}

## æŠ€èƒ½éœ€æ±‚åˆ†æ
{chr(10).join([f"- **{skill.replace('_', ' ').title()}**: {count} æ¬¡æåŠ" for skill, count in top_skills]) if top_skills else "- æŠ€èƒ½åˆ†æè³‡æ–™ä¸è¶³"}

## åŸå¸‚åˆ†æ

### Dubai
- è·ä½æ•¸é‡: {test_results.get('dubai', {}).get('job_count', 0)}
- ç¶²ç«™åˆ†å¸ƒ: {test_results.get('dubai', {}).get('sites', {})}
{f"- å¹³å‡è–ªè³‡: {test_results.get('dubai', {}).get('avg_salary', 0):,.0f} AED" if test_results.get('dubai', {}).get('avg_salary') else ""}

### Abu Dhabi
- è·ä½æ•¸é‡: {test_results.get('abu_dhabi', {}).get('job_count', 0)}
- ç¶²ç«™åˆ†å¸ƒ: {test_results.get('abu_dhabi', {}).get('sites', {})}
{f"- å¹³å‡è–ªè³‡: {test_results.get('abu_dhabi', {}).get('avg_salary', 0):,.0f} AED" if test_results.get('abu_dhabi', {}).get('avg_salary') else ""}

## å¸‚å ´æ´å¯Ÿ
- ä¸­æ±åœ°å€å°AIè«®è©¢æœå‹™éœ€æ±‚é€æ¼¸å¢é•·
- æ”¿åºœæ•¸ä½åŒ–è½‰å‹æ¨å‹•AIäººæ‰éœ€æ±‚
- è·¨åœ‹ä¼æ¥­åœ¨UAEè¨­ç«‹AIä¸­å¿ƒ

## æ¸¬è©¦çµè«–
âœ… ä¸­æ±åœ°å€ AI Consultant è·ä½æœå°‹æ¸¬è©¦å®Œæˆ
ğŸ“ çµæœå·²ä¿å­˜è‡³: {result_dir}
"""
        
        with open(result_dir / "test_report.md", 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"\nğŸ“ æ¸¬è©¦çµæœå·²ä¿å­˜è‡³: {result_dir}")
        return True
        
    else:
        print("\nâŒ æ‰€æœ‰åŸå¸‚éƒ½æœªæ‰¾åˆ°è·ä½")
        return False

if __name__ == "__main__":
    success = test_middle_east_ai_consultant()
    if success:
        print("\nğŸ‰ ä¸­æ±åœ°å€ AI Consultant æ¸¬è©¦æˆåŠŸå®Œæˆï¼")
    else:
        print("\nğŸ’¥ ä¸­æ±åœ°å€ AI Consultant æ¸¬è©¦å¤±æ•—")
        sys.exit(1)