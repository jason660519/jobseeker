#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ­æ´²å¸‚å ´å…¨é¢æ¸¬è©¦
æ¸¬è©¦æ™ºèƒ½è·¯ç”±å™¨å°æ­æ´²å„åœ‹çš„æ”¯æ´èƒ½åŠ›ä¸¦åŸ·è¡Œå¯¦éš›è·ä½æœç´¢

Author: JobSpy Team
Date: 2025-01-27
"""

import sys
import os
from datetime import datetime
import pandas as pd
import time

# æ·»åŠ  jobspy æ¨¡çµ„è·¯å¾‘
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from jobspy import scrape_jobs
from jobspy.intelligent_router import IntelligentRouter

def test_comprehensive_europe():
    """
    å…¨é¢æ¸¬è©¦æ­æ´²å¸‚å ´æ”¯æ´
    
    Returns:
        dict: æ¸¬è©¦çµæœçµ±è¨ˆ
    """
    print("=" * 80)
    print("ğŸ‡ªğŸ‡º æ­æ´²å¸‚å ´å…¨é¢æ¸¬è©¦ - AIå·¥ç¨‹å¸«è·ä½æœç´¢")
    print("=" * 80)
    
    # åˆå§‹åŒ–æ™ºèƒ½è·¯ç”±å™¨
    router = IntelligentRouter()
    
    # æ­æ´²å„åœ‹æ¸¬è©¦æŸ¥è©¢
    europe_queries = [
        # ä¸»è¦æ­æ´²åœ‹å®¶
        "è‹±åœ‹å€«æ•¦ AIå·¥ç¨‹å¸« è·ä½",
        "æ³•åœ‹å·´é» æ©Ÿå™¨å­¸ç¿’å·¥ç¨‹å¸« å·¥ä½œ",
        "å¾·åœ‹æŸæ— æ·±åº¦å­¸ç¿’å·¥ç¨‹å¸« è·ç¼º",
        "è·è˜­é˜¿å§†æ–¯ç‰¹ä¸¹ äººå·¥æ™ºèƒ½å·¥ç¨‹å¸«",
        "ç‘å£«è˜‡é»ä¸– AIç ”ç™¼å·¥ç¨‹å¸«",
        "æ¯”åˆ©æ™‚å¸ƒé­¯å¡çˆ¾ æ©Ÿå™¨å­¸ç¿’ è·ä½",
        "å¥§åœ°åˆ©ç¶­ä¹Ÿç´ AI å·¥ç¨‹å¸«",
        "ç¾©å¤§åˆ©ç±³è˜­ äººå·¥æ™ºèƒ½ å·¥ä½œ",
        "è¥¿ç­ç‰™é¦¬å¾·é‡Œ æ©Ÿå™¨å­¸ç¿’ è·ç¼º",
        "ç‘å…¸æ–¯å¾·å“¥çˆ¾æ‘© AIå·¥ç¨‹å¸«",
        
        # æ­æ´²åœ°å€é€šç”¨æŸ¥è©¢
        "æ­æ´²åœ°å€ AIå·¥ç¨‹å¸« è·ä½",
        "Europe AI Engineer jobs",
        "æ­ç›Ÿ äººå·¥æ™ºèƒ½å·¥ç¨‹å¸« å·¥ä½œ",
        "EU machine learning engineer",
        "European AI developer positions"
    ]
    
    print(f"\nğŸ“ æ¸¬è©¦ {len(europe_queries)} å€‹æ­æ´²æŸ¥è©¢...")
    print("-" * 60)
    
    test_results = []
    
    for i, query in enumerate(europe_queries, 1):
        print(f"\n{i:2d}. æ¸¬è©¦æŸ¥è©¢: {query}")
        
        try:
            # åˆ†ææŸ¥è©¢
            decision = router.analyze_query(query)
            
            result = {
                'query': query,
                'geographic_match': decision.geographic_match,
                'industry_match': decision.industry_match,
                'confidence_score': decision.confidence_score,
                'selected_agents': [agent.value for agent in decision.selected_agents],
                'reasoning': decision.reasoning,
                'status': 'success'
            }
            
            print(f"    âœ… åœ°ç†åŒ¹é…: {decision.geographic_match}")
            print(f"    ğŸ¯ è¡Œæ¥­åŒ¹é…: {decision.industry_match}")
            print(f"    ğŸ“Š ä¿¡å¿ƒåº¦: {decision.confidence_score:.2f}")
            print(f"    ğŸ¤– ä»£ç†: {[agent.value for agent in decision.selected_agents]}")
            
        except Exception as e:
            result = {
                'query': query,
                'geographic_match': None,
                'industry_match': None,
                'confidence_score': 0.0,
                'selected_agents': [],
                'reasoning': '',
                'status': f'error: {str(e)}'
            }
            print(f"    âŒ éŒ¯èª¤: {str(e)}")
        
        test_results.append(result)
    
    # åŸ·è¡Œå¯¦éš›è·ä½æœç´¢æ¸¬è©¦
    print("\n" + "=" * 80)
    print("ğŸ” åŸ·è¡Œå¯¦éš›è·ä½æœç´¢æ¸¬è©¦")
    print("=" * 80)
    
    search_tests = [
        {
            'name': 'è‹±åœ‹ AI å·¥ç¨‹å¸«',
            'search_term': 'AI Engineer',
            'location': 'London, UK',
            'country': 'UK'
        },
        {
            'name': 'å¾·åœ‹ æ©Ÿå™¨å­¸ç¿’å·¥ç¨‹å¸«',
            'search_term': 'Machine Learning Engineer',
            'location': 'Berlin, Germany',
            'country': 'Germany'
        },
        {
            'name': 'æ³•åœ‹ äººå·¥æ™ºèƒ½å·¥ç¨‹å¸«',
            'search_term': 'AI Engineer',
            'location': 'Paris, France',
            'country': 'France'
        }
    ]
    
    search_results = []
    
    for i, test in enumerate(search_tests, 1):
        print(f"\n{i}. æœç´¢æ¸¬è©¦: {test['name']}")
        print(f"   æœç´¢è©: {test['search_term']}")
        print(f"   åœ°é»: {test['location']}")
        
        try:
            # åŸ·è¡Œè·ä½æœç´¢
            jobs_df = scrape_jobs(
                site_name=['indeed', 'linkedin'],  # ä½¿ç”¨å­—ç¬¦ä¸²è€Œé AgentType
                search_term=test['search_term'],
                location=test['location'],
                results_wanted=10,
                hours_old=72,
                country_indeed=test['country']
            )
            
            if jobs_df is not None and not jobs_df.empty:
                job_count = len(jobs_df)
                print(f"   âœ… æ‰¾åˆ° {job_count} å€‹è·ä½")
                
                # ä¿å­˜çµæœ
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"europe_{test['country'].lower()}_{timestamp}.csv"
                jobs_df.to_csv(filename, index=False, encoding='utf-8-sig')
                print(f"   ğŸ“ çµæœå·²ä¿å­˜è‡³: {filename}")
                
                # é¡¯ç¤ºå‰å¹¾å€‹è·ä½
                print(f"   ğŸ“‹ å‰3å€‹è·ä½:")
                for j, row in jobs_df.head(3).iterrows():
                    title = row.get('title', 'N/A')[:50]
                    company = row.get('company', 'N/A')[:30]
                    location = row.get('location', 'N/A')[:30]
                    print(f"      {j+1}. {title} - {company} ({location})")
                
                search_results.append({
                    'test_name': test['name'],
                    'job_count': job_count,
                    'status': 'success',
                    'filename': filename
                })
            else:
                print(f"   âš ï¸  æœªæ‰¾åˆ°è·ä½")
                search_results.append({
                    'test_name': test['name'],
                    'job_count': 0,
                    'status': 'no_results',
                    'filename': None
                })
                
        except Exception as e:
            print(f"   âŒ æœç´¢éŒ¯èª¤: {str(e)}")
            search_results.append({
                'test_name': test['name'],
                'job_count': 0,
                'status': f'error: {str(e)}',
                'filename': None
            })
        
        # é¿å…éæ–¼é »ç¹çš„è«‹æ±‚
        if i < len(search_tests):
            print(f"   â³ ç­‰å¾… 3 ç§’...")
            time.sleep(3)
    
    # ç”Ÿæˆçµ±è¨ˆå ±å‘Š
    print("\n" + "=" * 80)
    print("ğŸ“Š æ¸¬è©¦çµ±è¨ˆå ±å‘Š")
    print("=" * 80)
    
    # è·¯ç”±æ¸¬è©¦çµ±è¨ˆ
    successful_routes = sum(1 for r in test_results if r['status'] == 'success')
    total_routes = len(test_results)
    route_success_rate = (successful_routes / total_routes) * 100 if total_routes > 0 else 0
    
    europe_matches = sum(1 for r in test_results if r.get('geographic_match') == 'Europe')
    tech_matches = sum(1 for r in test_results if r.get('industry_match') == 'Technology')
    avg_confidence = sum(r.get('confidence_score', 0) for r in test_results) / total_routes if total_routes > 0 else 0
    
    print(f"\nğŸ¯ è·¯ç”±æ¸¬è©¦çµæœ:")
    print(f"   ç¸½æ¸¬è©¦æ•¸: {total_routes}")
    print(f"   æˆåŠŸæ¸¬è©¦: {successful_routes}")
    print(f"   æˆåŠŸç‡: {route_success_rate:.1f}%")
    print(f"   æ­æ´²åœ°ç†åŒ¹é…: {europe_matches}/{total_routes} ({(europe_matches/total_routes)*100:.1f}%)")
    print(f"   æŠ€è¡“è¡Œæ¥­åŒ¹é…: {tech_matches}/{total_routes} ({(tech_matches/total_routes)*100:.1f}%)")
    print(f"   å¹³å‡ä¿¡å¿ƒåº¦: {avg_confidence:.2f}")
    
    # æœç´¢æ¸¬è©¦çµ±è¨ˆ
    successful_searches = sum(1 for r in search_results if r['status'] == 'success')
    total_searches = len(search_results)
    search_success_rate = (successful_searches / total_searches) * 100 if total_searches > 0 else 0
    total_jobs_found = sum(r.get('job_count', 0) for r in search_results)
    
    print(f"\nğŸ” è·ä½æœç´¢çµæœ:")
    print(f"   ç¸½æœç´¢æ¸¬è©¦: {total_searches}")
    print(f"   æˆåŠŸæœç´¢: {successful_searches}")
    print(f"   æœç´¢æˆåŠŸç‡: {search_success_rate:.1f}%")
    print(f"   ç¸½è·ä½æ•¸: {total_jobs_found}")
    print(f"   å¹³å‡æ¯æ¬¡æœç´¢: {total_jobs_found/total_searches:.1f} å€‹è·ä½")
    
    # ä¿å­˜è©³ç´°å ±å‘Š
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_filename = f"comprehensive_europe_test_report_{timestamp}.txt"
    
    with open(report_filename, 'w', encoding='utf-8') as f:
        f.write(f"æ­æ´²å¸‚å ´å…¨é¢æ¸¬è©¦å ±å‘Š\n")
        f.write(f"æ¸¬è©¦æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"="*80 + "\n\n")
        
        f.write(f"è·¯ç”±æ¸¬è©¦çµæœ:\n")
        f.write(f"ç¸½æ¸¬è©¦æ•¸: {total_routes}\n")
        f.write(f"æˆåŠŸæ¸¬è©¦: {successful_routes}\n")
        f.write(f"æˆåŠŸç‡: {route_success_rate:.1f}%\n")
        f.write(f"æ­æ´²åœ°ç†åŒ¹é…: {europe_matches}/{total_routes}\n")
        f.write(f"æŠ€è¡“è¡Œæ¥­åŒ¹é…: {tech_matches}/{total_routes}\n")
        f.write(f"å¹³å‡ä¿¡å¿ƒåº¦: {avg_confidence:.2f}\n\n")
        
        f.write(f"è©³ç´°è·¯ç”±æ¸¬è©¦çµæœ:\n")
        f.write("-"*60 + "\n")
        for i, result in enumerate(test_results, 1):
            f.write(f"{i:2d}. {result['query']}\n")
            f.write(f"    åœ°ç†åŒ¹é…: {result['geographic_match']}\n")
            f.write(f"    è¡Œæ¥­åŒ¹é…: {result['industry_match']}\n")
            f.write(f"    ä¿¡å¿ƒåº¦: {result['confidence_score']:.2f}\n")
            f.write(f"    ä»£ç†: {result['selected_agents']}\n")
            f.write(f"    ç‹€æ…‹: {result['status']}\n\n")
        
        f.write(f"è·ä½æœç´¢çµæœ:\n")
        f.write(f"ç¸½æœç´¢æ¸¬è©¦: {total_searches}\n")
        f.write(f"æˆåŠŸæœç´¢: {successful_searches}\n")
        f.write(f"æœç´¢æˆåŠŸç‡: {search_success_rate:.1f}%\n")
        f.write(f"ç¸½è·ä½æ•¸: {total_jobs_found}\n\n")
        
        f.write(f"è©³ç´°æœç´¢çµæœ:\n")
        f.write("-"*40 + "\n")
        for i, result in enumerate(search_results, 1):
            f.write(f"{i}. {result['test_name']}\n")
            f.write(f"   è·ä½æ•¸: {result['job_count']}\n")
            f.write(f"   ç‹€æ…‹: {result['status']}\n")
            if result['filename']:
                f.write(f"   æ–‡ä»¶: {result['filename']}\n")
            f.write("\n")
    
    print(f"\nğŸ“„ è©³ç´°å ±å‘Šå·²ä¿å­˜è‡³: {report_filename}")
    
    return {
        'route_tests': {
            'total': total_routes,
            'successful': successful_routes,
            'success_rate': route_success_rate,
            'europe_matches': europe_matches,
            'tech_matches': tech_matches,
            'avg_confidence': avg_confidence
        },
        'search_tests': {
            'total': total_searches,
            'successful': successful_searches,
            'success_rate': search_success_rate,
            'total_jobs': total_jobs_found
        },
        'test_results': test_results,
        'search_results': search_results
    }

def main():
    """
    ä¸»å‡½æ•¸
    """
    try:
        results = test_comprehensive_europe()
        
        print("\n" + "="*80)
        print("ğŸ‰ æ­æ´²å¸‚å ´å…¨é¢æ¸¬è©¦å®Œæˆ!")
        print("="*80)
        
        route_success = results['route_tests']['success_rate']
        search_success = results['search_tests']['success_rate']
        
        if route_success >= 90 and search_success >= 70:
            print("âœ… æ¸¬è©¦çµæœ: å„ªç§€ - æ­æ´²å¸‚å ´æ”¯æ´å®Œå–„")
        elif route_success >= 80 and search_success >= 50:
            print("âš ï¸  æ¸¬è©¦çµæœ: è‰¯å¥½ - æ­æ´²å¸‚å ´æ”¯æ´åŸºæœ¬å®Œå–„")
        else:
            print("âŒ æ¸¬è©¦çµæœ: éœ€è¦æ”¹é€² - æ­æ´²å¸‚å ´æ”¯æ´æœ‰å¾…åŠ å¼·")
        
        print(f"\nğŸ“ˆ é—œéµæŒ‡æ¨™:")
        print(f"   è·¯ç”±æˆåŠŸç‡: {route_success:.1f}%")
        print(f"   æœç´¢æˆåŠŸç‡: {search_success:.1f}%")
        print(f"   æ­æ´²åœ°ç†åŒ¹é…ç‡: {(results['route_tests']['europe_matches']/results['route_tests']['total'])*100:.1f}%")
        print(f"   ç¸½è·ä½æ•¸: {results['search_tests']['total_jobs']}")
            
    except Exception as e:
        print(f"âŒ æ¸¬è©¦åŸ·è¡ŒéŒ¯èª¤: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()