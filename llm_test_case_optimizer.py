#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LLMæ¸¬è©¦æ¡ˆä¾‹å„ªåŒ–å™¨
è‡ªå‹•æ”¹é€²å’Œå„ªåŒ–æ¸¬è©¦æ¡ˆä¾‹çš„è³ªé‡ã€å¤šæ¨£æ€§å’Œæœ‰æ•ˆæ€§

Author: JobSpy Team
Date: 2025-01-27
"""

import sys
import os
import json
import re
import time
import random
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple, Set
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
from collections import defaultdict, Counter
import statistics

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°Pythonè·¯å¾‘
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from jobseeker.llm_intent_analyzer import LLMProvider
from llm_test_case_validator import LLMTestCaseValidator, ValidationReport


class OptimizationStrategy(Enum):
    """å„ªåŒ–ç­–ç•¥"""
    QUALITY_IMPROVEMENT = "quality_improvement"  # è³ªé‡æ”¹é€²
    DIVERSITY_ENHANCEMENT = "diversity_enhancement"  # å¤šæ¨£æ€§å¢å¼·
    COVERAGE_EXPANSION = "coverage_expansion"  # è¦†è“‹ç‡æ“´å±•
    BALANCE_ADJUSTMENT = "balance_adjustment"  # å¹³è¡¡èª¿æ•´
    EDGE_CASE_GENERATION = "edge_case_generation"  # é‚Šç•Œæ¡ˆä¾‹ç”Ÿæˆ
    LANGUAGE_ENRICHMENT = "language_enrichment"  # èªè¨€è±å¯ŒåŒ–
    COMPLEXITY_BALANCING = "complexity_balancing"  # è¤‡é›œåº¦å¹³è¡¡
    INTENT_CLARIFICATION = "intent_clarification"  # æ„åœ–æ¾„æ¸…


class OptimizationAction(Enum):
    """å„ªåŒ–å‹•ä½œ"""
    ADD = "add"  # æ·»åŠ 
    MODIFY = "modify"  # ä¿®æ”¹
    REMOVE = "remove"  # ç§»é™¤
    MERGE = "merge"  # åˆä½µ
    SPLIT = "split"  # åˆ†å‰²
    ENHANCE = "enhance"  # å¢å¼·


@dataclass
class OptimizationRule:
    """å„ªåŒ–è¦å‰‡"""
    strategy: OptimizationStrategy
    action: OptimizationAction
    condition: str
    description: str
    priority: int
    auto_apply: bool = True
    parameters: Dict[str, Any] = field(default_factory=dict)


@dataclass
class OptimizationResult:
    """å„ªåŒ–çµæœ"""
    original_count: int
    optimized_count: int
    actions_applied: List[str]
    improvements: Dict[str, float]
    new_test_cases: List[Dict[str, Any]]
    modified_test_cases: List[Dict[str, Any]]
    removed_test_cases: List[str]
    optimization_time: float
    quality_score_improvement: float


class LLMTestCaseOptimizer:
    """LLMæ¸¬è©¦æ¡ˆä¾‹å„ªåŒ–å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–å„ªåŒ–å™¨"""
        self.validator = LLMTestCaseValidator()
        self.optimization_rules = self._load_optimization_rules()
        self.templates = self._load_templates()
        self.enhancement_patterns = self._load_enhancement_patterns()
        
    def _load_optimization_rules(self) -> List[OptimizationRule]:
        """è¼‰å…¥å„ªåŒ–è¦å‰‡"""
        return [
            # è³ªé‡æ”¹é€²è¦å‰‡
            OptimizationRule(
                strategy=OptimizationStrategy.QUALITY_IMPROVEMENT,
                action=OptimizationAction.MODIFY,
                condition="query_too_short",
                description="æ“´å±•éçŸ­çš„æŸ¥è©¢å…§å®¹",
                priority=1
            ),
            OptimizationRule(
                strategy=OptimizationStrategy.QUALITY_IMPROVEMENT,
                action=OptimizationAction.MODIFY,
                condition="query_too_long",
                description="ç°¡åŒ–éé•·çš„æŸ¥è©¢å…§å®¹",
                priority=2
            ),
            OptimizationRule(
                strategy=OptimizationStrategy.QUALITY_IMPROVEMENT,
                action=OptimizationAction.REMOVE,
                condition="empty_or_invalid",
                description="ç§»é™¤ç©ºç™½æˆ–ç„¡æ•ˆçš„æ¸¬è©¦æ¡ˆä¾‹",
                priority=1
            ),
            
            # å¤šæ¨£æ€§å¢å¼·è¦å‰‡
            OptimizationRule(
                strategy=OptimizationStrategy.DIVERSITY_ENHANCEMENT,
                action=OptimizationAction.ADD,
                condition="category_imbalance",
                description="æ·»åŠ ç¼ºå°‘çš„é¡åˆ¥æ¸¬è©¦æ¡ˆä¾‹",
                priority=3
            ),
            OptimizationRule(
                strategy=OptimizationStrategy.DIVERSITY_ENHANCEMENT,
                action=OptimizationAction.MODIFY,
                condition="duplicate_queries",
                description="ä¿®æ”¹é‡è¤‡çš„æŸ¥è©¢å…§å®¹",
                priority=2
            ),
            
            # è¦†è“‹ç‡æ“´å±•è¦å‰‡
            OptimizationRule(
                strategy=OptimizationStrategy.COVERAGE_EXPANSION,
                action=OptimizationAction.ADD,
                condition="missing_edge_cases",
                description="æ·»åŠ é‚Šç•Œæ¡ˆä¾‹",
                priority=3
            ),
            OptimizationRule(
                strategy=OptimizationStrategy.COVERAGE_EXPANSION,
                action=OptimizationAction.ADD,
                condition="missing_languages",
                description="æ·»åŠ å¤šèªè¨€æ¸¬è©¦æ¡ˆä¾‹",
                priority=4
            ),
            
            # è¤‡é›œåº¦å¹³è¡¡è¦å‰‡
            OptimizationRule(
                strategy=OptimizationStrategy.COMPLEXITY_BALANCING,
                action=OptimizationAction.ADD,
                condition="complexity_imbalance",
                description="å¹³è¡¡è¤‡é›œåº¦åˆ†ä½ˆ",
                priority=3
            ),
            
            # æ„åœ–æ¾„æ¸…è¦å‰‡
            OptimizationRule(
                strategy=OptimizationStrategy.INTENT_CLARIFICATION,
                action=OptimizationAction.MODIFY,
                condition="intent_mismatch",
                description="æ¾„æ¸…æ„åœ–èˆ‡æŸ¥è©¢çš„åŒ¹é…",
                priority=2
            )
        ]
    
    def _load_templates(self) -> Dict[str, List[str]]:
        """è¼‰å…¥æ¸¬è©¦æ¡ˆä¾‹æ¨¡æ¿"""
        return {
            "job_search": [
                "æˆ‘æƒ³æ‰¾{location}çš„{position}å·¥ä½œ",
                "å°‹æ‰¾{company}çš„{position}è·ä½",
                "æœ‰æ²’æœ‰{skill}ç›¸é—œçš„å·¥ä½œæ©Ÿæœƒ",
                "Looking for {position} jobs in {location}",
                "Search for {skill} developer positions",
                "{location}ã§{position}ã®ä»•äº‹ã‚’æ¢ã—ã¦ã„ã¾ã™",
                "{location}ì—ì„œ {position} ì¼ìë¦¬ë¥¼ ì°¾ê³  ìˆìŠµë‹ˆë‹¤"
            ],
            "salary_query": [
                "{position}çš„è–ªè³‡ç¯„åœæ˜¯å¤šå°‘",
                "{location}{position}çš„å¹³å‡è–ªæ°´",
                "What's the salary range for {position}",
                "Average {position} salary in {location}",
                "{position}ã®çµ¦æ–™ã¯ã„ãã‚‰ã§ã™ã‹",
                "{position}ì˜ ì—°ë´‰ì€ ì–¼ë§ˆì¸ê°€ìš”"
            ],
            "career_advice": [
                "å¦‚ä½•è½‰è·åˆ°{field}é ˜åŸŸ",
                "æƒ³è¦æˆç‚º{position}éœ€è¦ä»€éº¼æŠ€èƒ½",
                "How to transition to {field}",
                "Skills needed for {position} role",
                "{field}ã«è»¢è·ã™ã‚‹ã«ã¯",
                "{field}ë¡œ ì „ì§í•˜ë ¤ë©´"
            ],
            "edge_cases": [
                "æˆ‘æƒ³æ‰¾å·¥ä½œä½†ä¸çŸ¥é“åšä»€éº¼",
                "æœ‰æ²’æœ‰ä¸ç”¨ç¶“é©—çš„å·¥ä½œ",
                "é ç«¯å·¥ä½œæ©Ÿæœƒ",
                "part-time jobs for students",
                "work from home opportunities",
                "åœ¨å®…å‹¤å‹™ã®ä»•äº‹",
                "ì¬íƒê·¼ë¬´ ê°€ëŠ¥í•œ ì¼ìë¦¬"
            ],
            "inappropriate": [
                "ä»Šå¤©å¤©æ°£å¦‚ä½•",
                "æ¨è–¦å¥½åƒçš„é¤å»³",
                "What's the weather like",
                "Best restaurants nearby",
                "ä»Šæ—¥ã®å¤©æ°—",
                "ë§›ìˆëŠ” ì‹ë‹¹ ì¶”ì²œ"
            ]
        }
    
    def _load_enhancement_patterns(self) -> Dict[str, List[str]]:
        """è¼‰å…¥å¢å¼·æ¨¡å¼"""
        return {
            "locations": ["å°åŒ—", "æ–°ç«¹", "å°ä¸­", "é«˜é›„", "æ¡ƒåœ’", "å°å—", "New York", "San Francisco", "London", "Tokyo", "Seoul"],
            "positions": ["è»Ÿé«”å·¥ç¨‹å¸«", "è³‡æ–™ç§‘å­¸å®¶", "ç”¢å“ç¶“ç†", "è¨­è¨ˆå¸«", "è¡ŒéŠ·å°ˆå“¡", "software engineer", "data scientist", "product manager", "designer", "marketing specialist"],
            "skills": ["Python", "JavaScript", "React", "æ©Ÿå™¨å­¸ç¿’", "äººå·¥æ™ºæ…§", "UI/UX", "æ•¸æ“šåˆ†æ", "å°ˆæ¡ˆç®¡ç†"],
            "companies": ["Google", "Microsoft", "Apple", "å°ç©é›»", "è¯ç™¼ç§‘", "é´»æµ·", "TSMC", "MediaTek"],
            "fields": ["ç§‘æŠ€æ¥­", "é‡‘èæ¥­", "é†«ç™‚æ¥­", "æ•™è‚²æ¥­", "è£½é€ æ¥­", "technology", "finance", "healthcare", "education"]
        }
    
    def optimize_test_cases(self, test_cases: List[Dict[str, Any]], 
                          strategies: List[OptimizationStrategy] = None,
                          target_count: int = None) -> OptimizationResult:
        """å„ªåŒ–æ¸¬è©¦æ¡ˆä¾‹"""
        print(f"ğŸ”§ é–‹å§‹å„ªåŒ– {len(test_cases)} å€‹æ¸¬è©¦æ¡ˆä¾‹...")
        
        start_time = time.time()
        original_count = len(test_cases)
        
        if strategies is None:
            strategies = list(OptimizationStrategy)
        
        # åˆå§‹é©—è­‰
        initial_report = self.validator.validate_test_cases(test_cases)
        initial_quality_score = initial_report.metrics.overall_score
        
        # è¤‡è£½æ¸¬è©¦æ¡ˆä¾‹ä»¥é¿å…ä¿®æ”¹åŸå§‹æ•¸æ“š
        optimized_cases = [case.copy() for case in test_cases]
        actions_applied = []
        new_cases = []
        modified_cases = []
        removed_case_ids = []
        
        # æ‡‰ç”¨å„ªåŒ–ç­–ç•¥
        for strategy in strategies:
            print(f"   ğŸ¯ æ‡‰ç”¨ç­–ç•¥: {strategy.value}")
            
            if strategy == OptimizationStrategy.QUALITY_IMPROVEMENT:
                result = self._apply_quality_improvement(optimized_cases)
                actions_applied.extend(result["actions"])
                modified_cases.extend(result["modified"])
                removed_case_ids.extend(result["removed"])
                
            elif strategy == OptimizationStrategy.DIVERSITY_ENHANCEMENT:
                result = self._apply_diversity_enhancement(optimized_cases)
                actions_applied.extend(result["actions"])
                new_cases.extend(result["new"])
                modified_cases.extend(result["modified"])
                
            elif strategy == OptimizationStrategy.COVERAGE_EXPANSION:
                result = self._apply_coverage_expansion(optimized_cases)
                actions_applied.extend(result["actions"])
                new_cases.extend(result["new"])
                
            elif strategy == OptimizationStrategy.COMPLEXITY_BALANCING:
                result = self._apply_complexity_balancing(optimized_cases)
                actions_applied.extend(result["actions"])
                new_cases.extend(result["new"])
                
            elif strategy == OptimizationStrategy.INTENT_CLARIFICATION:
                result = self._apply_intent_clarification(optimized_cases)
                actions_applied.extend(result["actions"])
                modified_cases.extend(result["modified"])
        
        # æ·»åŠ æ–°æ¡ˆä¾‹
        optimized_cases.extend(new_cases)
        
        # ç§»é™¤æ¨™è¨˜ç‚ºåˆªé™¤çš„æ¡ˆä¾‹
        optimized_cases = [case for case in optimized_cases if case.get("id") not in removed_case_ids]
        
        # ç›®æ¨™æ•¸é‡èª¿æ•´
        if target_count and len(optimized_cases) != target_count:
            optimized_cases = self._adjust_to_target_count(optimized_cases, target_count)
            actions_applied.append(f"èª¿æ•´åˆ°ç›®æ¨™æ•¸é‡: {target_count}")
        
        # æœ€çµ‚é©—è­‰
        final_report = self.validator.validate_test_cases(optimized_cases)
        final_quality_score = final_report.metrics.overall_score
        
        # è¨ˆç®—æ”¹é€²æŒ‡æ¨™
        improvements = {
            "quality_score": final_quality_score - initial_quality_score,
            "coverage_score": final_report.metrics.coverage_score - initial_report.metrics.coverage_score,
            "diversity_score": final_report.metrics.diversity_score - initial_report.metrics.diversity_score,
            "valid_cases": final_report.metrics.valid_cases - initial_report.metrics.valid_cases
        }
        
        optimization_time = time.time() - start_time
        
        result = OptimizationResult(
            original_count=original_count,
            optimized_count=len(optimized_cases),
            actions_applied=actions_applied,
            improvements=improvements,
            new_test_cases=new_cases,
            modified_test_cases=modified_cases,
            removed_test_cases=removed_case_ids,
            optimization_time=optimization_time,
            quality_score_improvement=improvements["quality_score"]
        )
        
        print(f"   âœ… å„ªåŒ–å®Œæˆï¼Œè€—æ™‚ {optimization_time:.2f} ç§’")
        print(f"   ğŸ“Š è³ªé‡åˆ†æ•¸æå‡: {improvements['quality_score']:.3f}")
        
        return result, optimized_cases
    
    def _apply_quality_improvement(self, test_cases: List[Dict[str, Any]]) -> Dict[str, List]:
        """æ‡‰ç”¨è³ªé‡æ”¹é€²"""
        actions = []
        modified = []
        removed = []
        
        for case in test_cases[:]:
            case_id = case.get("id", "unknown")
            query = case.get("query", "")
            
            # ç§»é™¤ç©ºç™½æˆ–ç„¡æ•ˆæ¡ˆä¾‹
            if not query.strip() or len(query) < 3:
                removed.append(case_id)
                actions.append(f"ç§»é™¤ç„¡æ•ˆæ¡ˆä¾‹: {case_id}")
                continue
            
            # æ“´å±•éçŸ­æŸ¥è©¢
            if len(query) < 10:
                enhanced_query = self._enhance_short_query(query, case)
                if enhanced_query != query:
                    case["query"] = enhanced_query
                    modified.append(case_id)
                    actions.append(f"æ“´å±•çŸ­æŸ¥è©¢: {case_id}")
            
            # ç°¡åŒ–éé•·æŸ¥è©¢
            elif len(query) > 200:
                simplified_query = self._simplify_long_query(query)
                if simplified_query != query:
                    case["query"] = simplified_query
                    modified.append(case_id)
                    actions.append(f"ç°¡åŒ–é•·æŸ¥è©¢: {case_id}")
            
            # æ¸…ç†é‡è¤‡å­—ç¬¦
            cleaned_query = re.sub(r"(.)\1{3,}", r"\1\1", query)
            if cleaned_query != query:
                case["query"] = cleaned_query
                modified.append(case_id)
                actions.append(f"æ¸…ç†é‡è¤‡å­—ç¬¦: {case_id}")
        
        return {"actions": actions, "modified": modified, "removed": removed}
    
    def _apply_diversity_enhancement(self, test_cases: List[Dict[str, Any]]) -> Dict[str, List]:
        """æ‡‰ç”¨å¤šæ¨£æ€§å¢å¼·"""
        actions = []
        new_cases = []
        modified = []
        
        # åˆ†æç•¶å‰åˆ†ä½ˆ
        category_counts = Counter(case.get("category", "") for case in test_cases)
        total_cases = len(test_cases)
        
        # æª¢æŸ¥é¡åˆ¥ä¸å¹³è¡¡
        target_categories = ["basic_job_search", "advanced_job_search", "salary_query", 
                           "location_query", "career_advice", "edge_case", "inappropriate_query"]
        
        for category in target_categories:
            current_count = category_counts.get(category, 0)
            target_count = max(1, total_cases // len(target_categories))
            
            if current_count < target_count:
                needed = target_count - current_count
                for _ in range(needed):
                    new_case = self._generate_case_for_category(category)
                    if new_case:
                        new_cases.append(new_case)
                        actions.append(f"æ·»åŠ  {category} é¡åˆ¥æ¡ˆä¾‹")
        
        # è™•ç†é‡è¤‡æŸ¥è©¢
        query_counts = Counter(case.get("query", "") for case in test_cases)
        duplicate_queries = [query for query, count in query_counts.items() if count > 1]
        
        for query in duplicate_queries:
            matching_cases = [case for case in test_cases if case.get("query") == query]
            for i, case in enumerate(matching_cases[1:], 1):  # ä¿ç•™ç¬¬ä¸€å€‹ï¼Œä¿®æ”¹å…¶ä»–
                case_id = case.get("id", "unknown")
                varied_query = self._create_query_variation(query, case)
                if varied_query != query:
                    case["query"] = varied_query
                    modified.append(case_id)
                    actions.append(f"ä¿®æ”¹é‡è¤‡æŸ¥è©¢: {case_id}")
        
        return {"actions": actions, "new": new_cases, "modified": modified}
    
    def _apply_coverage_expansion(self, test_cases: List[Dict[str, Any]]) -> Dict[str, List]:
        """æ‡‰ç”¨è¦†è“‹ç‡æ“´å±•"""
        actions = []
        new_cases = []
        
        # æª¢æŸ¥é‚Šç•Œæ¡ˆä¾‹è¦†è“‹
        edge_case_count = sum(1 for case in test_cases if case.get("category") == "edge_case")
        if edge_case_count < len(test_cases) * 0.1:  # å°‘æ–¼10%
            needed_edge_cases = max(1, int(len(test_cases) * 0.1) - edge_case_count)
            for _ in range(needed_edge_cases):
                edge_case = self._generate_edge_case()
                if edge_case:
                    new_cases.append(edge_case)
                    actions.append("æ·»åŠ é‚Šç•Œæ¡ˆä¾‹")
        
        # æª¢æŸ¥å¤šèªè¨€è¦†è“‹
        languages = set(case.get("language", "zh-TW") for case in test_cases)
        target_languages = ["zh-TW", "en", "ja", "ko"]
        
        for lang in target_languages:
            if lang not in languages:
                lang_case = self._generate_multilingual_case(lang)
                if lang_case:
                    new_cases.append(lang_case)
                    actions.append(f"æ·»åŠ  {lang} èªè¨€æ¡ˆä¾‹")
        
        return {"actions": actions, "new": new_cases}
    
    def _apply_complexity_balancing(self, test_cases: List[Dict[str, Any]]) -> Dict[str, List]:
        """æ‡‰ç”¨è¤‡é›œåº¦å¹³è¡¡"""
        actions = []
        new_cases = []
        
        # åˆ†æè¤‡é›œåº¦åˆ†ä½ˆ
        complexity_counts = Counter(case.get("complexity", "medium") for case in test_cases)
        total_cases = len(test_cases)
        
        target_complexities = ["simple", "medium", "complex", "extreme"]
        target_ratios = {"simple": 0.3, "medium": 0.4, "complex": 0.2, "extreme": 0.1}
        
        for complexity in target_complexities:
            current_count = complexity_counts.get(complexity, 0)
            target_count = int(total_cases * target_ratios[complexity])
            
            if current_count < target_count:
                needed = target_count - current_count
                for _ in range(needed):
                    complex_case = self._generate_case_with_complexity(complexity)
                    if complex_case:
                        new_cases.append(complex_case)
                        actions.append(f"æ·»åŠ  {complexity} è¤‡é›œåº¦æ¡ˆä¾‹")
        
        return {"actions": actions, "new": new_cases}
    
    def _apply_intent_clarification(self, test_cases: List[Dict[str, Any]]) -> Dict[str, List]:
        """æ‡‰ç”¨æ„åœ–æ¾„æ¸…"""
        actions = []
        modified = []
        
        intent_keywords = {
            "job_search": ["å·¥ä½œ", "è·ç¼º", "job", "position", "ä»•äº‹", "ì¼ìë¦¬"],
            "salary_query": ["è–ªè³‡", "è–ªæ°´", "salary", "wage", "çµ¦æ–™", "ê¸‰ì—¬"],
            "career_advice": ["è½‰è·", "è·æ¶¯", "career", "advice", "è»¢è·", "ì „ì§"],
            "location_query": ["åœ°é»", "ä½ç½®", "location", "place", "å ´æ‰€", "ìœ„ì¹˜"]
        }
        
        for case in test_cases:
            case_id = case.get("id", "unknown")
            query = case.get("query", "")
            expected_intent = case.get("expected_intent", "")
            
            if expected_intent in intent_keywords:
                keywords = intent_keywords[expected_intent]
                has_keyword = any(keyword.lower() in query.lower() for keyword in keywords)
                
                if not has_keyword:
                    # æ·»åŠ ç›¸é—œé—œéµè©
                    enhanced_query = self._add_intent_keywords(query, expected_intent)
                    if enhanced_query != query:
                        case["query"] = enhanced_query
                        modified.append(case_id)
                        actions.append(f"æ¾„æ¸…æ„åœ–: {case_id}")
        
        return {"actions": actions, "modified": modified}
    
    def _enhance_short_query(self, query: str, case: Dict[str, Any]) -> str:
        """å¢å¼·çŸ­æŸ¥è©¢"""
        category = case.get("category", "")
        intent = case.get("expected_intent", "")
        
        enhancements = {
            "job_search": ["çš„å·¥ä½œæ©Ÿæœƒ", "ç›¸é—œè·ä½", "å·¥ä½œ"],
            "salary_query": ["çš„è–ªè³‡ç¯„åœ", "è–ªæ°´å¤šå°‘", "å¾…é‡å¦‚ä½•"],
            "career_advice": ["è·æ¶¯å»ºè­°", "ç™¼å±•æ–¹å‘", "è½‰è·å»ºè­°"]
        }
        
        if intent in enhancements:
            enhancement = random.choice(enhancements[intent])
            return f"{query}{enhancement}"
        
        return f"{query}ç›¸é—œä¿¡æ¯"
    
    def _simplify_long_query(self, query: str) -> str:
        """ç°¡åŒ–é•·æŸ¥è©¢"""
        # ç§»é™¤é‡è¤‡è©èª
        words = query.split()
        unique_words = []
        seen = set()
        
        for word in words:
            if word.lower() not in seen:
                unique_words.append(word)
                seen.add(word.lower())
        
        simplified = " ".join(unique_words)
        
        # å¦‚æœé‚„æ˜¯å¤ªé•·ï¼Œæˆªå–å‰150å€‹å­—ç¬¦
        if len(simplified) > 150:
            simplified = simplified[:147] + "..."
        
        return simplified
    
    def _generate_case_for_category(self, category: str) -> Optional[Dict[str, Any]]:
        """ç‚ºç‰¹å®šé¡åˆ¥ç”Ÿæˆæ¸¬è©¦æ¡ˆä¾‹"""
        templates = self.templates.get(category, [])
        if not templates:
            return None
        
        template = random.choice(templates)
        
        # æ›¿æ›æ¨¡æ¿è®Šé‡
        query = self._fill_template(template)
        
        case_id = f"opt_{category}_{int(time.time() * 1000) % 10000}"
        
        intent_mapping = {
            "basic_job_search": "job_search",
            "advanced_job_search": "job_search",
            "salary_query": "salary_query",
            "career_advice": "career_advice",
            "edge_case": "job_search",
            "inappropriate_query": "inappropriate_query"
        }
        
        return {
            "id": case_id,
            "query": query,
            "expected_intent": intent_mapping.get(category, "job_search"),
            "category": category,
            "complexity": "medium",
            "language": self._detect_query_language(query),
            "expected_confidence_range": [0.7, 0.9],
            "expected_entities": {},
            "metadata": {
                "generated_by": "optimizer",
                "generation_time": datetime.now().isoformat()
            }
        }
    
    def _create_query_variation(self, original_query: str, case: Dict[str, Any]) -> str:
        """å‰µå»ºæŸ¥è©¢è®Šé«”"""
        variations = [
            f"è«‹å•{original_query}",
            f"æˆ‘æƒ³äº†è§£{original_query}",
            f"èƒ½å¦å¹«æˆ‘{original_query}",
            f"é—œæ–¼{original_query}çš„å•é¡Œ",
            f"{original_query}çš„ç›¸é—œä¿¡æ¯"
        ]
        
        # æ ¹æ“šèªè¨€é¸æ“‡é©ç•¶çš„è®Šé«”
        language = case.get("language", "zh-TW")
        if language == "en":
            variations = [
                f"Can you help me with {original_query}",
                f"I'm looking for {original_query}",
                f"Please find {original_query}",
                f"Information about {original_query}",
                f"Help me understand {original_query}"
            ]
        
        return random.choice(variations)
    
    def _generate_edge_case(self) -> Dict[str, Any]:
        """ç”Ÿæˆé‚Šç•Œæ¡ˆä¾‹"""
        edge_cases = [
            "æˆ‘æƒ³æ‰¾å·¥ä½œä½†ä¸çŸ¥é“è‡ªå·±é©åˆä»€éº¼",
            "æ²’æœ‰å·¥ä½œç¶“é©—å¯ä»¥æ‰¾åˆ°å·¥ä½œå—",
            "50æ­²é‚„èƒ½è½‰è·å—",
            "åªæƒ³è¦é ç«¯å·¥ä½œ",
            "part-time job for students",
            "work from home opportunities",
            "jobs with no experience required",
            "career change at 40"
        ]
        
        query = random.choice(edge_cases)
        case_id = f"edge_{int(time.time() * 1000) % 10000}"
        
        return {
            "id": case_id,
            "query": query,
            "expected_intent": "job_search",
            "category": "edge_case",
            "complexity": "complex",
            "language": self._detect_query_language(query),
            "expected_confidence_range": [0.5, 0.8],
            "expected_entities": {},
            "metadata": {
                "generated_by": "optimizer",
                "generation_time": datetime.now().isoformat()
            }
        }
    
    def _generate_multilingual_case(self, language: str) -> Dict[str, Any]:
        """ç”Ÿæˆå¤šèªè¨€æ¡ˆä¾‹"""
        queries = {
            "zh-TW": "æˆ‘æƒ³åœ¨å°åŒ—æ‰¾è»Ÿé«”å·¥ç¨‹å¸«çš„å·¥ä½œ",
            "en": "Looking for software engineer jobs in New York",
            "ja": "æ±äº¬ã§ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã®ä»•äº‹ã‚’æ¢ã—ã¦ã„ã¾ã™",
            "ko": "ì„œìš¸ì—ì„œ ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´ ì¼ìë¦¬ë¥¼ ì°¾ê³  ìˆìŠµë‹ˆë‹¤"
        }
        
        query = queries.get(language, queries["zh-TW"])
        case_id = f"lang_{language}_{int(time.time() * 1000) % 10000}"
        
        return {
            "id": case_id,
            "query": query,
            "expected_intent": "job_search",
            "category": "basic_job_search",
            "complexity": "medium",
            "language": language,
            "expected_confidence_range": [0.7, 0.9],
            "expected_entities": {},
            "metadata": {
                "generated_by": "optimizer",
                "generation_time": datetime.now().isoformat()
            }
        }
    
    def _generate_case_with_complexity(self, complexity: str) -> Dict[str, Any]:
        """ç”ŸæˆæŒ‡å®šè¤‡é›œåº¦çš„æ¡ˆä¾‹"""
        complexity_queries = {
            "simple": [
                "æ‰¾å·¥ä½œ",
                "job search",
                "ä»•äº‹æ¢ã—",
                "ì¼ìë¦¬ ì°¾ê¸°"
            ],
            "medium": [
                "æˆ‘æƒ³æ‰¾å°åŒ—çš„è»Ÿé«”å·¥ç¨‹å¸«å·¥ä½œ",
                "Looking for software engineer jobs in San Francisco",
                "æ±äº¬ã§ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ã®ä»•äº‹ã‚’æ¢ã—ã¦ã„ã¾ã™",
                "ì„œìš¸ì—ì„œ ê°œë°œì ì¼ìë¦¬ë¥¼ ì°¾ê³  ìˆìŠµë‹ˆë‹¤"
            ],
            "complex": [
                "æˆ‘æ˜¯è³‡æ·±å‰ç«¯å·¥ç¨‹å¸«ï¼Œæƒ³è½‰è·åˆ°å¤§å‹ç§‘æŠ€å…¬å¸åšå…¨ç«¯é–‹ç™¼ï¼Œå¸Œæœ›è–ªè³‡åœ¨150è¬ä»¥ä¸Š",
                "Senior frontend developer looking to transition to full-stack role at FAANG companies with 150k+ salary",
                "ã‚·ãƒ‹ã‚¢ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã¨ã—ã¦ã€å¤§æ‰‹ãƒ†ãƒƒã‚¯ä¼æ¥­ã§ãƒ•ãƒ«ã‚¹ã‚¿ãƒƒã‚¯é–‹ç™ºã«è»¢è·ã—ãŸã„",
                "ì‹œë‹ˆì–´ í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œìë¡œì„œ ëŒ€ê¸°ì—…ì—ì„œ í’€ìŠ¤íƒ ê°œë°œìë¡œ ì „ì§í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤"
            ],
            "extreme": [
                "æˆ‘æ˜¯45æ­²çš„å‚³çµ±è£½é€ æ¥­ç¶“ç†ï¼Œæ²’æœ‰ç¨‹å¼èƒŒæ™¯ï¼Œæƒ³è½‰è·åˆ°AI/MLé ˜åŸŸï¼Œä½†åªè€ƒæ…®é ç«¯å·¥ä½œï¼Œè–ªè³‡ä¸èƒ½ä½æ–¼ç¾åœ¨çš„200è¬ï¼Œè€Œä¸”å¸Œæœ›åœ¨6å€‹æœˆå…§å®Œæˆè½‰è·",
                "45-year-old manufacturing manager with no coding background wanting to transition to AI/ML field, remote only, salary must be 200k+, timeline 6 months",
                "45æ­³ã®è£½é€ æ¥­ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã§ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°çµŒé¨“ãªã—ã€AI/MLåˆ†é‡ã«è»¢è·ã—ãŸã„ã€ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ã®ã¿ã€å¹´å2000ä¸‡å††ä»¥ä¸Šã€6ãƒ¶æœˆä»¥å†…",
                "45ì„¸ ì œì¡°ì—… ë§¤ë‹ˆì €ë¡œ ì½”ë”© ê²½í—˜ ì—†ì´ AI/ML ë¶„ì•¼ë¡œ ì „ì§í•˜ê³  ì‹¶ì€ë°, ì¬íƒê·¼ë¬´ë§Œ ê°€ëŠ¥í•˜ê³  ì—°ë´‰ 2ì–µ ì´ìƒ, 6ê°œì›” ë‚´ ì „ì§ í¬ë§"
            ]
        }
        
        queries = complexity_queries.get(complexity, complexity_queries["medium"])
        query = random.choice(queries)
        case_id = f"comp_{complexity}_{int(time.time() * 1000) % 10000}"
        
        confidence_ranges = {
            "simple": [0.8, 0.95],
            "medium": [0.7, 0.9],
            "complex": [0.6, 0.8],
            "extreme": [0.4, 0.7]
        }
        
        return {
            "id": case_id,
            "query": query,
            "expected_intent": "job_search",
            "category": "basic_job_search",
            "complexity": complexity,
            "language": self._detect_query_language(query),
            "expected_confidence_range": confidence_ranges[complexity],
            "expected_entities": {},
            "metadata": {
                "generated_by": "optimizer",
                "generation_time": datetime.now().isoformat()
            }
        }
    
    def _add_intent_keywords(self, query: str, intent: str) -> str:
        """æ·»åŠ æ„åœ–é—œéµè©"""
        keywords = {
            "job_search": ["å·¥ä½œ", "è·ä½", "job", "position"],
            "salary_query": ["è–ªè³‡", "è–ªæ°´", "salary", "wage"],
            "career_advice": ["è·æ¶¯", "å»ºè­°", "career", "advice"],
            "location_query": ["åœ°é»", "ä½ç½®", "location", "place"]
        }
        
        if intent in keywords:
            keyword = random.choice(keywords[intent])
            if keyword not in query:
                return f"{query} {keyword}"
        
        return query
    
    def _fill_template(self, template: str) -> str:
        """å¡«å……æ¨¡æ¿"""
        patterns = self.enhancement_patterns
        
        # æ›¿æ›æ¨¡æ¿è®Šé‡
        for key, values in patterns.items():
            placeholder = f"{{{key[:-1]}}}"
            if placeholder in template:
                template = template.replace(placeholder, random.choice(values))
        
        return template
    
    def _detect_query_language(self, query: str) -> str:
        """æª¢æ¸¬æŸ¥è©¢èªè¨€"""
        if re.search(r"[\u4e00-\u9fff]", query):
            return "zh-TW"
        elif re.search(r"[\u3040-\u309f\u30a0-\u30ff]", query):
            return "ja"
        elif re.search(r"[\uac00-\ud7af]", query):
            return "ko"
        elif re.search(r"[a-zA-Z]", query):
            return "en"
        else:
            return "unknown"
    
    def _adjust_to_target_count(self, test_cases: List[Dict[str, Any]], target_count: int) -> List[Dict[str, Any]]:
        """èª¿æ•´åˆ°ç›®æ¨™æ•¸é‡"""
        current_count = len(test_cases)
        
        if current_count > target_count:
            # éš¨æ©Ÿç§»é™¤å¤šé¤˜çš„æ¡ˆä¾‹ï¼Œä½†ä¿æŒé¡åˆ¥å¹³è¡¡
            categories = list(set(case.get("category", "") for case in test_cases))
            cases_by_category = defaultdict(list)
            
            for case in test_cases:
                category = case.get("category", "")
                cases_by_category[category].append(case)
            
            # æŒ‰æ¯”ä¾‹ä¿ç•™
            result = []
            for category in categories:
                category_cases = cases_by_category[category]
                keep_count = max(1, int(len(category_cases) * target_count / current_count))
                result.extend(random.sample(category_cases, min(keep_count, len(category_cases))))
            
            # å¦‚æœé‚„æ˜¯å¤ªå¤šï¼Œéš¨æ©Ÿç§»é™¤
            if len(result) > target_count:
                result = random.sample(result, target_count)
            
            return result
        
        elif current_count < target_count:
            # ç”Ÿæˆé¡å¤–æ¡ˆä¾‹
            needed = target_count - current_count
            categories = ["basic_job_search", "salary_query", "career_advice", "edge_case"]
            
            for _ in range(needed):
                category = random.choice(categories)
                new_case = self._generate_case_for_category(category)
                if new_case:
                    test_cases.append(new_case)
        
        return test_cases
    
    def export_optimized_cases(self, test_cases: List[Dict[str, Any]], 
                             result: OptimizationResult, 
                             output_file: str = None) -> str:
        """å°å‡ºå„ªåŒ–å¾Œçš„æ¸¬è©¦æ¡ˆä¾‹"""
        if not output_file:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"optimized_test_cases_{timestamp}.json"
        
        print(f"ğŸ’¾ å°å‡ºå„ªåŒ–å¾Œçš„æ¸¬è©¦æ¡ˆä¾‹åˆ° {output_file}...")
        
        export_data = {
            "optimization_info": {
                "optimization_time": datetime.now().isoformat(),
                "original_count": result.original_count,
                "optimized_count": result.optimized_count,
                "actions_applied": result.actions_applied,
                "improvements": result.improvements,
                "optimization_duration": result.optimization_time
            },
            "test_cases": test_cases,
            "statistics": {
                "category_distribution": dict(Counter(case.get("category", "") for case in test_cases)),
                "complexity_distribution": dict(Counter(case.get("complexity", "") for case in test_cases)),
                "language_distribution": dict(Counter(case.get("language", "") for case in test_cases)),
                "intent_distribution": dict(Counter(case.get("expected_intent", "") for case in test_cases))
            }
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)
        
        print(f"   âœ… å„ªåŒ–å¾Œçš„æ¸¬è©¦æ¡ˆä¾‹å·²å°å‡º")
        return output_file
    
    def print_optimization_summary(self, result: OptimizationResult) -> None:
        """æ‰“å°å„ªåŒ–æ‘˜è¦"""
        print("\n" + "=" * 60)
        print("ğŸ”§ LLMæ¸¬è©¦æ¡ˆä¾‹å„ªåŒ–å ±å‘Š")
        print("=" * 60)
        
        print(f"\nğŸ“Š å„ªåŒ–çµ±è¨ˆ:")
        print(f"   åŸå§‹æ¡ˆä¾‹æ•¸: {result.original_count}")
        print(f"   å„ªåŒ–å¾Œæ¡ˆä¾‹æ•¸: {result.optimized_count}")
        print(f"   å„ªåŒ–æ™‚é–“: {result.optimization_time:.2f} ç§’")
        
        print(f"\nğŸ¯ åŸ·è¡Œçš„å„ªåŒ–å‹•ä½œ:")
        for i, action in enumerate(result.actions_applied, 1):
            print(f"   {i}. {action}")
        
        print(f"\nğŸ“ˆ æ”¹é€²æŒ‡æ¨™:")
        for metric, improvement in result.improvements.items():
            improvement_emoji = "ğŸ“ˆ" if improvement > 0 else "ğŸ“‰" if improvement < 0 else "â¡ï¸"
            print(f"   {improvement_emoji} {metric}: {improvement:+.3f}")
        
        print(f"\nğŸ“‹ è®Šæ›´æ‘˜è¦:")
        print(f"   æ–°å¢æ¡ˆä¾‹: {len(result.new_test_cases)}")
        print(f"   ä¿®æ”¹æ¡ˆä¾‹: {len(result.modified_test_cases)}")
        print(f"   ç§»é™¤æ¡ˆä¾‹: {len(result.removed_test_cases)}")
        
        if result.quality_score_improvement > 0:
            print(f"\nâœ… å„ªåŒ–æˆåŠŸï¼è³ªé‡åˆ†æ•¸æå‡ {result.quality_score_improvement:.3f}")
        else:
            print(f"\nâš ï¸ å„ªåŒ–æ•ˆæœæœ‰é™ï¼Œè³ªé‡åˆ†æ•¸è®ŠåŒ– {result.quality_score_improvement:.3f}")
        
        print("\n" + "=" * 60)


def load_test_cases_from_file(file_path: str) -> List[Dict[str, Any]]:
    """å¾æ–‡ä»¶è¼‰å…¥æ¸¬è©¦æ¡ˆä¾‹"""
    print(f"ğŸ“‚ è¼‰å…¥æ¸¬è©¦æ¡ˆä¾‹å¾ {file_path}...")
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        if isinstance(data, dict) and "test_cases" in data:
            test_cases = data["test_cases"]
        elif isinstance(data, list):
            test_cases = data
        else:
            raise ValueError("ç„¡æ•ˆçš„æ–‡ä»¶æ ¼å¼")
        
        print(f"   âœ… æˆåŠŸè¼‰å…¥ {len(test_cases)} å€‹æ¸¬è©¦æ¡ˆä¾‹")
        return test_cases
        
    except Exception as e:
        print(f"   âŒ è¼‰å…¥å¤±æ•—: {str(e)}")
        return []


def main():
    """ä¸»å‡½æ•¸ - æ¸¬è©¦æ¡ˆä¾‹å„ªåŒ–å™¨å…¥å£é»"""
    print("ğŸ”§ LLMæ¸¬è©¦æ¡ˆä¾‹å„ªåŒ–å™¨")
    print("=" * 60)
    
    optimizer = LLMTestCaseOptimizer()
    
    try:
        # ç²å–è¼¸å…¥æ–‡ä»¶
        input_file = input("è«‹è¼¸å…¥æ¸¬è©¦æ¡ˆä¾‹æ–‡ä»¶è·¯å¾‘ (æˆ–æŒ‰Enterä½¿ç”¨é»˜èª): ").strip()
        if not input_file:
            input_file = "generated_test_cases.json"
        
        # è¼‰å…¥æ¸¬è©¦æ¡ˆä¾‹
        test_cases = load_test_cases_from_file(input_file)
        
        if not test_cases:
            print("âŒ æ²’æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æ¸¬è©¦æ¡ˆä¾‹")
            return
        
        # é¸æ“‡å„ªåŒ–ç­–ç•¥
        print("\nğŸ¯ é¸æ“‡å„ªåŒ–ç­–ç•¥:")
        print("1. å…¨é¢å„ªåŒ– (æ‰€æœ‰ç­–ç•¥)")
        print("2. è³ªé‡æ”¹é€²")
        print("3. å¤šæ¨£æ€§å¢å¼·")
        print("4. è¦†è“‹ç‡æ“´å±•")
        print("5. è¤‡é›œåº¦å¹³è¡¡")
        print("6. è‡ªå®šç¾©")
        
        choice = input("è«‹é¸æ“‡ (1-6): ").strip()
        
        strategies = []
        if choice == "1":
            strategies = list(OptimizationStrategy)
        elif choice == "2":
            strategies = [OptimizationStrategy.QUALITY_IMPROVEMENT]
        elif choice == "3":
            strategies = [OptimizationStrategy.DIVERSITY_ENHANCEMENT]
        elif choice == "4":
            strategies = [OptimizationStrategy.COVERAGE_EXPANSION]
        elif choice == "5":
            strategies = [OptimizationStrategy.COMPLEXITY_BALANCING]
        elif choice == "6":
            print("\nå¯ç”¨ç­–ç•¥:")
            for i, strategy in enumerate(OptimizationStrategy, 1):
                print(f"{i}. {strategy.value}")
            
            selected = input("è«‹è¼¸å…¥ç­–ç•¥ç·¨è™Ÿ (ç”¨é€—è™Ÿåˆ†éš”): ").strip()
            try:
                indices = [int(x.strip()) - 1 for x in selected.split(",")]
                strategies = [list(OptimizationStrategy)[i] for i in indices if 0 <= i < len(OptimizationStrategy)]
            except:
                print("ç„¡æ•ˆçš„é¸æ“‡ï¼Œä½¿ç”¨å…¨é¢å„ªåŒ–")
                strategies = list(OptimizationStrategy)
        else:
            strategies = list(OptimizationStrategy)
        
        # ç›®æ¨™æ•¸é‡
        target_count = None
        target_input = input(f"\nç›®æ¨™æ¡ˆä¾‹æ•¸é‡ (ç•¶å‰: {len(test_cases)}, æŒ‰Enterä¿æŒä¸è®Š): ").strip()
        if target_input.isdigit():
            target_count = int(target_input)
        
        # åŸ·è¡Œå„ªåŒ–
        print(f"\nğŸ”§ é–‹å§‹å„ªåŒ–ï¼Œä½¿ç”¨ç­–ç•¥: {[s.value for s in strategies]}")
        result, optimized_cases = optimizer.optimize_test_cases(test_cases, strategies, target_count)
        
        # é¡¯ç¤ºçµæœ
        optimizer.print_optimization_summary(result)
        
        # å°å‡ºçµæœ
        export_result = input("\næ˜¯å¦å°å‡ºå„ªåŒ–å¾Œçš„æ¸¬è©¦æ¡ˆä¾‹ï¼Ÿ (y/n): ").strip().lower()
        if export_result == 'y':
            output_file = optimizer.export_optimized_cases(optimized_cases, result)
            print(f"   ğŸ“„ å„ªåŒ–å¾Œæ–‡ä»¶: {output_file}")
        
        print("\nğŸ‰ æ¸¬è©¦æ¡ˆä¾‹å„ªåŒ–å®Œæˆï¼")
        
    except KeyboardInterrupt:
        print("\nâŒ å„ªåŒ–éç¨‹è¢«ç”¨æˆ¶ä¸­æ–·")
    except Exception as e:
        print(f"\nâŒ å„ªåŒ–éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()